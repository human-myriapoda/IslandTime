{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=uB7RQOG9E8vwMURhnYDIVlo7I-0JdKzSNTd8HgUH-e4&tc=tPb0OmITfff-ArbUDpBbAzrem-iu583-F_wwJfCHC7s&cc=ulf91Gl1ShDC8ZdOhP_ldXlTWzl71V6isO5oFohS_eE>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=uB7RQOG9E8vwMURhnYDIVlo7I-0JdKzSNTd8HgUH-e4&tc=tPb0OmITfff-ArbUDpBbAzrem-iu583-F_wwJfCHC7s&cc=ulf91Gl1ShDC8ZdOhP_ldXlTWzl71V6isO5oFohS_eE</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "from IslandTime import TimeSeriesConnections, retrieve_island_info, plot_shoreline_transects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "island_info = retrieve_island_info('Dhakandhoo', 'Maldives', verbose=False)\n",
    "\n",
    "ts = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['coastline_position_transect_2_waterline']\n",
    "ts_we = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['wave_energy_of_combined_wind_waves_and_swell']\n",
    "ts_sl = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['sea_level_anomaly']\n",
    "ts_sst = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['sea_surface_temperature']\n",
    "ts_tp = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['total_precipitation']\n",
    "ts_temp = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['2_metre_dewpoint_temperature']\n",
    "ts_wd = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['mean_wave_direction']\n",
    "ts_windd = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['wind_direction_10m']\n",
    "ts_winds = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['wind_speed_10m']\n",
    "ts_ap = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_2_waterline']['monthly']['mean_sea_level_pressure']\n",
    "\n",
    "import Rbeast as rb\n",
    "\n",
    "o = rb.beast(ts, start=[ts.index[0].year, ts.index[0].month, ts.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_we = rb.beast(ts_we, start=[ts_we.index[0].year, ts_we.index[0].month, ts_we.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_sl = rb.beast(ts_sl, start=[ts_sl.index[0].year, ts_sl.index[0].month, ts_sl.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_sst = rb.beast(ts_sst, start=[ts_sst.index[0].year, ts_sst.index[0].month, ts_sst.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_tp = rb.beast(ts_tp, start=[ts_tp.index[0].year, ts_tp.index[0].month, ts_tp.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_temp = rb.beast(ts_temp, start=[ts_temp.index[0].year, ts_temp.index[0].month, ts_temp.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_wd = rb.beast(ts_wd, start=[ts_wd.index[0].year, ts_wd.index[0].month, ts_wd.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_windd = rb.beast(ts_windd, start=[ts_windd.index[0].year, ts_windd.index[0].month, ts_windd.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_winds = rb.beast(ts_winds, start=[ts_winds.index[0].year, ts_winds.index[0].month, ts_winds.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "o_ap = rb.beast(ts_ap, start=[ts_ap.index[0].year, ts_ap.index[0].month, ts_ap.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "# o_wd = rb.beast(ts_wd, start=[ts_wd.index[0].year, ts_wd.index[0].month, ts_wd.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "\n",
    "names = ['coastline_position', 'wave_energy', 'sea_level_anomaly', 'sst', 'total_precipitation', 'dewpoint_temperature', 'mean_wave_direction', 'wind_direction_10m', 'wind_speed_10m', 'mean_sea_level_pressure']\n",
    "o_list = [o, o_we, o_sl, o_sst, o_tp, o_temp, o_wd, o_windd, o_winds, o_ap]\n",
    "ts_list = [ts, ts_we, ts_sl, ts_sst, ts_tp, ts_temp, ts_wd, ts_windd, ts_winds, ts_ap]\n",
    "ts_dict, ts_dict_trend, ts_dict_seasonal, ts_dict_res = {}, {}, {}, {}\n",
    "for ts, o, name in zip(ts_list, o_list, names):\n",
    "    ts_dict[name] = ts\n",
    "    ts_dict_trend[name] = o.trend.Y\n",
    "    ts_dict_seasonal[name] = o.season.Y\n",
    "    ts_dict_res[name] = ts - o.trend.Y - o.season.Y\n",
    "\n",
    "\n",
    "# ts_dict = {'wave_energy': ts_we, 'coastline_position': ts, 'sea_level_anomaly': ts_sl, 'sst': ts_sst} #, 'mean_wave_direction': ts_wd}\n",
    "# ts_dict_trend = {'wave_energy': o_we.trend.Y, 'coastline_position': o.trend.Y, 'sea_level_anomaly': o_sl.trend.Y, 'sst': o_sst.trend.Y} #, 'mean_wave_direction': o_wd.trend.Y}\n",
    "# ts_dict_seasonal = {'wave_energy': o_we.season.Y, 'coastline_position': o.season.Y, 'sea_level_anomaly': o_sl.season.Y, 'sst': o_sst.season.Y} #, 'mean_wave_direction': o_wd.season.Y}\n",
    "# ts_dict_res = {'wave_energy': ts_we - o_we.trend.Y - o_we.season.Y, 'coastline_position': ts - o.trend.Y - o.season.Y, 'sea_level_anomaly': ts_sl - o_sl.trend.Y - o_sl.season.Y, 'sst': ts_sst - o_sst.trend.Y - o_sst.season.Y}#, 'mean_wave_direction': ts_wd - o_wd.trend.Y - o_wd.season.Y}\n",
    "\n",
    "ts_df = pd.DataFrame(ts_dict)\n",
    "ts_df_trend = pd.DataFrame(ts_dict_trend)\n",
    "ts_df_seasonal = pd.DataFrame(ts_dict_seasonal)\n",
    "ts_df_res = pd.DataFrame(ts_dict_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------\n",
      "Evaluating time series connections\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Evaluating connections between time series: wave_energy & coastline_position\n",
      "--- Evaluating correlation at lag 0 ---\n",
      "--- Evaluating cross-correlation ---\n",
      "--- Evaluating correlation at lag 4 ---\n",
      "--- Evaluating correlation at lag -2 ---\n",
      "--- Evaluating cointegration ---\n",
      "No cointegration exists between time series\n",
      "Evaluating connections between time series: wave_energy & sea_level_anomaly\n",
      "--- Evaluating correlation at lag 0 ---\n",
      "--- Evaluating cross-correlation ---\n",
      "--- Evaluating correlation at lag 4 ---\n",
      "--- Evaluating correlation at lag -3 ---\n",
      "--- Evaluating cointegration ---\n",
      "Cointegration exists between time series\n",
      "Evaluating connections between time series: wave_energy & sst\n",
      "--- Evaluating correlation at lag 0 ---\n",
      "--- Evaluating cross-correlation ---\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'first_lag_significant_pos' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dictt \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesConnections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\IslandTimeConnections.py:328\u001b[0m, in \u001b[0;36mTimeSeriesConnections.main\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    325\u001b[0m index_fig \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# Evaluate cross-correlation\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m axs[index_fig], dict_results_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross_correlation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_cross_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_df_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex_fig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m index_fig \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# Plot lagged correlation using ccf\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\IslandTimeConnections.py:112\u001b[0m, in \u001b[0;36mTimeSeriesConnections.evaluate_cross_correlation\u001b[1;34m(self, ts_df_subset, ax)\u001b[0m\n\u001b[0;32m    100\u001b[0m     first_ccf_significant_neg \u001b[38;5;241m=\u001b[39m ccf_significant_neg[np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39mabs(lags_significant_neg))]\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Save results in dictionary\u001b[39;00m\n\u001b[0;32m    103\u001b[0m dict_results_ccf \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlags_ccf\u001b[39m\u001b[38;5;124m'\u001b[39m: lags_ccf,\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccf\u001b[39m\u001b[38;5;124m'\u001b[39m: ccf,\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlags_significant\u001b[39m\u001b[38;5;124m'\u001b[39m: lags_significant,\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccf_significant\u001b[39m\u001b[38;5;124m'\u001b[39m: ccf_significant,\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlags_significant_pos\u001b[39m\u001b[38;5;124m'\u001b[39m: lags_significant_pos,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlags_significant_neg\u001b[39m\u001b[38;5;124m'\u001b[39m: lags_significant_neg,\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccf_significant_pos\u001b[39m\u001b[38;5;124m'\u001b[39m: ccf_significant_pos,\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccf_significant_neg\u001b[39m\u001b[38;5;124m'\u001b[39m: ccf_significant_neg,\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_significant_pos\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mfirst_lag_significant_pos\u001b[49m,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_significant_neg\u001b[39m\u001b[38;5;124m'\u001b[39m: first_lag_significant_neg,\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_ccf_significant_pos\u001b[39m\u001b[38;5;124m'\u001b[39m: first_ccf_significant_pos,\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_ccf_significant_neg\u001b[39m\u001b[38;5;124m'\u001b[39m: first_ccf_significant_neg\n\u001b[0;32m    116\u001b[0m }\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Plot cross-correlation\u001b[39;00m\n\u001b[0;32m    119\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(lags_ccf, ccf, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'first_lag_significant_pos' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "dictt = TimeSeriesConnections(ts_dict).main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "ts1.plot(ax=ax, color='r')\n",
    "ts2.plot(ax=ax2, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t statistic: -3.83 \n",
      " p value: 0.04 \n",
      " critical p values [1%, 5%, 10%] [-4.50158458 -3.88654012 -3.57500991]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import ccf, grangercausalitytests, coint, adfuller\n",
    "\n",
    "t_statistic, p_val, critical_p_val = coint(ts1, ts2, trend='ct', autolag=None, maxlag=3)\n",
    "print(f' t statistic: {np.round(t_statistic, 2)} \\n p value: {np.round(p_val,2)} \\n critical p values [1%, 5%, 10%] {critical_p_val}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansen Test Statistics:\n",
      "[56.70130768 11.12405127]\n",
      "Critical Values (90%, 95%, 99%):\n",
      "[[13.4294 15.4943 19.9349]\n",
      " [ 2.7055  3.8415  6.6349]]\n",
      "Trace statistic for r<=0: 56.70, critical values [13.4294 15.4943 19.9349]\n",
      "Null hypothesis of r<=0 is rejected at the 95% confidence level.\n",
      "Trace statistic for r<=1: 11.12, critical values [2.7055 3.8415 6.6349]\n",
      "Null hypothesis of r<=1 is rejected at the 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "# 4. Johansen Co-integration Test\n",
    "data = pd.concat([ts1, ts2], axis=1)\n",
    "result = coint_johansen(data, det_order=0, k_ar_diff=3)\n",
    "\n",
    "print('Johansen Test Statistics:')\n",
    "print(result.lr1)  # Trace statistic\n",
    "print('Critical Values (90%, 95%, 99%):')\n",
    "print(result.cvt)\n",
    "\n",
    "# Interpret the Johansen test results\n",
    "for i in range(len(result.lr1)):\n",
    "    trace_stat = result.lr1[i]\n",
    "    critical_values = result.cvt[i]\n",
    "    print(f'Trace statistic for r<={i}: {trace_stat:.2f}, critical values {critical_values}')\n",
    "\n",
    "    if trace_stat > critical_values[1]:  # Compare to 95% critical value\n",
    "        print(f'Null hypothesis of r<={i} is rejected at the 95% confidence level.')\n",
    "    else:\n",
    "        print(f'Null hypothesis of r<={i} cannot be rejected at the 95% confidence level.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m coint_vector \u001b[38;5;241m=\u001b[39m coint_vectors[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# First co-integrating vector\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# data = pd.concat([ts1, ts2], axis=1)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate the co-integrating relationship\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m coint_relationship \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[43mdata_s\u001b[49m, coint_vector)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Plot the time series and co-integrating relationship on the same plot\u001b[39;00m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_s' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract co-integrating vectors and compute the co-integrating relationship\n",
    "coint_vectors = result.evec\n",
    "coint_vector = coint_vectors[:, 0]  # First co-integrating vector\n",
    "\n",
    "# data = pd.concat([ts1, ts2], axis=1)\n",
    "\n",
    "# Calculate the co-integrating relationship\n",
    "coint_relationship = np.dot(data_s, coint_vector)\n",
    "\n",
    "# Plot the time series and co-integrating relationship on the same plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(ts1, label='Time Series 1', color='blue')\n",
    "plt.plot(ts2, label='Time Series 2', color='red')\n",
    "plt.plot(data.index, coint_relationship, label='Co-integrating Relationship', color='green', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Time Series and Co-integrating Relationship')\n",
    "plt.show()\n",
    "\n",
    "# Test for stationarity of the residuals\n",
    "residuals = coint_relationship - np.mean(coint_relationship)\n",
    "adf_result = adfuller(residuals)\n",
    "print(f'ADF Statistic: {adf_result[0]}')\n",
    "print(f'p-value: {adf_result[1]}')\n",
    "print(f'Critical Values: {adf_result[4]}')\n",
    "\n",
    "# Plot the residuals of the co-integrating relationship on a separate plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(data.index, residuals, label='Residuals of Co-integrating Relationship', color='purple')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.title('Residuals of Co-integrating Relationship')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: To supress printing the parameers in beast(),      set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast_irreg(),set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast123(),   set extra.printOptions = 0  \n",
      "INFO: To supress warning messages in beast(),            set quiet = 1 \n",
      "INFO: To supress warning messages in beast_irreg(),      set quiet = 1 \n",
      "INFO: To supress warning messages in beast123(),         set extra.quiet = 1  \n",
      "\n",
      "#--------------------------------------------------#\n",
      "#       Brief summary of Input Data                #\n",
      "#--------------------------------------------------#\n",
      "Data Dimension: One signal of length 92\n",
      "IsOrdered     : Yes, ordered in time\n",
      "IsRegular     : Yes, evenly spaced at interval of  0.0833333 year = 1 months = 30.4167 days\n",
      "HasSeasonCmpnt: True  | period = 1 year = 12 months = 365 days. The model 'Y=Trend+Season+Error' is fitted.\n",
      "              : Num_of_DataPoints_per_Period = period/deltaTime = 1/0.0833333 = 12\n",
      "HasOutlierCmpt: False | If true, Y=Trend+Season+Outlier+Error fitted instead of Y=Trend+Season+Error\n",
      "Deseasonalize : False | If true, remove a global seasonal  cmpnt before running BEAST & add it back after BEAST\n",
      "Detrend       : False | If true, remove a global trend component before running BEAST & add it back after BEAST\n",
      "MissingValue  : NaN  flagged as missing values \n",
      "MaxMissingRate: if more than 75% of data is missing, BEAST will skip it.\n",
      "\n",
      "\n",
      "#--------------------------------------------------#\n",
      "#      OPTIONS used in the MCMC inference          #\n",
      "#--------------------------------------------------#\n",
      "\n",
      "#......Start of displaying 'MetaData' ......\n",
      "metadata                =  rb.args() ### or 'lambda: None': just get an empty object### # metadata is used to interpret the input data Y\n",
      "metadata.season         = 'harmonic' # fit a harmonic model to the periodic component\n",
      "metadata.startTime      = 1          # 0001-01-01\n",
      "metadata.deltaTime      = 0.0833333  # 0.0833333 year(s) = 1 month(s) = 30.4167 day(s)\n",
      "metadata.period         = 1          # 1 year(s) = 12 month(s) = 365 day(s) \n",
      "metadata.maxMissingRate = 0.75       # if more than 75% of data is missing, BEAST will skip it.\n",
      "metadata.deseasonalize  = False      # if true,remove a global seasonal cmpnt before running BEAST & add it back later\n",
      "metadata.detrend        = False      # if true,remove a global trend  cmpnt before running BEAST & add it back later\n",
      "#........End of displaying MetaData ........\n",
      "\n",
      "#......Start of displaying 'prior' ......\n",
      "prior                   =  rb.args() ### or 'lambda: None': just get an empty object### # prior is the true model parameters of BEAST\n",
      "prior.seasonMinOrder    = 1          # sorder.minmax[1]: min harmonic order alllowed\n",
      "prior.seasonMaxOrder    = 5          # sorder.minmax[2]: max harmonic order alllowed\n",
      "prior.seasonMinKnotNum  = 0          # scp.minmax[1]   : min num of seasonal chngpts allowed\n",
      "prior.seasonMaxKnotNum  = 10         # scp.minmax[2]   : max num of seasonal chngpts allowed\n",
      "prior.seasonMinSepDist  = 6          # sseg.min        : min seasonal segment length in terms of datapoints\n",
      "prior.seasonLeftMargin  = 6          # sseg.leftmargin : no season chngpts in the first 6 datapoints\n",
      "prior.seasonRightMargin = 6          # sseg.rightmargin: no seoson chngpts in the last 6 datapoints\n",
      "prior.trendMinOrder     = 0          # torder.minmax[1]: min trend polynomial order alllowed\n",
      "prior.trendMaxOrder     = 1          # torder.minmax[2]: max trend polynomial order alllowed\n",
      "prior.trendMinKnotNum   = 0          # tcp.minmax[1]   : min num of chngpts in trend allowed\n",
      "prior.trendMaxKnotNum   = 10         # tcp.minmax[2]   : max num of chngpts in trend allowed\n",
      "prior.trendMinSepDist   = 6          # tseg.min        : min trend segment length in terms of datapoints\n",
      "prior.trendLeftMargin   = 6          # tseg.leftmargin : no trend chngpts in the first 6 datapoints\n",
      "prior.trendRightMargin  = 6          # tseg.rightmargin: no trend chngpts in the last 6 datapoints\n",
      "prior.K_MAX             = 92         # max number of terms in general linear model (relevant only at small values)\n",
      "prior.precValue         = 1.5        # useful mainly when precPriorType='constant'\n",
      "prior.modelPriorType    = 1         \n",
      "prior.precPriorType     = 'componentwise'\n",
      "#......End of displaying prior ......\n",
      "\n",
      "#......Start of displaying 'mcmc' ......\n",
      "mcmc                           =  rb.args() ### or 'lambda: None': just get an empty object### # mcmc is not BEAST parameters but MCMC sampler options\n",
      "mcmc.seed                      = 0          # A nonzero seed to replicate among runs\n",
      "mcmc.samples                   = 8000       # Number of samples saved per chain: the larger, the better\n",
      "mcmc.thinningFactor            = 5          # Thinning the chain: the larger, the better \n",
      "mcmc.burnin                    = 200        # Number of initial samples discarded: the larger, the better\n",
      "mcmc.chainNumber               = 3          # Number of chains: the larger, the better\n",
      "mcmc.maxMoveStepSize           = 6          # Max step of jumping from current changepoint: No need to change\n",
      "mcmc.trendResamplingOrderProb  = 0.1        # Proposal probability of sampling trend polynominal order \n",
      "mcmc.seasonResamplingOrderProb = 0.17       # Proposal probability of sampling seasoanl order \n",
      "mcmc.credIntervalAlphaLevel    = 0.95       # The alphal level for Credible Intervals\n",
      "# Total number of models randomly visited in BEAST is (burnin+sampples*thinFactor)*chainNumber=120600\n",
      "#......End of displaying mcmc ......\n",
      "\n",
      "#......Start of displaying 'extra' ......\n",
      "extra                      =  rb.args() ### or 'lambda: None': just get an empty object### # extra is used to configure output/computing options\n",
      "extra.dumpInputData        = True  # if true, dump a copy of the input data as o.data \n",
      "extra.whichOutputDimIsTime = 1     # 1,2 or 3; which dim of the result is time; used for a 2D/3D input Y\n",
      "extra.computeCredible      = True  # if true, compute  credibiel interval of estimated Y (e.g., o.trend.CI)\n",
      "extra.fastCIComputation    = True  # if true, do not sort but approximiate CI \n",
      "extra.computeSeasonOrder   = True  # if true, dump the estimated time-varying seasonal order: o.season.order \n",
      "extra.computeTrendOrder    = True  # if true, dump the estimated trend polynomial order \n",
      "extra.computeSeasonChngpt  = True  # if true, dump the seasoanl changepoints (scp) in the output \n",
      "extra.computeTrendChngpt   = True  # if true, dump the trend changepoints (tcp) in the output \n",
      "extra.computeSeasonAmp     = False #  compute time-varying seasonal mangitude if season=harmonic  \n",
      "extra.computeTrendSlope    = True  # if true, dump the time-varying slope in trend\n",
      "extra.tallyPosNegSeasonJump= False # differentiate postive/negative jumps at scp\n",
      "extra.tallyPosNegTrendJump = False # differentiate postive/negative jumps at tcp\n",
      "extra.tallyIncDecTrendJump = False # differentiate increased/decreased slopes at tcp\n",
      "extra.printProgressBar     = True  # if true, show an ascii progressbar\n",
      "extra.printOptions         = True  # if true, print the option of the BEAST run\n",
      "extra.consoleWidth         = 85    # an integer specifying the console width for printing\n",
      "extra.numThreadsPerCPU     = 2     # each cpu core spawns 2 concurrent threads (for beast123())\n",
      "extra.numParThreads        = 0     # total number of threads (for beast123() only)\n",
      "#......End of displaying extra ......\n",
      "\n",
      "\\Progress:100.0% done[==============================================================]\n",
      "\n",
      "INFO: To supress printing the parameers in beast(),      set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast_irreg(),set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast123(),   set extra.printOptions = 0  \n",
      "INFO: To supress warning messages in beast(),            set quiet = 1 \n",
      "INFO: To supress warning messages in beast_irreg(),      set quiet = 1 \n",
      "INFO: To supress warning messages in beast123(),         set extra.quiet = 1  \n",
      "\n",
      "#--------------------------------------------------#\n",
      "#       Brief summary of Input Data                #\n",
      "#--------------------------------------------------#\n",
      "Data Dimension: One signal of length 92\n",
      "IsOrdered     : Yes, ordered in time\n",
      "IsRegular     : Yes, evenly spaced at interval of  0.0833333 year = 1 months = 30.4167 days\n",
      "HasSeasonCmpnt: True  | period = 1 year = 12 months = 365 days. The model 'Y=Trend+Season+Error' is fitted.\n",
      "              : Num_of_DataPoints_per_Period = period/deltaTime = 1/0.0833333 = 12\n",
      "HasOutlierCmpt: False | If true, Y=Trend+Season+Outlier+Error fitted instead of Y=Trend+Season+Error\n",
      "Deseasonalize : False | If true, remove a global seasonal  cmpnt before running BEAST & add it back after BEAST\n",
      "Detrend       : False | If true, remove a global trend component before running BEAST & add it back after BEAST\n",
      "MissingValue  : NaN  flagged as missing values \n",
      "MaxMissingRate: if more than 75% of data is missing, BEAST will skip it.\n",
      "\n",
      "\n",
      "#--------------------------------------------------#\n",
      "#      OPTIONS used in the MCMC inference          #\n",
      "#--------------------------------------------------#\n",
      "\n",
      "#......Start of displaying 'MetaData' ......\n",
      "metadata                =  rb.args() ### or 'lambda: None': just get an empty object### # metadata is used to interpret the input data Y\n",
      "metadata.season         = 'harmonic' # fit a harmonic model to the periodic component\n",
      "metadata.startTime      = 1          # 0001-01-01\n",
      "metadata.deltaTime      = 0.0833333  # 0.0833333 year(s) = 1 month(s) = 30.4167 day(s)\n",
      "metadata.period         = 1          # 1 year(s) = 12 month(s) = 365 day(s) \n",
      "metadata.maxMissingRate = 0.75       # if more than 75% of data is missing, BEAST will skip it.\n",
      "metadata.deseasonalize  = False      # if true,remove a global seasonal cmpnt before running BEAST & add it back later\n",
      "metadata.detrend        = False      # if true,remove a global trend  cmpnt before running BEAST & add it back later\n",
      "#........End of displaying MetaData ........\n",
      "\n",
      "#......Start of displaying 'prior' ......\n",
      "prior                   =  rb.args() ### or 'lambda: None': just get an empty object### # prior is the true model parameters of BEAST\n",
      "prior.seasonMinOrder    = 1          # sorder.minmax[1]: min harmonic order alllowed\n",
      "prior.seasonMaxOrder    = 5          # sorder.minmax[2]: max harmonic order alllowed\n",
      "prior.seasonMinKnotNum  = 0          # scp.minmax[1]   : min num of seasonal chngpts allowed\n",
      "prior.seasonMaxKnotNum  = 10         # scp.minmax[2]   : max num of seasonal chngpts allowed\n",
      "prior.seasonMinSepDist  = 6          # sseg.min        : min seasonal segment length in terms of datapoints\n",
      "prior.seasonLeftMargin  = 6          # sseg.leftmargin : no season chngpts in the first 6 datapoints\n",
      "prior.seasonRightMargin = 6          # sseg.rightmargin: no seoson chngpts in the last 6 datapoints\n",
      "prior.trendMinOrder     = 0          # torder.minmax[1]: min trend polynomial order alllowed\n",
      "prior.trendMaxOrder     = 1          # torder.minmax[2]: max trend polynomial order alllowed\n",
      "prior.trendMinKnotNum   = 0          # tcp.minmax[1]   : min num of chngpts in trend allowed\n",
      "prior.trendMaxKnotNum   = 10         # tcp.minmax[2]   : max num of chngpts in trend allowed\n",
      "prior.trendMinSepDist   = 6          # tseg.min        : min trend segment length in terms of datapoints\n",
      "prior.trendLeftMargin   = 6          # tseg.leftmargin : no trend chngpts in the first 6 datapoints\n",
      "prior.trendRightMargin  = 6          # tseg.rightmargin: no trend chngpts in the last 6 datapoints\n",
      "prior.K_MAX             = 92         # max number of terms in general linear model (relevant only at small values)\n",
      "prior.precValue         = 1.5        # useful mainly when precPriorType='constant'\n",
      "prior.modelPriorType    = 1         \n",
      "prior.precPriorType     = 'componentwise'\n",
      "#......End of displaying prior ......\n",
      "\n",
      "#......Start of displaying 'mcmc' ......\n",
      "mcmc                           =  rb.args() ### or 'lambda: None': just get an empty object### # mcmc is not BEAST parameters but MCMC sampler options\n",
      "mcmc.seed                      = 0          # A nonzero seed to replicate among runs\n",
      "mcmc.samples                   = 8000       # Number of samples saved per chain: the larger, the better\n",
      "mcmc.thinningFactor            = 5          # Thinning the chain: the larger, the better \n",
      "mcmc.burnin                    = 200        # Number of initial samples discarded: the larger, the better\n",
      "mcmc.chainNumber               = 3          # Number of chains: the larger, the better\n",
      "mcmc.maxMoveStepSize           = 6          # Max step of jumping from current changepoint: No need to change\n",
      "mcmc.trendResamplingOrderProb  = 0.1        # Proposal probability of sampling trend polynominal order \n",
      "mcmc.seasonResamplingOrderProb = 0.17       # Proposal probability of sampling seasoanl order \n",
      "mcmc.credIntervalAlphaLevel    = 0.95       # The alphal level for Credible Intervals\n",
      "# Total number of models randomly visited in BEAST is (burnin+sampples*thinFactor)*chainNumber=120600\n",
      "#......End of displaying mcmc ......\n",
      "\n",
      "#......Start of displaying 'extra' ......\n",
      "extra                      =  rb.args() ### or 'lambda: None': just get an empty object### # extra is used to configure output/computing options\n",
      "extra.dumpInputData        = True  # if true, dump a copy of the input data as o.data \n",
      "extra.whichOutputDimIsTime = 1     # 1,2 or 3; which dim of the result is time; used for a 2D/3D input Y\n",
      "extra.computeCredible      = True  # if true, compute  credibiel interval of estimated Y (e.g., o.trend.CI)\n",
      "extra.fastCIComputation    = True  # if true, do not sort but approximiate CI \n",
      "extra.computeSeasonOrder   = True  # if true, dump the estimated time-varying seasonal order: o.season.order \n",
      "extra.computeTrendOrder    = True  # if true, dump the estimated trend polynomial order \n",
      "extra.computeSeasonChngpt  = True  # if true, dump the seasoanl changepoints (scp) in the output \n",
      "extra.computeTrendChngpt   = True  # if true, dump the trend changepoints (tcp) in the output \n",
      "extra.computeSeasonAmp     = False #  compute time-varying seasonal mangitude if season=harmonic  \n",
      "extra.computeTrendSlope    = True  # if true, dump the time-varying slope in trend\n",
      "extra.tallyPosNegSeasonJump= False # differentiate postive/negative jumps at scp\n",
      "extra.tallyPosNegTrendJump = False # differentiate postive/negative jumps at tcp\n",
      "extra.tallyIncDecTrendJump = False # differentiate increased/decreased slopes at tcp\n",
      "extra.printProgressBar     = True  # if true, show an ascii progressbar\n",
      "extra.printOptions         = True  # if true, print the option of the BEAST run\n",
      "extra.consoleWidth         = 85    # an integer specifying the console width for printing\n",
      "extra.numThreadsPerCPU     = 2     # each cpu core spawns 2 concurrent threads (for beast123())\n",
      "extra.numParThreads        = 0     # total number of threads (for beast123() only)\n",
      "#......End of displaying extra ......\n",
      "\n",
      "|Progress:100.0% done[==============================================================]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "# import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "import Rbeast as rb\n",
    "\n",
    "# Plot original time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(data['coastline_position_transect_2_waterline'], label='Time Series 1')\n",
    "plt.plot(data['wave_energy_of_combined_wind_waves_and_swell'], label='Time Series 2')\n",
    "plt.legend()\n",
    "plt.title('Original Time Series with Seasonality')\n",
    "plt.show()\n",
    "\n",
    "# Seasonal Decomposition\n",
    "# decomposition_ts1 = seasonal_decompose(data['coastline_position_transect_2_waterline'], model='additive', period=12)\n",
    "# decomposition_ts2 = seasonal_decompose(data['wave_energy_of_combined_wind_waves_and_swell'], model='additive', period=12)\n",
    "decomposition_ts1 = rb.beast(data['coastline_position_transect_2_waterline'], period='1 year', deltat='1/12 year')\n",
    "decomposition_ts2 = rb.beast(data['wave_energy_of_combined_wind_waves_and_swell'], period='1 year', deltat='1/12 year')\n",
    "rb.plot(decomposition_ts2)\n",
    "\n",
    "plot_acf(data['coastline_position_transect_2_waterline'])\n",
    "\n",
    "# # Plot seasonal decomposition\n",
    "# plt.figure(figsize=(14, 12))\n",
    "\n",
    "# plt.subplot(2, 3, 1)\n",
    "# plt.plot(data['coastline_position_transect_2_waterline'], label='Time Series 1')\n",
    "# plt.legend()\n",
    "# plt.title('Time Series 1')\n",
    "\n",
    "# plt.subplot(2, 3, 2)\n",
    "# plt.plot(decomposition_ts1.trend.dropna(), label='Trend Component')\n",
    "# plt.legend()\n",
    "# plt.title('Trend Component of TS1')\n",
    "\n",
    "# plt.subplot(2, 3, 3)\n",
    "# plt.plot(decomposition_ts1.seasonal, label='Seasonal Component')\n",
    "# plt.legend()\n",
    "# plt.title('Seasonal Component of TS1')\n",
    "\n",
    "# plt.subplot(2, 3, 4)\n",
    "# plt.plot(data['wave_energy_of_combined_wind_waves_and_swell'], label='Time Series 2')\n",
    "# plt.legend()\n",
    "# plt.title('Time Series 2')\n",
    "\n",
    "# plt.subplot(2, 3, 5)\n",
    "# plt.plot(decomposition_ts2.trend.dropna(), label='Trend Component')\n",
    "# plt.legend()\n",
    "# plt.title('Trend Component of TS2')\n",
    "\n",
    "# plt.subplot(2, 3, 6)\n",
    "# plt.plot(decomposition_ts2.seasonal, label='Seasonal Component')\n",
    "# plt.legend()\n",
    "# plt.title('Seasonal Component of TS2')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Remove seasonality by subtracting seasonal component\n",
    "# data_deseasonalized = pd.DataFrame({\n",
    "#     'ts1_deseasonalized': data['coastline_position_transect_2_waterline'] - decomposition_ts1.seasonal,\n",
    "#     'ts2_deseasonalized': data['wave_energy_of_combined_wind_waves_and_swell'] - decomposition_ts2.seasonal\n",
    "# })\n",
    "\n",
    "# # Perform Johansen test on deseasonalized data\n",
    "# result_deseasonalized = coint_johansen(data_deseasonalized, det_order=0, k_ar_diff=3)\n",
    "\n",
    "# # Extract co-integrating vectors and compute the co-integrating relationship\n",
    "# coint_vectors_deseasonalized = result_deseasonalized.evec\n",
    "# coint_vector_deseasonalized = coint_vectors_deseasonalized[:, 0]  # First co-integrating vector\n",
    "\n",
    "# # Calculate the co-integrating relationship\n",
    "# coint_relationship_deseasonalized = np.dot(data_deseasonalized, coint_vector_deseasonalized)\n",
    "\n",
    "# # Plot deseasonalized time series and co-integrating relationship\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# # plt.plot(data_deseasonalized['ts1_deseasonalized'], label='Deseasonalized Time Series 1', color='blue')\n",
    "# # plt.plot(data_deseasonalized['ts2_deseasonalized'], label='Deseasonalized Time Series 2', color='red')\n",
    "# plt.plot(data.index, coint_relationship_deseasonalized, label='Co-integrating Relationship', color='green', linestyle='--')\n",
    "# plt.legend()\n",
    "# plt.title('Deseasonalized Time Series and Co-integrating Relationship')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s = pd.DataFrame({'ts1_s': decomposition_ts1.season.Y, 'ts2_s': decomposition_ts2.season.Y}, index=ts1.index)\n",
    "data_res = pd.DataFrame({'ts1_res': ts1 - decomposition_ts1.trend.Y - decomposition_ts1.season.Y, 'ts2_res': ts2 - decomposition_ts2.trend.Y - decomposition_ts2.season.Y}, index=ts1.index)\n",
    "data_t = pd.DataFrame({'ts1_t': decomposition_ts1.trend.Y, 'ts2_t': decomposition_ts2.trend.Y}, index=ts1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21a6a08b950>]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ts1.index, decomposition_ts2.trend.Y)\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(ts1.index, decomposition_ts1.trend.Y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 9 Axes>,\n",
       " array([<Axes: xlabel='[]', ylabel='Y'>,\n",
       "        <Axes: xlabel='[]', ylabel='season'>,\n",
       "        <Axes: xlabel='[]', ylabel='Pr(scp)'>,\n",
       "        <Axes: xlabel='[]', ylabel='sOrder'>,\n",
       "        <Axes: xlabel='[]', ylabel='trend'>,\n",
       "        <Axes: xlabel='[]', ylabel='Pr(tcp)'>,\n",
       "        <Axes: xlabel='[]', ylabel='tOrder'>,\n",
       "        <Axes: xlabel='[]', ylabel='slpsgn'>,\n",
       "        <Axes: xlabel='time', ylabel='error'>], dtype=object))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.plot(decomposition_ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansen Test Statistics:\n",
      "[10.22817199  2.17772393]\n",
      "Critical Values (90%, 95%, 99%):\n",
      "[[13.4294 15.4943 19.9349]\n",
      " [ 2.7055  3.8415  6.6349]]\n",
      "Trace statistic for r<=0: 10.23, critical values [13.4294 15.4943 19.9349]\n",
      "Null hypothesis of r<=0 cannot be rejected at the 95% confidence level.\n",
      "Trace statistic for r<=1: 2.18, critical values [2.7055 3.8415 6.6349]\n",
      "Null hypothesis of r<=1 cannot be rejected at the 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "# 4. Johansen Co-integration Test\n",
    "result = coint_johansen(data_t, det_order=0, k_ar_diff=1)\n",
    "\n",
    "print('Johansen Test Statistics:')\n",
    "print(result.lr1)  # Trace statistic\n",
    "print('Critical Values (90%, 95%, 99%):')\n",
    "print(result.cvt)\n",
    "\n",
    "\n",
    "# Interpret the Johansen test results\n",
    "for i in range(len(result.lr1)):\n",
    "    trace_stat = result.lr1[i]\n",
    "    critical_values = result.cvt[i]\n",
    "    print(f'Trace statistic for r<={i}: {trace_stat:.2f}, critical values {critical_values}')\n",
    "\n",
    "    if trace_stat > critical_values[1]:  # Compare to 95% critical value\n",
    "        print(f'Null hypothesis of r<={i} is rejected at the 95% confidence level.')\n",
    "    else:\n",
    "        print(f'Null hypothesis of r<={i} cannot be rejected at the 95% confidence level.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal inference and discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt    \n",
    "## use `%matplotlib notebook` for interactive figures\n",
    "# plt.style.use('ggplot')\n",
    "import sklearn\n",
    "\n",
    "import tigramite\n",
    "from tigramite import data_processing as pp\n",
    "from tigramite.toymodels import structural_causal_processes as toys\n",
    "\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.lpcmci import LPCMCI\n",
    "\n",
    "from tigramite.independence_tests.parcorr import ParCorr\n",
    "from tigramite.independence_tests.robust_parcorr import RobustParCorr\n",
    "from tigramite.independence_tests.parcorr_wls import ParCorrWLS \n",
    "from tigramite.independence_tests.gpdc import GPDC\n",
    "from tigramite.independence_tests.cmiknn import CMIknn\n",
    "from tigramite.independence_tests.cmisymb import CMIsymb\n",
    "from tigramite.independence_tests.gsquared import Gsquared\n",
    "from tigramite.independence_tests.regressionCI import RegressionCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 10 Axes>,\n",
       " array([<Axes: ylabel='coastline_position'>, <Axes: ylabel='wave_energy'>,\n",
       "        <Axes: ylabel='sea_level_anomaly'>, <Axes: ylabel='sst'>,\n",
       "        <Axes: ylabel='total_precipitation'>,\n",
       "        <Axes: ylabel='dewpoint_temperature'>,\n",
       "        <Axes: ylabel='mean_wave_direction'>,\n",
       "        <Axes: ylabel='wind_direction_10m'>,\n",
       "        <Axes: ylabel='wind_speed_10m'>,\n",
       "        <Axes: ylabel='mean_sea_level_pressure'>], dtype=object))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize dataframe object, specify time axis and variable names\n",
    "var_names = names\n",
    "dataframe = pp.DataFrame(ts_df.values, \n",
    "                         datatime = ts_df.index, \n",
    "                         var_names=var_names)\n",
    "\n",
    "tp.plot_timeseries(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##\n",
      "## Estimating lagged dependencies \n",
      "##\n",
      "\n",
      "Parameters:\n",
      "\n",
      "independence test = par_corr\n",
      "tau_min = 0\n",
      "tau_max = 13\n"
     ]
    }
   ],
   "source": [
    "parcorr = ParCorr(significance='analytic')\n",
    "pcmci = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    verbosity=1)\n",
    "correlations = pcmci.get_lagged_dependencies(tau_max=13, val_only=True)['val_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_lags = np.argmax(np.abs(correlations), axis=2)\n",
    "tp.plot_scatterplots(dataframe=dataframe, add_scatterplot_args={'matrix_lags':matrix_lags}); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_densityplots(dataframe=dataframe, add_densityplot_args={'matrix_lags':matrix_lags})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##\n",
      "## Estimating lagged dependencies \n",
      "##\n",
      "\n",
      "Parameters:\n",
      "\n",
      "independence test = par_corr\n",
      "tau_min = 0\n",
      "tau_max = 13\n"
     ]
    }
   ],
   "source": [
    "parcorr = ParCorr(significance='analytic')\n",
    "pcmci = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    verbosity=1)\n",
    "\n",
    "correlations = pcmci.get_lagged_dependencies(tau_max=13, val_only=True)['val_matrix']\n",
    "lag_func_matrix = tp.plot_lagfuncs(val_matrix=correlations, setup_args={'var_names':var_names, \n",
    "                                    'x_base':5, 'y_base':.5}); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##\n",
      "## Step 1: PC1 algorithm for selecting lagged conditions\n",
      "##\n",
      "\n",
      "Parameters:\n",
      "independence test = par_corr\n",
      "tau_min = 1\n",
      "tau_max = 12\n",
      "pc_alpha = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "max_conds_dim = None\n",
      "max_combinations = 1\n",
      "\n",
      "\n",
      "\n",
      "## Resulting lagged parent (super)sets:\n",
      "\n",
      "    Variable coastline_position has 10 link(s):\n",
      "    [pc_alpha = 0.5]\n",
      "        (coastline_position -1): max_pval = 0.00249, |min_val| =  0.393\n",
      "        (mean_wave_direction -1): max_pval = 0.05515, |min_val| =  0.250\n",
      "        (mean_wave_direction -2): max_pval = 0.19077, |min_val| =  0.164\n",
      "        (total_precipitation -12): max_pval = 0.22805, |min_val| =  0.153\n",
      "        (wind_direction_10m -5): max_pval = 0.22736, |min_val| =  0.148\n",
      "        (mean_wave_direction -10): max_pval = 0.24553, |min_val| =  0.147\n",
      "        (coastline_position -4): max_pval = 0.42312, |min_val| =  0.099\n",
      "        (wind_direction_10m -6): max_pval = 0.45706, |min_val| =  0.098\n",
      "        (coastline_position -2): max_pval = 0.48467, |min_val| =  0.087\n",
      "        (wave_energy -11): max_pval = 0.49342, |min_val| =  0.084\n",
      "\n",
      "    Variable wave_energy has 8 link(s):\n",
      "    [pc_alpha = 0.5]\n",
      "        (wave_energy -12): max_pval = 0.00050, |min_val| =  0.439\n",
      "        (sst -2): max_pval = 0.01711, |min_val| =  0.312\n",
      "        (mean_wave_direction -5): max_pval = 0.13913, |min_val| =  0.193\n",
      "        (total_precipitation -9): max_pval = 0.13851, |min_val| =  0.186\n",
      "        (total_precipitation -4): max_pval = 0.29597, |min_val| =  0.135\n",
      "        (dewpoint_temperature -1): max_pval = 0.33160, |min_val| =  0.129\n",
      "        (mean_wave_direction -7): max_pval = 0.43550, |min_val| =  0.100\n",
      "        (wind_direction_10m -9): max_pval = 0.45413, |min_val| =  0.094\n",
      "\n",
      "    Variable sea_level_anomaly has 11 link(s):\n",
      "    [pc_alpha = 0.5]\n",
      "        (sea_level_anomaly -1): max_pval = 0.00003, |min_val| =  0.483\n",
      "        (wind_speed_10m -4): max_pval = 0.02165, |min_val| =  0.280\n",
      "        (total_precipitation -8): max_pval = 0.03555, |min_val| =  0.270\n",
      "        (dewpoint_temperature -8): max_pval = 0.05763, |min_val| =  0.251\n",
      "        (sst -8): max_pval = 0.06607, |min_val| =  0.242\n",
      "        (wind_direction_10m -8): max_pval = 0.20741, |min_val| =  0.158\n",
      "        (total_precipitation -12): max_pval = 0.22606, |min_val| =  0.153\n",
      "        (wind_direction_10m -10): max_pval = 0.30404, |min_val| =  0.129\n",
      "        (wind_direction_10m -1): max_pval = 0.38400, |min_val| =  0.108\n",
      "        (sea_level_anomaly -12): max_pval = 0.48167, |min_val| =  0.090\n",
      "        (total_precipitation -9): max_pval = 0.47456, |min_val| =  0.088\n",
      "\n",
      "    Variable sst has 8 link(s):\n",
      "    [pc_alpha = 0.4]\n",
      "        (sea_level_anomaly -3): max_pval = 0.01081, |min_val| =  0.312\n",
      "        (total_precipitation -12): max_pval = 0.01697, |min_val| =  0.289\n",
      "        (wind_speed_10m -1): max_pval = 0.12149, |min_val| =  0.190\n",
      "        (coastline_position -2): max_pval = 0.13333, |min_val| =  0.187\n",
      "        (sea_level_anomaly -6): max_pval = 0.15976, |min_val| =  0.174\n",
      "        (wind_speed_10m -11): max_pval = 0.21142, |min_val| =  0.157\n",
      "        (wave_energy -9): max_pval = 0.24408, |min_val| =  0.150\n",
      "        (total_precipitation -9): max_pval = 0.36094, |min_val| =  0.116\n",
      "\n",
      "    Variable total_precipitation has 9 link(s):\n",
      "    [pc_alpha = 0.4]\n",
      "        (sst -1): max_pval = 0.00824, |min_val| =  0.334\n",
      "        (wind_direction_10m -3): max_pval = 0.02014, |min_val| =  0.290\n",
      "        (total_precipitation -12): max_pval = 0.16465, |min_val| =  0.177\n",
      "        (sst -6): max_pval = 0.16447, |min_val| =  0.176\n",
      "        (total_precipitation -3): max_pval = 0.19281, |min_val| =  0.162\n",
      "        (coastline_position -12): max_pval = 0.21166, |min_val| =  0.158\n",
      "        (wind_speed_10m -2): max_pval = 0.20313, |min_val| =  0.157\n",
      "        (wind_direction_10m -9): max_pval = 0.28187, |min_val| =  0.133\n",
      "        (total_precipitation -2): max_pval = 0.37960, |min_val| =  0.108\n",
      "\n",
      "    Variable dewpoint_temperature has 11 link(s):\n",
      "    [pc_alpha = 0.4]\n",
      "        (wave_energy -6): max_pval = 0.01455, |min_val| =  0.302\n",
      "        (sst -1): max_pval = 0.01904, |min_val| =  0.288\n",
      "        (mean_wave_direction -4): max_pval = 0.04166, |min_val| =  0.260\n",
      "        (wind_speed_10m -4): max_pval = 0.05871, |min_val| =  0.236\n",
      "        (sst -2): max_pval = 0.18867, |min_val| =  0.165\n",
      "        (sea_level_anomaly -7): max_pval = 0.22473, |min_val| =  0.161\n",
      "        (dewpoint_temperature -8): max_pval = 0.22029, |min_val| =  0.152\n",
      "        (sst -6): max_pval = 0.31985, |min_val| =  0.134\n",
      "        (wave_energy -7): max_pval = 0.33488, |min_val| =  0.128\n",
      "        (wind_speed_10m -3): max_pval = 0.35840, |min_val| =  0.116\n",
      "        (coastline_position -8): max_pval = 0.39388, |min_val| =  0.115\n",
      "\n",
      "    Variable mean_wave_direction has 10 link(s):\n",
      "    [pc_alpha = 0.5]\n",
      "        (mean_wave_direction -12): max_pval = 0.01901, |min_val| =  0.305\n",
      "        (dewpoint_temperature -7): max_pval = 0.01326, |min_val| =  0.301\n",
      "        (dewpoint_temperature -12): max_pval = 0.02991, |min_val| =  0.283\n",
      "        (mean_wave_direction -2): max_pval = 0.12719, |min_val| =  0.196\n",
      "        (sea_level_anomaly -3): max_pval = 0.21167, |min_val| =  0.160\n",
      "        (wave_energy -7): max_pval = 0.29109, |min_val| =  0.139\n",
      "        (sst -12): max_pval = 0.27259, |min_val| =  0.137\n",
      "        (wind_speed_10m -1): max_pval = 0.29717, |min_val| =  0.133\n",
      "        (wind_direction_10m -8): max_pval = 0.41938, |min_val| =  0.101\n",
      "        (sea_level_anomaly -9): max_pval = 0.48551, |min_val| =  0.091\n",
      "\n",
      "    Variable wind_direction_10m has 5 link(s):\n",
      "    [pc_alpha = 0.3]\n",
      "        (sst -1): max_pval = 0.03512, |min_val| =  0.258\n",
      "        (total_precipitation -6): max_pval = 0.03659, |min_val| =  0.254\n",
      "        (wind_direction_10m -10): max_pval = 0.15574, |min_val| =  0.181\n",
      "        (sea_level_anomaly -1): max_pval = 0.15326, |min_val| =  0.181\n",
      "        (wind_speed_10m -7): max_pval = 0.20855, |min_val| =  0.159\n",
      "\n",
      "    Variable wind_speed_10m has 5 link(s):\n",
      "    [pc_alpha = 0.2]\n",
      "        (wind_direction_10m -5): max_pval = 0.06082, |min_val| =  0.232\n",
      "        (wave_energy -12): max_pval = 0.06540, |min_val| =  0.226\n",
      "        (wind_speed_10m -1): max_pval = 0.16108, |min_val| =  0.177\n",
      "        (wind_speed_10m -6): max_pval = 0.16173, |min_val| =  0.177\n",
      "        (mean_wave_direction -10): max_pval = 0.16525, |min_val| =  0.171\n",
      "\n",
      "##\n",
      "## Step 2: MCI algorithm\n",
      "##\n",
      "\n",
      "Parameters:\n",
      "\n",
      "independence test = par_corr\n",
      "tau_min = 0\n",
      "tau_max = 12\n",
      "max_conds_py = None\n",
      "max_conds_px = None\n",
      "\n",
      "## Significant links at alpha = 0.1:\n",
      "\n",
      "    Variable coastline_position has 17 link(s):\n",
      "        (sea_level_anomaly -8): pval = 0.01521 | val =  0.352\n",
      "        (dewpoint_temperature  0): pval = 0.02122 | val =  0.335 | unoriented link\n",
      "        (coastline_position -1): pval = 0.01625 | val =  0.332\n",
      "        (wind_speed_10m -9): pval = 0.01698 | val = -0.327\n",
      "        (wave_energy -1): pval = 0.02184 | val = -0.324\n",
      "        (wave_energy  0): pval = 0.03082 | val =  0.306 | unoriented link\n",
      "        (mean_wave_direction -2): pval = 0.03736 | val = -0.298\n",
      "        (wind_speed_10m -11): pval = 0.03416 | val =  0.292\n",
      "        (dewpoint_temperature -8): pval = 0.05052 | val = -0.287\n",
      "        (total_precipitation -12): pval = 0.04429 | val = -0.286\n",
      "        (mean_wave_direction -1): pval = 0.05147 | val = -0.280\n",
      "        (wind_direction_10m  0): pval = 0.04865 | val = -0.272 | unoriented link\n",
      "        (wave_energy -11): pval = 0.05344 | val = -0.272\n",
      "        (wave_energy -6): pval = 0.06481 | val =  0.263\n",
      "        (sst -7): pval = 0.07441 | val =  0.255\n",
      "        (wind_speed_10m -7): pval = 0.08682 | val =  0.238\n",
      "        (wind_direction_10m -5): pval = 0.08596 | val = -0.236\n",
      "\n",
      "    Variable wave_energy has 14 link(s):\n",
      "        (total_precipitation  0): pval = 0.01752 | val =  0.328 | unoriented link\n",
      "        (total_precipitation -9): pval = 0.02132 | val =  0.319\n",
      "        (wind_direction_10m -9): pval = 0.01866 | val =  0.313\n",
      "        (coastline_position  0): pval = 0.03082 | val =  0.306 | unoriented link\n",
      "        (wind_direction_10m -1): pval = 0.02243 | val =  0.305\n",
      "        (sst -9): pval = 0.04240 | val =  0.283\n",
      "        (coastline_position -2): pval = 0.04688 | val =  0.282\n",
      "        (wind_speed_10m -8): pval = 0.03961 | val =  0.278\n",
      "        (wave_energy -11): pval = 0.05266 | val = -0.270\n",
      "        (wave_energy -12): pval = 0.05248 | val =  0.268\n",
      "        (wind_direction_10m -12): pval = 0.05572 | val = -0.260\n",
      "        (mean_wave_direction -7): pval = 0.07922 | val = -0.248\n",
      "        (coastline_position -6): pval = 0.08025 | val =  0.247\n",
      "        (wind_speed_10m  0): pval = 0.07887 | val =  0.237 | unoriented link\n",
      "\n",
      "    Variable sea_level_anomaly has 11 link(s):\n",
      "        (sea_level_anomaly -1): pval = 0.00010 | val =  0.532\n",
      "        (wind_direction_10m -8): pval = 0.00995 | val = -0.351\n",
      "        (total_precipitation -8): pval = 0.02695 | val =  0.316\n",
      "        (sst -8): pval = 0.03035 | val =  0.307\n",
      "        (total_precipitation -3): pval = 0.04103 | val = -0.296\n",
      "        (dewpoint_temperature -4): pval = 0.05236 | val =  0.288\n",
      "        (dewpoint_temperature -12): pval = 0.05250 | val = -0.288\n",
      "        (coastline_position -1): pval = 0.06641 | val =  0.270\n",
      "        (wind_speed_10m  0): pval = 0.05797 | val = -0.265 | unoriented link\n",
      "        (wind_speed_10m -4): pval = 0.06319 | val = -0.257\n",
      "        (dewpoint_temperature  0): pval = 0.08474 | val = -0.251 | unoriented link\n",
      "\n",
      "    Variable sst has 14 link(s):\n",
      "        (dewpoint_temperature -10): pval = 0.00061 | val = -0.472\n",
      "        (wave_energy -9): pval = 0.00054 | val =  0.459\n",
      "        (sea_level_anomaly -3): pval = 0.00321 | val =  0.405\n",
      "        (wind_speed_10m -1): pval = 0.00440 | val = -0.375\n",
      "        (coastline_position -5): pval = 0.00770 | val =  0.373\n",
      "        (total_precipitation -12): pval = 0.00708 | val =  0.369\n",
      "        (sea_level_anomaly -6): pval = 0.01045 | val = -0.359\n",
      "        (wind_speed_10m  0): pval = 0.00983 | val = -0.342 | unoriented link\n",
      "        (wind_direction_10m -11): pval = 0.01843 | val = -0.317\n",
      "        (wave_energy -11): pval = 0.02340 | val =  0.314\n",
      "        (sst -3): pval = 0.02529 | val = -0.304\n",
      "        (mean_wave_direction -10): pval = 0.06180 | val = -0.263\n",
      "        (mean_wave_direction -7): pval = 0.06532 | val = -0.263\n",
      "        (wave_energy -6): pval = 0.07345 | val = -0.250\n",
      "\n",
      "    Variable total_precipitation has 18 link(s):\n",
      "        (mean_wave_direction -4): pval = 0.00874 | val =  0.371\n",
      "        (coastline_position -2): pval = 0.01571 | val =  0.343\n",
      "        (coastline_position -1): pval = 0.02090 | val = -0.329\n",
      "        (wave_energy  0): pval = 0.01752 | val =  0.328 | unoriented link\n",
      "        (wind_speed_10m -2): pval = 0.02561 | val = -0.301\n",
      "        (wave_energy -9): pval = 0.03297 | val =  0.299\n",
      "        (total_precipitation -1): pval = 0.03718 | val = -0.293\n",
      "        (dewpoint_temperature -7): pval = 0.05504 | val =  0.279\n",
      "        (sst -11): pval = 0.05468 | val =  0.271\n",
      "        (total_precipitation -2): pval = 0.06282 | val =  0.262\n",
      "        (dewpoint_temperature -6): pval = 0.07359 | val = -0.261\n",
      "        (wind_direction_10m -3): pval = 0.05725 | val = -0.258\n",
      "        (sst -12): pval = 0.06935 | val =  0.256\n",
      "        (sea_level_anomaly -10): pval = 0.08065 | val =  0.255\n",
      "        (dewpoint_temperature -11): pval = 0.08135 | val =  0.254\n",
      "        (total_precipitation -3): pval = 0.08868 | val = -0.241\n",
      "        (sst -1): pval = 0.09197 | val =  0.234\n",
      "        (wind_direction_10m -9): pval = 0.08954 | val =  0.231\n",
      "\n",
      "    Variable dewpoint_temperature has 14 link(s):\n",
      "        (wind_speed_10m  0): pval = 0.00013 | val =  0.507 | unoriented link\n",
      "        (sea_level_anomaly -1): pval = 0.01188 | val = -0.368\n",
      "        (wind_speed_10m -4): pval = 0.00776 | val = -0.362\n",
      "        (mean_wave_direction -12): pval = 0.01364 | val =  0.357\n",
      "        (dewpoint_temperature -8): pval = 0.01975 | val = -0.339\n",
      "        (coastline_position  0): pval = 0.02122 | val =  0.335 | unoriented link\n",
      "        (wind_speed_10m -3): pval = 0.01336 | val = -0.335\n",
      "        (sst -1): pval = 0.03824 | val =  0.291\n",
      "        (sst -9): pval = 0.05262 | val =  0.279\n",
      "        (coastline_position -8): pval = 0.06658 | val =  0.267\n",
      "        (sst -3): pval = 0.06821 | val =  0.260\n",
      "        (sea_level_anomaly  0): pval = 0.08474 | val = -0.251 | unoriented link\n",
      "        (mean_wave_direction -4): pval = 0.09739 | val = -0.240\n",
      "        (mean_wave_direction -2): pval = 0.09948 | val = -0.238\n",
      "\n",
      "    Variable mean_wave_direction has 11 link(s):\n",
      "        (mean_wave_direction -2): pval = 0.00208 | val =  0.429\n",
      "        (sea_level_anomaly -9): pval = 0.00580 | val =  0.392\n",
      "        (sst -8): pval = 0.02082 | val =  0.326\n",
      "        (mean_wave_direction -11): pval = 0.02618 | val =  0.321\n",
      "        (sea_level_anomaly -7): pval = 0.04371 | val = -0.292\n",
      "        (wave_energy -8): pval = 0.05058 | val =  0.278\n",
      "        (coastline_position -1): pval = 0.05512 | val =  0.276\n",
      "        (wind_direction_10m -8): pval = 0.04940 | val =  0.266\n",
      "        (dewpoint_temperature -7): pval = 0.07875 | val = -0.256\n",
      "        (total_precipitation -6): pval = 0.08603 | val =  0.245\n",
      "        (wind_speed_10m -10): pval = 0.09242 | val = -0.234\n",
      "\n",
      "    Variable wind_direction_10m has 8 link(s):\n",
      "        (sst -1): pval = 0.00386 | val = -0.380\n",
      "        (sst -5): pval = 0.01659 | val =  0.322\n",
      "        (sst -7): pval = 0.03712 | val = -0.282\n",
      "        (wind_direction_10m -10): pval = 0.03116 | val = -0.281\n",
      "        (sea_level_anomaly -1): pval = 0.04361 | val = -0.278\n",
      "        (coastline_position  0): pval = 0.04865 | val = -0.272 | unoriented link\n",
      "        (sst -9): pval = 0.06641 | val =  0.249\n",
      "        (sea_level_anomaly -2): pval = 0.09524 | val = -0.232\n",
      "\n",
      "    Variable wind_speed_10m has 11 link(s):\n",
      "        (dewpoint_temperature  0): pval = 0.00013 | val =  0.507 | unoriented link\n",
      "        (sst  0): pval = 0.00983 | val = -0.342 | unoriented link\n",
      "        (dewpoint_temperature -7): pval = 0.02865 | val = -0.304\n",
      "        (wind_speed_10m -2): pval = 0.02800 | val = -0.289\n",
      "        (sea_level_anomaly  0): pval = 0.05797 | val = -0.265 | unoriented link\n",
      "        (coastline_position -5): pval = 0.06267 | val = -0.258\n",
      "        (mean_wave_direction -6): pval = 0.06581 | val =  0.255\n",
      "        (sst -3): pval = 0.05974 | val =  0.253\n",
      "        (wave_energy  0): pval = 0.07887 | val =  0.237 | unoriented link\n",
      "        (sst -12): pval = 0.09638 | val = -0.226\n",
      "        (wind_speed_10m -1): pval = 0.08669 | val =  0.225\n"
     ]
    }
   ],
   "source": [
    "tau_max = 12\n",
    "pc_alpha = 0.01\n",
    "pcmci.verbosity = 1\n",
    "results = pcmci.run_pcmci(tau_max=tau_max, pc_alpha=None, alpha_level=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##\n",
      "## Step 1: PC1 algorithm for selecting lagged conditions\n",
      "##\n",
      "\n",
      "Parameters:\n",
      "independence test = par_corr\n",
      "tau_min = 1\n",
      "tau_max = 12\n",
      "pc_alpha = [0.1]\n",
      "max_conds_dim = None\n",
      "max_combinations = 1\n",
      "\n",
      "\n",
      "\n",
      "## Resulting lagged parent (super)sets:\n",
      "\n",
      "    Variable coastline_position has 3 link(s):\n",
      "        (coastline_position -1): max_pval = 0.00000, |min_val| =  0.646\n",
      "        (mean_wave_direction -1): max_pval = 0.00284, |min_val| =  0.362\n",
      "        (total_precipitation -12): max_pval = 0.08332, |min_val| =  0.215\n",
      "\n",
      "    Variable wave_energy has 5 link(s):\n",
      "        (wave_energy -12): max_pval = 0.00010, |min_val| =  0.467\n",
      "        (sst -2): max_pval = 0.00712, |min_val| =  0.331\n",
      "        (mean_wave_direction -6): max_pval = 0.07268, |min_val| =  0.226\n",
      "        (coastline_position -12): max_pval = 0.09524, |min_val| =  0.210\n",
      "        (coastline_position -5): max_pval = 0.09931, |min_val| =  0.206\n",
      "\n",
      "    Variable sea_level_anomaly has 5 link(s):\n",
      "        (sea_level_anomaly -1): max_pval = 0.00003, |min_val| =  0.483\n",
      "        (dewpoint_temperature -8): max_pval = 0.01896, |min_val| =  0.290\n",
      "        (total_precipitation -8): max_pval = 0.02022, |min_val| =  0.290\n",
      "        (wind_speed_10m -4): max_pval = 0.02165, |min_val| =  0.280\n",
      "        (sst -8): max_pval = 0.03466, |min_val| =  0.262\n",
      "\n",
      "    Variable sst has 3 link(s):\n",
      "        (wave_energy -10): max_pval = 0.00803, |min_val| =  0.324\n",
      "        (sea_level_anomaly -3): max_pval = 0.01081, |min_val| =  0.312\n",
      "        (total_precipitation -12): max_pval = 0.01697, |min_val| =  0.289\n",
      "\n",
      "    Variable total_precipitation has 2 link(s):\n",
      "        (sst -1): max_pval = 0.00207, |min_val| =  0.372\n",
      "        (wind_direction_10m -3): max_pval = 0.02014, |min_val| =  0.290\n",
      "\n",
      "    Variable dewpoint_temperature has 5 link(s):\n",
      "        (mean_wave_direction -4): max_pval = 0.01007, |min_val| =  0.317\n",
      "        (wave_energy -6): max_pval = 0.01316, |min_val| =  0.302\n",
      "        (sst -1): max_pval = 0.01904, |min_val| =  0.288\n",
      "        (wind_speed_10m -4): max_pval = 0.05871, |min_val| =  0.236\n",
      "        (wave_energy -7): max_pval = 0.08803, |min_val| =  0.212\n",
      "\n",
      "    Variable mean_wave_direction has 6 link(s):\n",
      "        (mean_wave_direction -12): max_pval = 0.00911, |min_val| =  0.324\n",
      "        (dewpoint_temperature -7): max_pval = 0.01326, |min_val| =  0.301\n",
      "        (dewpoint_temperature -12): max_pval = 0.01469, |min_val| =  0.299\n",
      "        (sea_level_anomaly -5): max_pval = 0.01770, |min_val| =  0.289\n",
      "        (wave_energy -7): max_pval = 0.03418, |min_val| =  0.267\n",
      "        (mean_wave_direction -2): max_pval = 0.09422, |min_val| =  0.213\n",
      "\n",
      "    Variable wind_direction_10m has 2 link(s):\n",
      "        (sst -1): max_pval = 0.03512, |min_val| =  0.258\n",
      "        (total_precipitation -6): max_pval = 0.03659, |min_val| =  0.254\n",
      "\n",
      "    Variable wind_speed_10m has 3 link(s):\n",
      "        (wind_direction_10m -5): max_pval = 0.06082, |min_val| =  0.232\n",
      "        (wave_energy -12): max_pval = 0.06540, |min_val| =  0.226\n",
      "        (dewpoint_temperature -1): max_pval = 0.09903, |min_val| =  0.203\n",
      "\n",
      "##\n",
      "## Step 2: PC algorithm with contemp. conditions and MCI tests\n",
      "##\n",
      "\n",
      "Parameters:\n",
      "\n",
      "independence test = par_corr\n",
      "tau_min = 0\n",
      "tau_max = 12\n",
      "pc_alpha = 0.1\n",
      "contemp_collider_rule = majority\n",
      "conflict_resolution = True\n",
      "reset_lagged_links = False\n",
      "max_conds_dim = None\n",
      "max_conds_py = None\n",
      "max_conds_px = None\n",
      "max_conds_px_lagged = None\n",
      "fdr_method = none\n",
      "\n",
      "## Significant links at alpha = 0.1:\n",
      "\n",
      "    Variable coastline_position has 4 link(s):\n",
      "        (dewpoint_temperature  0): pval = 0.00042 | val =  0.444\n",
      "        (coastline_position -1): pval = 0.00045 | val =  0.432\n",
      "        (mean_wave_direction -1): pval = 0.01549 | val = -0.311\n",
      "        (wind_direction_10m  0): pval = 0.05801 | val = -0.240\n",
      "\n",
      "    Variable wave_energy has 2 link(s):\n",
      "        (sst -2): pval = 0.00384 | val =  0.365\n",
      "        (wave_energy -12): pval = 0.01196 | val =  0.328\n",
      "\n",
      "    Variable sea_level_anomaly has 4 link(s):\n",
      "        (sea_level_anomaly -1): pval = 0.00043 | val =  0.448\n",
      "        (wind_speed_10m -4): pval = 0.00466 | val = -0.361\n",
      "        (total_precipitation -8): pval = 0.02525 | val =  0.284\n",
      "        (sst -8): pval = 0.05083 | val =  0.253\n",
      "\n",
      "    Variable sst has 2 link(s):\n",
      "        (sea_level_anomaly -3): pval = 0.00362 | val =  0.367\n",
      "        (total_precipitation -12): pval = 0.00303 | val =  0.365\n",
      "\n",
      "    Variable total_precipitation has 2 link(s):\n",
      "        (sst -1): pval = 0.00584 | val =  0.344\n",
      "        (wind_direction_10m -3): pval = 0.06033 | val = -0.234\n",
      "\n",
      "    Variable dewpoint_temperature has 3 link(s):\n",
      "        (wind_speed_10m -4): pval = 0.00049 | val = -0.437\n",
      "        (sst -1): pval = 0.00226 | val =  0.387\n",
      "        (wind_speed_10m  0): pval = 0.00738 | val =  0.348 | unclear orientation due to conflict\n",
      "\n",
      "    Variable mean_wave_direction has 1 link(s):\n",
      "        (mean_wave_direction -2): pval = 0.01211 | val =  0.330\n",
      "\n",
      "    Variable wind_direction_10m has 2 link(s):\n",
      "        (sst -1): pval = 0.00100 | val = -0.405\n",
      "        (total_precipitation -6): pval = 0.03301 | val =  0.265\n",
      "\n",
      "    Variable wind_speed_10m has 2 link(s):\n",
      "        (sst  0): pval = 0.00022 | val = -0.459\n",
      "        (dewpoint_temperature  0): pval = 0.00738 | val =  0.348 | unclear orientation due to conflict\n",
      "\n",
      "## Ambiguous triples (not used for orientation):\n",
      "\n",
      "    [(sst -1), dewpoint_temperature, coastline_position]\n",
      "    [(wind_speed_10m  0), dewpoint_temperature, coastline_position]\n",
      "    [(wind_speed_10m -4), dewpoint_temperature, coastline_position]\n",
      "    [(sst -1), wind_direction_10m, coastline_position]\n",
      "    [(total_precipitation -6), wind_direction_10m, coastline_position]\n",
      "    [(coastline_position -1), coastline_position, dewpoint_temperature]\n",
      "    [(wind_direction_10m  0), coastline_position, dewpoint_temperature]\n",
      "    [(dewpoint_temperature  0), coastline_position, wind_direction_10m]\n",
      "    [(mean_wave_direction -1), coastline_position, wind_direction_10m]\n",
      "    [(sea_level_anomaly -3), sst, wind_speed_10m]\n",
      "    [(total_precipitation -12), sst, wind_speed_10m]\n",
      "    [(coastline_position  0), dewpoint_temperature, wind_speed_10m]\n",
      "    [(sst -1), dewpoint_temperature, wind_speed_10m]\n"
     ]
    }
   ],
   "source": [
    "tau_max = 12\n",
    "pc_alpha = 0.1\n",
    "pcmci.verbosity = 1\n",
    "\n",
    "results = pcmci.run_pcmciplus(tau_min=0, tau_max=tau_max, pc_alpha=pc_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], tau_max=tau_max, fdr_method='fdr_bh')\n",
    "# pcmci.print_significant_links(\n",
    "#         p_matrix = q_matrix,\n",
    "#         val_matrix = results['val_matrix'],\n",
    "#         alpha_level = 0.1)\n",
    "graph = pcmci.get_graph_from_pmatrix(p_matrix=q_matrix, alpha_level=0.1, \n",
    "            tau_min=0, tau_max=tau_max, link_assumptions=None)\n",
    "results['graph'] = graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_graph(\n",
    "    val_matrix=results['val_matrix'],\n",
    "    graph=results['graph'],\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='cross-MCI (edges)',\n",
    "    node_colorbar_label='auto-MCI (nodes)',\n",
    "    ); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series graph    \n",
    "tp.plot_time_series_graph(\n",
    "    figsize=(6, 4),\n",
    "    val_matrix=results['val_matrix'],\n",
    "    graph=results['graph'],\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='MCI',\n",
    "    ); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IslandTimeEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
