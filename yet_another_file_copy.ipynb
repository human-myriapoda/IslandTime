{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=6Zz_CGeJj-P7W78KCv7Uo2teOT8HUSOZmhXfK-bGRe8&tc=W7DwgrprhBJej-46oS3ndi8fXuvr8l55UN6b5UM3OCg&cc=3Uw_YqF2-xayVpMSeUMj0dCNVF0QYF1df2BUVaEsan0>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=6Zz_CGeJj-P7W78KCv7Uo2teOT8HUSOZmhXfK-bGRe8&tc=W7DwgrprhBJej-46oS3ndi8fXuvr8l55UN6b5UM3OCg&cc=3Uw_YqF2-xayVpMSeUMj0dCNVF0QYF1df2BUVaEsan0</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "from IslandTime import retrieve_island_info, Segmentation, update_results_map, plot_shoreline_transects, Workflow, update_data_map, TimeSeriesCoastSat, PreTimeSeries, TimeSeriesERA5, TimeSeriesClimateIndices\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import inspect\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_fig = os.path.join(os.getcwd(), 'figures', 'seasonality_BEAST')\n",
    "list_files = os.listdir(path_to_fig)\n",
    "\n",
    "for file in list_files:\n",
    "    t = os.path.getmtime(os.path.join(path_to_fig, file))\n",
    "    # into datetime\n",
    "    t = pd.to_datetime(t, unit='s')\n",
    "    # print(t)\n",
    "    if t < pd.to_datetime('2024-07-16'):\n",
    "        print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MULTIPOINT ((73.08961 0.26550), (73.51679 5.24...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FID                                           geometry\n",
       "0    0  MULTIPOINT ((73.08961 0.26550), (73.51679 5.24..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file('shp//Huvadhoo_included.shp')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('shp//islands_with_seasonality_cond3.shp')\n",
    "# gdf = gpd.read_file('shp//Huvadhoo_included.shp')\n",
    "# get number of points in MultiPoint\n",
    "ii = []\n",
    "for i in gdf['geometry'][0].geoms:\n",
    "    ii.append(i)\n",
    "\n",
    "print(len(ii))\n",
    "\n",
    "# for i in gdf['geometry'][0].geoms:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('shp//islands_seasonality_results.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9983079344012772 0.997070302530704\n"
     ]
    }
   ],
   "source": [
    "def asymmetric_seasonal_function_fitting(x, A, k, T1, T2, phi, offset):\n",
    "    period = T1 + T2\n",
    "    x_mod = (x + phi) % period\n",
    "    if x_mod < T1:\n",
    "        return A * np.exp(k * x) * np.sin(2 * np.pi * x_mod / T1) + offset\n",
    "    else:\n",
    "        return A * np.exp(k * x) * np.sin(2 * np.pi * (x_mod - T1) / T2) + offset\n",
    "\n",
    "def asymmetric_seasonal_function_fitting_wrapper(x, A, k, T1, T2, phi, offset):\n",
    "    return np.array([asymmetric_seasonal_function_fitting(xi, A, k, T1, T2, phi, offset) for xi in x])\n",
    "\n",
    "def seasonal_function_fitting(x, A, k, period, phi, offset):\n",
    "    return A * np.exp(k * x) * np.sin(2 * np.pi / period * x + phi) + offset\n",
    "\n",
    "initial_guess = [7, 0.001, 182, 182, 90, 0] \n",
    "initial_guess2 = [7, 0.001, 365, 90, 0]\n",
    "\n",
    "numeric_dates = np.array([(date - ts.index[0]).days for date in ts.index])\n",
    "numeric_dates_big = np.linspace(0, numeric_dates[-1], 1000)\n",
    "# dates_big = np.array([ts.index[0] + pd.Timedelta(days=xi) for xi in numeric_dates_big])\n",
    "\n",
    "params, _ = curve_fit(asymmetric_seasonal_function_fitting_wrapper, xdata=numeric_dates, ydata=res_B.season.Y, p0=initial_guess)\n",
    "params2, _ = curve_fit(seasonal_function_fitting, xdata=numeric_dates, ydata=res_B.season.Y, p0=initial_guess2)\n",
    "\n",
    "# plot\n",
    "plt.plot(ts.index, res_B.season.Y, label='data')\n",
    "plt.plot(ts.index, asymmetric_seasonal_function_fitting_wrapper(numeric_dates, *params), label='fit')\n",
    "plt.plot(ts.index, seasonal_function_fitting(numeric_dates, *params2), label='fit2')\n",
    "\n",
    "# print r2\n",
    "\n",
    "r2 = 1 - np.sum((res_B.season.Y - asymmetric_seasonal_function_fitting_wrapper(numeric_dates, *params))**2) / np.sum((res_B.season.Y - np.mean(res_B.season.Y))**2)\n",
    "r2_2 = 1 - np.sum((res_B.season.Y - seasonal_function_fitting(numeric_dates, *params2))**2) / np.sum((res_B.season.Y - np.mean(res_B.season.Y))**2)\n",
    "print(r2, r2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_name = 'coastline_position_transect_10_waterline'\n",
    "ts = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries'][ts_name]['monthly'][ts_name] \n",
    "p = island_info['timeseries_analysis'][ts_name]['seasonality']['peaks_seasonal_BEAST']\n",
    "stats.mode([ts.index[p][i].month for i in range(len(p))]).mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter Pillow unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from celluloid import Camera\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Polygon of the reference shoreline\n",
    "reference_shoreline = island_info['spatial_reference']['reference_shoreline']\n",
    "polygon_reference_shoreline = shapely.geometry.Polygon(reference_shoreline)\n",
    "transects_geo = island_info['spatial_reference']['transects']\n",
    "\n",
    "# Short cut for time series analysis results\n",
    "ts_analysis_results = island_info['timeseries_analysis']\n",
    "ts_pp = island_info['timeseries_preprocessing']\n",
    "\n",
    "# Get transect keys \n",
    "key_transects = [int((key).split('_')[3]) for key in ts_analysis_results.keys()]\n",
    "\n",
    "ax.plot(reference_shoreline[:, 0], reference_shoreline[:, 1], 'k-', zorder=1)\n",
    "ax.axis('off')\n",
    "# ax.set_xlabel('Longitude', fontsize=15)\n",
    "# ax.set_ylabel('Latitude', fontsize=15)\n",
    "\n",
    "# Get intersections between transects and reference shoreline\n",
    "intersections = [polygon_reference_shoreline.exterior.intersection(shapely.geometry.LineString(transects_geo[key_transect])) for key_transect in key_transects]\n",
    "\n",
    "# x and y coordinates of intersections\n",
    "x_intersections = []\n",
    "y_intersections = []\n",
    "for intersection in intersections:\n",
    "    if type(intersection) == shapely.geometry.MultiPoint:\n",
    "        # Take the first point of the MultiPoint\n",
    "        x_intersections.append(intersection.geoms[0].x)\n",
    "        y_intersections.append(intersection.geoms[0].y)\n",
    "    \n",
    "    elif type(intersection) == shapely.geometry.LineString:\n",
    "        x_intersections.append(None)\n",
    "        y_intersections.append(None)\n",
    "    else:\n",
    "        x_intersections.append(intersection.x)\n",
    "        y_intersections.append(intersection.y)\n",
    "\n",
    "cc = []\n",
    "for val in ts_analysis_results.keys():\n",
    "    ts = ts_pp['optimal time period']['dict_timeseries'][val]['monthly'][val]\n",
    "    p = ts_analysis_results[val]['seasonality']['peaks_seasonal_BEAST']\n",
    "    if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 1:\n",
    "        dates_p = ts.index[p]\n",
    "        mode_dates_p = stats.mode([dates_p[i].month for i in range(len(p))]).mode\n",
    "        cc.append(mode_dates_p)\n",
    "    \n",
    "    else:\n",
    "        cc.append(None)\n",
    "\n",
    "spa = ax.scatter(x_intersections, y_intersections, s=100, c=cc, cmap='Paired', edgecolor='k')\n",
    "cbar = fig.colorbar(spa, ax=ax)\n",
    "\n",
    "fig_a, ax_a = plt.subplots(figsize=(20, 10))\n",
    "camera = Camera(fig_a)\n",
    "ax_a.plot(reference_shoreline[:, 0], reference_shoreline[:, 1], 'k-', zorder=1)\n",
    "ax_a.axis('off')\n",
    "\n",
    "# dict month to month full name\n",
    "month_dict = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "\n",
    "for month in range(1, 13):\n",
    "\n",
    "    ax_a.plot(reference_shoreline[:, 0], reference_shoreline[:, 1], 'k-', zorder=1)\n",
    "    ax_a.axis('off')\n",
    "\n",
    "    # Get the center of the image\n",
    "    centre_image = np.array([np.mean(reference_shoreline[:, 0]), np.mean(reference_shoreline[:, 1])])\n",
    "\n",
    "    ax_a.text(centre_image[0], centre_image[1], month_dict[month], fontsize=25, color='black', ha='center', va='center')\n",
    "    # Starting point (xytext)\n",
    "    for x, y, m, kt in zip(x_intersections, y_intersections, cc, key_transects):\n",
    "        if m == month:\n",
    "            end_point = np.array([transects_geo[kt][1, :][0], transects_geo[kt][1, :][1]])\n",
    "\n",
    "            # Original endpoint (xy)\n",
    "            start_point = np.array([x, y])\n",
    "\n",
    "            # Calculate the direction vector\n",
    "            direction_vector = end_point - start_point\n",
    "\n",
    "            # Scale the direction vector to get a shorter vector\n",
    "            scale_factor = 0.3  # Adjust this factor to control the length of the new vector\n",
    "            shorter_direction_vector = direction_vector * scale_factor\n",
    "\n",
    "            # Calculate the new endpoint\n",
    "            new_end_point = start_point + shorter_direction_vector\n",
    "\n",
    "            # Annotate with the shorter vector\n",
    "            ax_a.annotate('', xytext=(new_end_point[0], new_end_point[1]), xy=(start_point[0], start_point[1]),\n",
    "                        arrowprops=dict(arrowstyle='<-', color='black'))\n",
    "            \n",
    "    camera.snap()\n",
    "\n",
    "animation = camera.animate()\n",
    "animation.save('{}.gif'.format('seasons_test'), writer='Pillow', fps=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_transects = [10, 3, 73, 65, 59, 54, 46, 36, 27, 17]\n",
    "# Short cut for time series analysis results\n",
    "ts_analysis_results = island_info['timeseries_analysis']\n",
    "ts_pp = island_info['timeseries_preprocessing']\n",
    "\n",
    "val = 'coastline_position_transect_{}_waterline'.format(s_transects[0])\n",
    "\n",
    "# for val in ts_analysis_results.keys():\n",
    "ts = ts_pp['optimal time period']['dict_timeseries'][val]['monthly'][val]\n",
    "p = ts_analysis_results[val]['seasonality']['peaks_seasonal_BEAST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19a1d72f7a0>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "val = 'coastline_position_transect_{}_waterline'.format(s_transects[0])\n",
    "plt.plot(NormalizeData(ts_analysis_results[val]['seasonality']['seasonal_fit_BEAST']))\n",
    "# val = 'coastline_position_transect_{}_waterline'.format(s_transects[1])\n",
    "# plt.plot(NormalizeData(ts_analysis_results[val]['seasonality']['seasonal_fit_BEAST']))\n",
    "# val = 'coastline_position_transect_{}_waterline'.format(s_transects[-1])\n",
    "# plt.plot(NormalizeData(ts_analysis_results[val]['seasonality']['seasonal_fit_BEAST']))\n",
    "val = 'coastline_position_transect_{}_waterline'.format(s_transects[-2])\n",
    "plt.plot(NormalizeData(ts_analysis_results[val]['seasonality']['seasonal_fit_BEAST']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sediment_transport_direction(time_series1, time_series2):\n",
    "    # Compute the cross-correlation\n",
    "    correlation = signal.correlate(time_series2, time_series1, mode='full')\n",
    "    lags = signal.correlation_lags(len(time_series2), len(time_series1), mode='full')\n",
    "    lag = lags[np.argmax(correlation)]\n",
    "\n",
    "    return np.sign(lag)\n",
    "\n",
    "val = 'coastline_position_transect_{}_waterline'.format(27)\n",
    "signal1 = NormalizeData(ts_analysis_results[val]['seasonality']['seasonal_fit_BEAST'])\n",
    "\n",
    "plt.plot(signal1, label=val)\n",
    "\n",
    "val = 'coastline_position_transect_{}_waterline'.format(10)\n",
    "signal2 = NormalizeData(ts_analysis_results[val]['seasonality']['seasonal_fit_BEAST'])\n",
    "\n",
    "\n",
    "plt.plot(signal2, label=val)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "sediment_transport_direction(signal1, signal2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction of propagation: left to right\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example signals\n",
    "# Create two example signals with a delay\n",
    "val = 'coastline_position_transect_{}_waterline'.format(s_transects[0])\n",
    "signal1 = NormalizeData(ts_analysis_results[val]['seasonality']['seasonal_fit_BEAST'])\n",
    "\n",
    "val = 'coastline_position_transect_{}_waterline'.format(s_transects[-2])\n",
    "signal2 = NormalizeData(ts_analysis_results[val]['seasonality']['seasonal_fit_BEAST'])\n",
    "\n",
    "t = np.arange(len(signal1))\n",
    "\n",
    "# Compute the cross-correlation\n",
    "correlation = signal.correlate(signal2, signal1, mode='full')\n",
    "lags = signal.correlation_lags(len(signal2), len(signal1), mode='full')\n",
    "lag = lags[np.argmax(correlation)]\n",
    "\n",
    "# Determine the direction of propagation\n",
    "if lag > 0:\n",
    "    direction = \"right to left\"\n",
    "elif lag < 0:\n",
    "    direction = \"left to right\"\n",
    "else:\n",
    "    direction = \"no delay\"\n",
    "\n",
    "print(f\"Direction of propagation: {direction}\")\n",
    "\n",
    "# Plot the signals and the cross-correlation\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t, signal1, label='Signal 1')\n",
    "plt.plot(t, signal2, label='Signal 2')\n",
    "plt.legend()\n",
    "plt.title(\"Signals\")\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(lags / fs, correlation)\n",
    "plt.title(\"Cross-correlation\")\n",
    "plt.xlabel(\"Time lag (s)\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(t, signal1, label='Signal 1')\n",
    "plt.plot(t, np.roll(signal2, -lag), label='Aligned Signal 2')\n",
    "plt.legend()\n",
    "plt.title(\"Aligned Signals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Polygon of the reference shoreline\n",
    "reference_shoreline = island_info['spatial_reference']['reference_shoreline']\n",
    "polygon_reference_shoreline = shapely.geometry.Polygon(reference_shoreline)\n",
    "transects_geo = island_info['spatial_reference']['transects']\n",
    "\n",
    "# Short cut for time series analysis results\n",
    "ts_analysis_results = island_info['timeseries_analysis']\n",
    "ts_pp = island_info['timeseries_preprocessing']\n",
    "\n",
    "# Get transect keys \n",
    "key_transects = s_transects\n",
    "\n",
    "ax.plot(reference_shoreline[:, 0], reference_shoreline[:, 1], 'k-', zorder=1)\n",
    "ax.axis('off')\n",
    "# ax.set_xlabel('Longitude', fontsize=15)\n",
    "# ax.set_ylabel('Latitude', fontsize=15)\n",
    "\n",
    "# Get intersections between transects and reference shoreline\n",
    "intersections = [polygon_reference_shoreline.exterior.intersection(shapely.geometry.LineString(transects_geo[key_transect])) for key_transect in key_transects]\n",
    "\n",
    "# x and y coordinates of intersections\n",
    "x_intersections = []\n",
    "y_intersections = []\n",
    "for intersection in intersections:\n",
    "    if type(intersection) == shapely.geometry.MultiPoint:\n",
    "        # Take the first point of the MultiPoint\n",
    "        x_intersections.append(intersection.geoms[0].x)\n",
    "        y_intersections.append(intersection.geoms[0].y)\n",
    "    \n",
    "    elif type(intersection) == shapely.geometry.LineString:\n",
    "        x_intersections.append(None)\n",
    "        y_intersections.append(None)\n",
    "    else:\n",
    "        x_intersections.append(intersection.x)\n",
    "        y_intersections.append(intersection.y)\n",
    "\n",
    "cc = []\n",
    "for s in s_transects:\n",
    "    val = 'coastline_position_transect_{}_waterline'.format(s)\n",
    "    ts = ts_pp['optimal time period']['dict_timeseries'][val]['monthly'][val]\n",
    "    p = ts_analysis_results[val]['seasonality']['peaks_seasonal_BEAST']\n",
    "    if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 1:\n",
    "        dates_p = ts.index[p]\n",
    "        mode_dates_p = stats.mode([dates_p[i].month for i in range(len(p))]).mode\n",
    "        cc.append(mode_dates_p)\n",
    "    \n",
    "    else:\n",
    "        cc.append(None)\n",
    "\n",
    "spa = ax.scatter(x_intersections, y_intersections, s=100, c=cc, cmap='Paired', edgecolor='k')\n",
    "cbar = fig.colorbar(spa, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_method(COVB, param, x_new, f, x, y, alpha):\n",
    "    # - - -\n",
    "    # Function to calculate the confidence interval and prediction interval\n",
    "    # for any user-defined regression function using the delta-method\n",
    "    # as described in Sec 5.1 of the following online statistics lecture:\n",
    "    # https://jchiquet.github.io/MAP566/docs/regression/map566-lecture-nonlinear-regression.html\n",
    "    #\n",
    "    # Greg Pelletier (gjpelletier@gmail.com)\n",
    "    # - - -\n",
    "    # INPUT\n",
    "    # COVB = variance-covariance matrix of the model parameters (e.g. from scipy or lmfit)\n",
    "    # param = best-fit parameters of the regression function (e.g. from scipy or lmfit)\n",
    "    # x_new = new x values to evaluate new predicted y_new values (e.g. x_new=linspace(min(x),max(x),100)\n",
    "    # f = user-defined regression lambda function to predict y given inputs if param and x values (e.g. observed x or x_new)\n",
    "    # \tFor example, if using the 3-parameter nonlinear regression exponential threshold function, then\n",
    "    # \tf = lambda param,xval : param[0] + param[1] * exp(param[2] * xval)\n",
    "    # x = observed x\n",
    "    # y = observed y\n",
    "    # alpha = significance level for the confidence/prediction interval (e.g. alpha=0.05 is the 95% confidence/prediction interval)\n",
    "    # - - -\n",
    "    # OUTPUT\n",
    "    # dict = dictionary of output varlables with the following keys:\n",
    "    #        'param': best-fit parameter values used as input\n",
    "    #        'COVB': variance-covariance matrix used as input\n",
    "    #        'fstr': string of the input lambda function of the regression model\n",
    "    #        'alpha': input significance level for the confidence/prediction interval (e.g. alpha=0.05 is the 95% confidence/prediction interval)\n",
    "    #        'x': observed x values used as input\n",
    "    #        'y': observed y values used as input\n",
    "    #        'yhat': predicted y at observed x values\n",
    "    #        'x_new': new x-values used as input to evaluate unew predicted y_new values\n",
    "    #        'y_new': new predicted y_new values at new x_new values\n",
    "    #        'lwr_conf': lower confidence interval for each value in x_new\n",
    "    #        'upr_conf': upper confidence interval for each value in x_new\n",
    "    #        'lwr_pred': lower prediction interval for each value in x_new\n",
    "    #        'upr_pred': upper prediction interval for each value in x_new\n",
    "    #        'grad_new': derivative gradients at x_new (change in f(x_new) per change in each param)\n",
    "    #        'G_new': variance due to each paramter at x_new\n",
    "    #        'GS_new': variance due to all parameters combined at x_new\n",
    "    #        'SST': Sum of Squares Total\n",
    "    #        'SSR': Sum of Squares Regression\n",
    "    #        'SSE': Sum of Squares Error\n",
    "    #        'MSR': Mean Square Regression\n",
    "    #        'MSE': Mean Square Error of the residuals\n",
    "    #        'syx': standard error of the estimate\n",
    "    #        'nobs': number of observations\n",
    "    #        'nparam': number of parameters\n",
    "    #        'df': degrees of freedom = nobs-nparam\n",
    "    #        'qt': 2-tailed t-statistic at alpha\n",
    "    #        'Fstat': F-statistic = MSR/MSE\n",
    "    #        'dfn': degrees of freedom for the numerator of the F-test = nparam-1\n",
    "    #        'dfd': degrees of freedom for the denominator of the F-test = nobs-nparam\n",
    "    #        'pvalue': signficance level of the regression from the probability of the F-test\n",
    "    #        'rsquared': r-squared = SSR/SST\n",
    "    #        'adj_rsquared': adjusted squared\n",
    "    # - - -\n",
    "    # calculate predicted y_new at each x_new\n",
    "    y_new = f(param, x_new)\n",
    "    # calculate derivative gradients at x_new (change in f(x_new) per change in each param)\n",
    "    grad_new = np.empty(shape=(np.size(x_new), np.size(param)))\n",
    "    h = 1e-8       # h= small change for each param to balance truncation error and rounding error of the gradient\n",
    "    for i in range(np.size(param)):\n",
    "        # make a copy of param\n",
    "        param2 = np.copy(param)\n",
    "        # gradient forward\n",
    "        param2[i] = (1+h) * param[i]\n",
    "        y_new2 = f(param2, x_new)\n",
    "        dy = y_new2 - y_new\n",
    "        dparam = param2[i] - param[i]\n",
    "        grad_up = dy / dparam\n",
    "        # gradient backward\n",
    "        param2[i] = (1-h) * param[i]\n",
    "        y_new2 = f(param2, x_new)\n",
    "        dy = y_new2 - y_new\n",
    "        dparam = param2[i] - param[i]\n",
    "        grad_dn = dy / dparam\n",
    "        # centered gradient is the average gradient forward and backward\n",
    "        grad_new[:,i] = (grad_up + grad_dn) / 2\n",
    "    # calculate variance in y_new due to each parameter and for all parameters combined\n",
    "    G_new = np.matmul(grad_new, COVB) * grad_new         # variance in y_new due to each param at each x_new\n",
    "    GS_new = np.sum(G_new, axis=1)                       # total variance from all param values at each x_new\n",
    "    # - - -\n",
    "    # # lwr_conf and upr_conf are confidence intervals of the best-fit curve\n",
    "    nobs = np.size(x)\n",
    "    nparam = np.size(param)\n",
    "    df = nobs - nparam\n",
    "    qt = stats.t.ppf(1-alpha/2, df)\n",
    "    delta_f = np.sqrt(GS_new) * qt\n",
    "    lwr_conf = y_new - delta_f\n",
    "    upr_conf = y_new + delta_f\n",
    "    # - - -\n",
    "    # # lwr_pred and upr_pred are prediction intervals of new observations\n",
    "    yhat = f(param,x)\n",
    "    SSE = np.sum((y-yhat) ** 2)                 # sum of squares (residual error)\n",
    "    MSE = SSE / df                              # mean square (residual error)\n",
    "    syx = np.sqrt(MSE)                          # std error of the estimate\n",
    "    delta_y = np.sqrt(GS_new + MSE) * qt\n",
    "    lwr_pred = y_new - delta_y\n",
    "    upr_pred = y_new + delta_y\n",
    "    # - - -\n",
    "    # optional additional outputs of regression statistics\n",
    "    SST = np.sum(y **2) - np.sum(y) **2 / nobs  # sum of squares (total)\n",
    "    SSR = SST - SSE                             # sum of squares (regression model)\n",
    "    MSR = SSR / (np.size(param)-1)              # mean square (regression model)\n",
    "    Fstat = MSR / MSE           # F statistic\n",
    "    dfn = np.size(param) - 1    # df numerator = degrees of freedom for model = number of model parameters - 1\n",
    "    dfd = df                    # df denomenator = degrees of freedom of the residual = df = nobs - nparam\n",
    "    pvalue = 1-stats.f.cdf(Fstat, dfn, dfd)      # p-value of F test statistic\n",
    "    rsquared = SSR / SST                                                        # ordinary rsquared\n",
    "    adj_rsquared = 1-(1-rsquared)*(np.size(x)-1)/(np.size(x)-np.size(param)-1)  # adjusted rsquared\n",
    "    # - - -\n",
    "    # make a string of the lambda function f to save in the output dictionary\n",
    "    fstr = str(inspect.getsourcelines(f)[0])\n",
    "    # make the dictionary of output variables from the delta-method\n",
    "    dict = {\n",
    "            'param': param,\n",
    "            'COVB': COVB,\n",
    "            'fstr': fstr,\n",
    "            'alpha': alpha,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'yhat': yhat,\n",
    "            'x_new': x_new,\n",
    "            'y_new': y_new,\n",
    "            'lwr_conf': lwr_conf,\n",
    "            'upr_conf': upr_conf,\n",
    "            'lwr_pred': lwr_pred,\n",
    "            'upr_pred': upr_pred,\n",
    "            'grad_new': grad_new,\n",
    "            'G_new': G_new,\n",
    "            'GS_new': GS_new,\n",
    "            'SST': SST,\n",
    "            'SSR': SSR,\n",
    "            'SSE': SSE,\n",
    "            'MSR': MSR,\n",
    "            'MSE': MSE,\n",
    "            'syx': syx,\n",
    "            'nobs': nobs,\n",
    "            'nparam': nparam,\n",
    "            'df': df,\n",
    "            'qt': qt,\n",
    "            'Fstat': Fstat,\n",
    "            'dfn': dfn,\n",
    "            'dfd': dfd,\n",
    "            'pvalue': pvalue,\n",
    "            'rsquared': rsquared,\n",
    "            'adj_rsquared': adj_rsquared\n",
    "            }\n",
    "\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# island = \"Vaadhoo (Gaafu Dhaalu)\"\n",
    "country = 'Maldives'\n",
    "\n",
    "# Retrieve island info\n",
    "island_info = retrieve_island_info(island, country, verbose=False)\n",
    "\n",
    "# ii = TimeSeriesCoastSat(island, country, distance_between_transects=5, reference_shoreline_transects_only=True, overwrite=True, retrieve_reference_shoreline_manually=True).main()\n",
    "\n",
    "# plot_shoreline_transects(island_info)\n",
    "\n",
    "# ii = Workflow(island, country, run_all=False, execute_analysis=True, execute_preprocess=False, execute_segmentation=False, update_maps=False, small_island=False, overwrite_analysis=False).main()\n",
    "\n",
    "# ii = Segmentation(island_info, list_sat=['S2'], find_polygons=True, save=False, plot_results=True, plot_all=True, time_series_only=True, animation_polygons=False).main()\n",
    "\n",
    "all_dict = pd.read_pickle(os.path.join(os.getcwd(), 'data', 'coastsat_data', '{}_{}'.format(island, country), 'all_polygons_{}_{}.data'.format(island, country)))\n",
    "best_dict = pd.read_pickle(os.path.join(os.getcwd(), 'data', 'coastsat_data', '{}_{}'.format(island, country), 'best_polygons_{}_{}.data'.format(island, country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(best_dict.keys())[0]\n",
    "dict_georef = all_dict[2]\n",
    "dict_rgb_ts = all_dict[1]\n",
    "dict_poly = all_dict[0]\n",
    "\n",
    "aff_mat = np.array([[dict_georef[key][1], dict_georef[key][2], dict_georef[key][0]],\n",
    "                    [dict_georef[key][4], dict_georef[key][5], dict_georef[key][3]],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "# Create affine transformation\n",
    "import skimage.transform as transform\n",
    "tform = transform.AffineTransform(aff_mat)\n",
    "\n",
    "polygon = dict_poly[key]['polygon_NIR_otsu']\n",
    "x_poly, y_poly  = polygon.exterior.coords.xy\n",
    "\n",
    "# Transform polygon\n",
    "tmp = np.column_stack((x_poly, y_poly))\n",
    "points_converted = tform(tmp)\n",
    "poly_image_crs = shapely.geometry.Polygon(points_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "compactness = (4 * np.pi * poly_image_crs.area) / (poly_image_crs.length ** 2)\n",
    "convex_hull = poly_image_crs.convex_hull\n",
    "solidity = poly_image_crs.area / convex_hull.area\n",
    "bounding_box = poly_image_crs.bounds\n",
    "min_rotated_rect = poly_image_crs.minimum_rotated_rectangle\n",
    "mrr_coords = list(min_rotated_rect.exterior.coords)\n",
    "major_axis = max([mrr_coords[i][0] - mrr_coords[i-1][0] for i in range(len(mrr_coords))])\n",
    "minor_axis = max([mrr_coords[i][1] - mrr_coords[i-1][1] for i in range(len(mrr_coords))])\n",
    "elongation = major_axis / minor_axis\n",
    "\n",
    "def calculate_curvature(polygon):\n",
    "    coords = np.array(polygon.exterior.coords)\n",
    "    angles = []\n",
    "    for i in range(len(coords) - 2):\n",
    "        v1 = coords[i+1] - coords[i]\n",
    "        v2 = coords[i+2] - coords[i+1]\n",
    "        angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "        if not np.isnan(angle):\n",
    "            angles.append(angle)\n",
    "    return np.mean(angles)\n",
    "\n",
    "avg_curvature = calculate_curvature(poly_image_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5710523112999077,\n",
       " 0.9516542785119299,\n",
       " 1.2297719109852085,\n",
       " 0.27854959513273636)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compactness, solidity, elongation, avg_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280860.0, 281410.0, 583140.0, 583680.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skimage.exposure as exposure\n",
    "import pyproj\n",
    "\n",
    "def _image_stretch(im):\n",
    "    # Rescale image for visualisation\n",
    "    if np.ndim(im) > 2:\n",
    "        for i in range(np.shape(im)[2]):\n",
    "            im_no_nan = im[:, :, i][~np.isnan(im[:, :, i])]\n",
    "            im[:, :, i] = exposure.rescale_intensity(im[:, :, i], in_range=(im_no_nan.min(), im_no_nan.max()))\n",
    "    \n",
    "    else:\n",
    "        im_no_nan = im[~np.isnan(im)]\n",
    "        im = exposure.rescale_intensity(im, in_range=(im_no_nan.min(), im_no_nan.max()))\n",
    "    \n",
    "    return im\n",
    "\n",
    "rgb = all_dict[1]['26-08-2015_S2']\n",
    "georef = all_dict[2]['26-08-2015_S2']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(_image_stretch(rgb), extent=[georef[0], georef[0] + georef[1] * rgb.shape[1], georef[3] + georef[5] * rgb.shape[0], georef[3]])\n",
    "plot_shoreline_transects(island_info, transect_plot=10, ax=ax)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21e43a52ba0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from matplotlib.collections import PolyCollection, LineCollection\n",
    "\n",
    "t = 2\n",
    "ts = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_{}_waterline'.format(t)]['monthly']['coastline_position_transect_{}_waterline'.format(t)]\n",
    "\n",
    "def plot_acf_colors(ax, markercolor=\"firebrick\", linecolor=\"black\", facecolor=\"silver\", barcolor=\"darkcyan\", linewidth=1):\n",
    "    \"\"\"utility function to get some control over colors with  plot_acf()\"\"\"\n",
    "    \n",
    "    for item in ax.collections:\n",
    "        # change the color of the confidence interval \n",
    "        if type(item) == PolyCollection:\n",
    "            item.set_facecolor(facecolor)\n",
    "        # change the color of the vertical lines\n",
    "        if type(item) == LineCollection:\n",
    "            item.set_color(barcolor)\n",
    "    # change the color of the markers\n",
    "    [line.get_label() for line in ax.lines]\n",
    "    for item in ax.lines:\n",
    "        item.set_color(markercolor)\n",
    "    # change the color of the horizontal lines\n",
    "    ax.lines[0].set_color(linecolor)\n",
    "    ax.lines[0].set_linewidth(linewidth)\n",
    "    #ax.lines.remove(ax.lines[0])\n",
    "    return ax\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(20,20))\n",
    "axs = axs.ravel()\n",
    "plot_acf(ts, lags=40, alpha=0.1, ax=axs[2], color='k', use_vlines=True, fft=True, vlines_kwargs={'colors': 'k', 'linestyles': 'dashed'}, title='', gapcolor='k')\n",
    "ax = plot_acf_colors(axs[2])\n",
    "axs[2].axvline(x=12, color='k', linestyle='-', linewidth=0.5, zorder=0, alpha=0.5)\n",
    "axs[2].axvline(x=6, color='k', linestyle='-', linewidth=0.5, zorder=0, alpha=0.5)\n",
    "# ax.axvline(x=24, color='red', linestyle='--')\n",
    "# ax.axvline(x=36, color='red', linestyle='--')\n",
    "# ax.axvline(x=6, color='g', linestyle='--', label='6 months')\n",
    "# ax.axvline(x=18, color='g', linestyle='--')\n",
    "# ax.axvline(x=30, color='g', linestyle='--')\n",
    "axs[2].set_xlabel('Lag (months)', fontsize=20)\n",
    "axs[2].set_ylabel('Autocorrelation', fontsize=20)\n",
    "axs[2].text(12.5, 0.8, '12 months', fontsize=20, fontweight='bold')\n",
    "axs[2].text(6.5, 0.8, '6 months', fontsize=20, fontweight='bold')\n",
    "axs[2].set_xlim(-1, 40.5)\n",
    "axs[2].set_ylim(-1.05, 1.05)\n",
    "\n",
    "axs[1].plot(ts, color='k', linewidth=1.5, label='Preprocessed time series')\n",
    "axs[1].set_xlabel('Time', fontsize=20)\n",
    "axs[1].set_ylabel('Coastline position (m)', fontsize=20)\n",
    "axs[1].legend()\n",
    "# plot_shoreline_transects(island_info, ax=axs[0], transect_plot=10)\n",
    "\n",
    "axs[3].plot(ts, color='k', linewidth=1.5, alpha=0.3)\n",
    "axs[3].set_xlabel('Time', fontsize=15)\n",
    "axs[3].set_ylabel('Coastline position (m)', fontsize=20)\n",
    "# ax.set_title('')\n",
    "# ax.legend(fontsize=15)\n",
    "\n",
    "import numpy as np\n",
    "import skimage.exposure as exposure\n",
    "import pyproj\n",
    "\n",
    "def _image_stretch(im):\n",
    "    # Rescale image for visualisation\n",
    "    if np.ndim(im) > 2:\n",
    "        for i in range(np.shape(im)[2]):\n",
    "            im_no_nan = im[:, :, i][~np.isnan(im[:, :, i])]\n",
    "            im[:, :, i] = exposure.rescale_intensity(im[:, :, i], in_range=(im_no_nan.min(), im_no_nan.max()))\n",
    "    \n",
    "    else:\n",
    "        im_no_nan = im[~np.isnan(im)]\n",
    "        im = exposure.rescale_intensity(im, in_range=(im_no_nan.min(), im_no_nan.max()))\n",
    "    \n",
    "    return im\n",
    "\n",
    "kk = 98\n",
    "georef = all_dict[2][list(all_dict[2].keys())[kk]]\n",
    "rgb = all_dict[1][list(all_dict[1].keys())[kk]]\n",
    "\n",
    "axs[0].imshow(_image_stretch(rgb), extent=[georef[0], georef[0] + georef[1] * rgb.shape[1], georef[3] + georef[5] * rgb.shape[0], georef[3]])\n",
    "plot_shoreline_transects(island_info, transect_plot=t, ax=axs[0])\n",
    "axs[0].axis('off')\n",
    "\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import find_peaks, argrelextrema\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "time_series = ts\n",
    "# Fourier transform of time series\n",
    "fft_result = fft(time_series.values)\n",
    "\n",
    "# Get frequencies\n",
    "frequencies = np.fft.fftfreq(len(time_series.values), d=1)#1/12)\n",
    "\n",
    "# fft_result without frequency 0\n",
    "fft_result_n = fft_result[1:]\n",
    "\n",
    "# Remove frequencies with amplitude below a threshold\n",
    "#print(all(element is False for element in (stats.zscore(np.abs(fft_result_n)) > self.z_score_seasonality)))\n",
    "score_list = stats.zscore(np.abs(fft_result_n)) > 2\n",
    "if all(not element for element in score_list):\n",
    "    fft_result = fft_result\n",
    "else:\n",
    "    threshold = np.min(np.abs(fft_result_n[stats.zscore(np.abs(fft_result_n)) > 2]))\n",
    "    fft_result[np.abs(fft_result) < threshold] = 0\n",
    "\n",
    "# Inverse Fourier transform (filetered data)\n",
    "filtered_data_fourier = np.fft.ifft(fft_result).real\n",
    "\n",
    "# Find peaks\n",
    "peaks_fourier, _ = find_peaks(filtered_data_fourier, height=0)\n",
    "\n",
    "# Find period\n",
    "period_fourier = stats.mode(np.diff(peaks_fourier)).mode\n",
    "\n",
    "axs[3].plot(time_series.index, filtered_data_fourier, color='seagreen', linewidth=1.5, label='Fourier-filtered time series')\n",
    "ii=0\n",
    "for peak in peaks_fourier:\n",
    "        if ii==0:\n",
    "            axs[3].axvline(time_series.index[peak], color='firebrick', linestyle='--', linewidth=0.8, label='Signal peaks')\n",
    "        else:\n",
    "            axs[3].axvline(time_series.index[peak], color='firebrick', linestyle='--', linewidth=0.8)\n",
    "        ii+=1\n",
    "\n",
    "import datetime\n",
    "axs[3].annotate('', xy=(datetime.datetime(2017, 5, 1), 136), xytext=(datetime.datetime(2018, 4, 1), 136), arrowprops=dict(arrowstyle='<->', color='black'))\n",
    "plt.text(datetime.datetime(2017, 10, 15), 138, '12 months', horizontalalignment='center', verticalalignment='center', fontsize=20, fontweight='bold')\n",
    "axs[3].legend(fontsize=20)\n",
    "# ax[1, 1].set_title('Fourier reconstruction'\n",
    "\n",
    "# fig.savefig('figures//seasonal_signal.png', dpi=300)\n",
    "\n",
    "# axs[0].text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0.433 exp(--2.506e-02 * x) + 1.218e+01\n",
      "r^2 = 0.6689, p = 1.11e-16\n",
      "standard error of the regression = 0.09905\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_acf(ts, lags=99, alpha=0.05, ax=ax, color='k', use_vlines=True, fft=True, vlines_kwargs={'colors': 'k', 'linestyles': 'dashed'}, title='', gapcolor='k')\n",
    "ax = plot_acf_colors(ax)\n",
    "\n",
    "# Define lags and compute ACF\n",
    "lags_acf = acf(ts, nlags=len(time_series)-1)\n",
    "# lags_acf = acf(ts, nlags=48)\n",
    "\n",
    "# Define range of lags\n",
    "range_lags_acf = np.arange(0, len(lags_acf))\n",
    "\n",
    "# Define sinusoidal function (for fitting)\n",
    "def seasonal_function_fitting(x, A, k, period, phi, offset):\n",
    "    return A * np.exp(k * x) * np.sin(2 * np.pi / period * x + phi) + offset\n",
    "\n",
    "initial_guess = [1, 0, 12, 0, 0]\n",
    "popt, pcov = curve_fit(seasonal_function_fitting, range_lags_acf, lags_acf, p0=initial_guess)\n",
    "\n",
    "# model lambda function to use in delta_method for any param or xval\n",
    "f = lambda param,x : param[0] * np.exp(param[1] * x) * np.sin(2 * np.pi / param[2] * x + param[3]) + param[4] \n",
    "\n",
    "x_new = np.linspace(min(range_lags_acf), max(range_lags_acf), 100)\n",
    "\n",
    "# Calculate confidence intervals\n",
    "d_ = delta_method(pcov,popt,x_new,f,range_lags_acf,lags_acf,0.05)\n",
    "\n",
    "# extract the output values from the delta-method output dictionary\n",
    "y_new_ = d_['y_new']\n",
    "lwr_conf_ = d_['lwr_conf']\n",
    "upr_conf_ = d_['upr_conf']\n",
    "lwr_pred_ = d_['lwr_pred']\n",
    "upr_pred_ = d_['upr_pred']\n",
    "rsquared_ = d_['rsquared']\n",
    "pvalue_ = d_['pvalue']\n",
    "syx_ = d_['syx']\n",
    "\n",
    "# make string values of fit stats and eqn for the plot labels\n",
    "pstr_ = '%.2e' %pvalue_\n",
    "rsqstr_ = '%.4f' %rsquared_\n",
    "b1str_ = '%.3f' %popt[0]\n",
    "b2str_ = '%.3e' %popt[1]\n",
    "b3str_ = '%.3e' %popt[2]\n",
    "syxstr_ = '%.5f' %syx_\n",
    "eqnstr_ = 'y = ' + b1str_ + ' exp(-' + b2str_ + ' * x) + ' + b3str_\n",
    "\n",
    "\n",
    "# plt.plot(x_new, y_new, '--k', label='best-fit (lmfit)',linewidth=4)    # lmfit solution of best fit\n",
    "plt.plot(x_new, y_new_, '-', label='best-fit (scipy)')     # scipy solution of best fit\n",
    "# 95% prediction limits\n",
    "plt.fill_between(x_new, d_['lwr_pred'], d_['upr_pred'],color=\"#d3d3d3\", label='95% PI (delta method)')\n",
    "# 95% confidence limits\n",
    "plt.fill_between(x_new, d_['lwr_conf'], d_['upr_conf'],color=\"#ABABAB\", label='95% CI (delta method)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Delta-method using scipy for parameters and covariance')\n",
    "plt.xlabel('x= xdata')\n",
    "plt.ylabel('y= ydata')\n",
    "print(eqnstr_)\n",
    "print('r^2 = '+ rsqstr_ +', p = '+ pstr_)\n",
    "print('standard error of the regression = '+ syxstr_)\n",
    "# plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "peaks, _ = find_peaks(y_new_, height=0)\n",
    "print(peaks[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: To supress printing the parameers in beast(),      set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast_irreg(),set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast123(),   set extra.printOptions = 0  \n",
      "INFO: To supress warning messages in beast(),            set quiet = 1 \n",
      "INFO: To supress warning messages in beast_irreg(),      set quiet = 1 \n",
      "INFO: To supress warning messages in beast123(),         set extra.quiet = 1  \n",
      "\n",
      "#--------------------------------------------------#\n",
      "#       Brief summary of Input Data                #\n",
      "#--------------------------------------------------#\n",
      "Data Dimension: One signal of length 65\n",
      "IsOrdered     : Yes, ordered in time\n",
      "IsRegular     : Yes, evenly spaced at interval of  0.0833333 year = 1 months = 30.4167 days\n",
      "HasSeasonCmpnt: True  | period = 1 year = 12 months = 365 days. The model 'Y=Trend+Season+Error' is fitted.\n",
      "              : Num_of_DataPoints_per_Period = period/deltaTime = 1/0.0833333 = 12\n",
      "HasOutlierCmpt: False | If true, Y=Trend+Season+Outlier+Error fitted instead of Y=Trend+Season+Error\n",
      "Deseasonalize : False | If true, remove a global seasonal  cmpnt before running BEAST & add it back after BEAST\n",
      "Detrend       : False | If true, remove a global trend component before running BEAST & add it back after BEAST\n",
      "MissingValue  : NaN  flagged as missing values \n",
      "MaxMissingRate: if more than 75% of data is missing, BEAST will skip it.\n",
      "\n",
      "\n",
      "#--------------------------------------------------#\n",
      "#      OPTIONS used in the MCMC inference          #\n",
      "#--------------------------------------------------#\n",
      "\n",
      "#......Start of displaying 'MetaData' ......\n",
      "metadata                =  rb.args() ### or 'lambda: None': just get an empty object### # metadata is used to interpret the input data Y\n",
      "metadata.season         = 'harmonic' # fit a harmonic model to the periodic component\n",
      "metadata.startTime      = 1          # 0001-01-01\n",
      "metadata.deltaTime      = 0.0833333  # 0.0833333 year(s) = 1 month(s) = 30.4167 day(s)\n",
      "metadata.period         = 1          # 1 year(s) = 12 month(s) = 365 day(s) \n",
      "metadata.maxMissingRate = 0.75       # if more than 75% of data is missing, BEAST will skip it.\n",
      "metadata.deseasonalize  = False      # if true,remove a global seasonal cmpnt before running BEAST & add it back later\n",
      "metadata.detrend        = False      # if true,remove a global trend  cmpnt before running BEAST & add it back later\n",
      "#........End of displaying MetaData ........\n",
      "\n",
      "#......Start of displaying 'prior' ......\n",
      "prior                   =  rb.args() ### or 'lambda: None': just get an empty object### # prior is the true model parameters of BEAST\n",
      "prior.seasonMinOrder    = 1          # sorder.minmax[1]: min harmonic order alllowed\n",
      "prior.seasonMaxOrder    = 5          # sorder.minmax[2]: max harmonic order alllowed\n",
      "prior.seasonMinKnotNum  = 0          # scp.minmax[1]   : min num of seasonal chngpts allowed\n",
      "prior.seasonMaxKnotNum  = 8          # scp.minmax[2]   : max num of seasonal chngpts allowed\n",
      "prior.seasonMinSepDist  = 6          # sseg.min        : min seasonal segment length in terms of datapoints\n",
      "prior.seasonLeftMargin  = 6          # sseg.leftmargin : no season chngpts in the first 6 datapoints\n",
      "prior.seasonRightMargin = 6          # sseg.rightmargin: no seoson chngpts in the last 6 datapoints\n",
      "prior.trendMinOrder     = 0          # torder.minmax[1]: min trend polynomial order alllowed\n",
      "prior.trendMaxOrder     = 1          # torder.minmax[2]: max trend polynomial order alllowed\n",
      "prior.trendMinKnotNum   = 0          # tcp.minmax[1]   : min num of chngpts in trend allowed\n",
      "prior.trendMaxKnotNum   = 8          # tcp.minmax[2]   : max num of chngpts in trend allowed\n",
      "prior.trendMinSepDist   = 6          # tseg.min        : min trend segment length in terms of datapoints\n",
      "prior.trendLeftMargin   = 6          # tseg.leftmargin : no trend chngpts in the first 6 datapoints\n",
      "prior.trendRightMargin  = 6          # tseg.rightmargin: no trend chngpts in the last 6 datapoints\n",
      "prior.K_MAX             = 65         # max number of terms in general linear model (relevant only at small values)\n",
      "prior.precValue         = 1.5        # useful mainly when precPriorType='constant'\n",
      "prior.modelPriorType    = 1         \n",
      "prior.precPriorType     = 'componentwise'\n",
      "#......End of displaying prior ......\n",
      "\n",
      "#......Start of displaying 'mcmc' ......\n",
      "mcmc                           =  rb.args() ### or 'lambda: None': just get an empty object### # mcmc is not BEAST parameters but MCMC sampler options\n",
      "mcmc.seed                      = 0          # A nonzero seed to replicate among runs\n",
      "mcmc.samples                   = 8000       # Number of samples saved per chain: the larger, the better\n",
      "mcmc.thinningFactor            = 5          # Thinning the chain: the larger, the better \n",
      "mcmc.burnin                    = 200        # Number of initial samples discarded: the larger, the better\n",
      "mcmc.chainNumber               = 3          # Number of chains: the larger, the better\n",
      "mcmc.maxMoveStepSize           = 6          # Max step of jumping from current changepoint: No need to change\n",
      "mcmc.trendResamplingOrderProb  = 0.1        # Proposal probability of sampling trend polynominal order \n",
      "mcmc.seasonResamplingOrderProb = 0.17       # Proposal probability of sampling seasoanl order \n",
      "mcmc.credIntervalAlphaLevel    = 0.95       # The alphal level for Credible Intervals\n",
      "# Total number of models randomly visited in BEAST is (burnin+sampples*thinFactor)*chainNumber=120600\n",
      "#......End of displaying mcmc ......\n",
      "\n",
      "#......Start of displaying 'extra' ......\n",
      "extra                      =  rb.args() ### or 'lambda: None': just get an empty object### # extra is used to configure output/computing options\n",
      "extra.dumpInputData        = True  # if true, dump a copy of the input data as o.data \n",
      "extra.whichOutputDimIsTime = 1     # 1,2 or 3; which dim of the result is time; used for a 2D/3D input Y\n",
      "extra.computeCredible      = True  # if true, compute  credibiel interval of estimated Y (e.g., o.trend.CI)\n",
      "extra.fastCIComputation    = True  # if true, do not sort but approximiate CI \n",
      "extra.computeSeasonOrder   = True  # if true, dump the estimated time-varying seasonal order: o.season.order \n",
      "extra.computeTrendOrder    = True  # if true, dump the estimated trend polynomial order \n",
      "extra.computeSeasonChngpt  = True  # if true, dump the seasoanl changepoints (scp) in the output \n",
      "extra.computeTrendChngpt   = True  # if true, dump the trend changepoints (tcp) in the output \n",
      "extra.computeSeasonAmp     = False #  compute time-varying seasonal mangitude if season=harmonic  \n",
      "extra.computeTrendSlope    = True  # if true, dump the time-varying slope in trend\n",
      "extra.tallyPosNegSeasonJump= False # differentiate postive/negative jumps at scp\n",
      "extra.tallyPosNegTrendJump = False # differentiate postive/negative jumps at tcp\n",
      "extra.tallyIncDecTrendJump = False # differentiate increased/decreased slopes at tcp\n",
      "extra.printProgressBar     = True  # if true, show an ascii progressbar\n",
      "extra.printOptions         = True  # if true, print the option of the BEAST run\n",
      "extra.consoleWidth         = 85    # an integer specifying the console width for printing\n",
      "extra.numThreadsPerCPU     = 2     # each cpu core spawns 2 concurrent threads (for beast123())\n",
      "extra.numParThreads        = 0     # total number of threads (for beast123() only)\n",
      "#......End of displaying extra ......\n",
      "\n",
      "|Progress:100.0% done[==============================================================]\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e34e954830>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from matplotlib.collections import PolyCollection, LineCollection\n",
    "import Rbeast as rb\n",
    "\n",
    "t = 69\n",
    "ts = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_{}_waterline'.format(t)]['monthly']['coastline_position_transect_{}_waterline'.format(t)]\n",
    "o = rb.beast(ts.values, deltat = '1/12 year', period='1 year')\n",
    "\n",
    "def plot_acf_colors(ax, markercolor=\"#d62828\", linecolor=\"black\", facecolor=\"silver\", barcolor=\"#003049\", linewidth=1):\n",
    "    \"\"\"utility function to get some control over colors with  plot_acf()\"\"\"\n",
    "    \n",
    "    for item in ax.collections:\n",
    "        # change the color of the confidence interval \n",
    "        if type(item) == PolyCollection:\n",
    "            item.set_facecolor(facecolor)\n",
    "        # change the color of the vertical lines\n",
    "        if type(item) == LineCollection:\n",
    "            item.set_color(barcolor)\n",
    "    # change the color of the markers\n",
    "    [line.get_label() for line in ax.lines]\n",
    "    for item in ax.lines:\n",
    "        item.set_color(markercolor)\n",
    "    # change the color of the horizontal lines\n",
    "    ax.lines[0].set_color(linecolor)\n",
    "    ax.lines[0].set_linewidth(linewidth)\n",
    "    #ax.lines.remove(ax.lines[0])\n",
    "    return ax\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(20,20))\n",
    "axs = axs.ravel()\n",
    "plot_acf(ts, lags=40, alpha=0.05, ax=axs[1], color='k', use_vlines=True, fft=True, vlines_kwargs={'colors': 'k', 'linestyles': 'dashed'}, title='', gapcolor='k')\n",
    "ax = plot_acf_colors(axs[1])\n",
    "# axs[1].axvline(x=12, color='k', linestyle='-', linewidth=0.5, zorder=0, alpha=0.5)\n",
    "# axs[1].axvline(x=6, color='k', linestyle='-', linewidth=0.5, zorder=0, alpha=0.5)\n",
    "# axs[1].axvline(x=18, color='k', linestyle='-', linewidth=0.5, zorder=0, alpha=0.5)\n",
    "# ax.axvline(x=24, color='red', linestyle='--')\n",
    "# ax.axvline(x=36, color='red', linestyle='--')\n",
    "# ax.axvline(x=6, color='g', linestyle='--', label='6 months')\n",
    "# ax.axvline(x=18, color='g', linestyle='--')\n",
    "# ax.axvline(x=30, color='g', linestyle='--')\n",
    "axs[1].set_xlabel('Lag (months)', fontsize=20)\n",
    "axs[1].set_ylabel('Autocorrelation', fontsize=20)\n",
    "# axs[1].text(12.2, 0.75, '12 months', fontsize=15, fontweight='bold')\n",
    "# axs[1].text(6.2, 0.85, '6 months', fontsize=15, fontweight='bold')\n",
    "# axs[1].text(18.2, 0.65, '18 months', fontsize=15, fontweight='bold')\n",
    "axs[1].set_xlim(-1, 40.5)\n",
    "axs[1].set_ylim(-1.05, 1.05)\n",
    "# Increase tick size\n",
    "# We change the fontsize of minor ticks label \n",
    "axs[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[3].tick_params(axis='both', which='major', labelsize=12)\n",
    "# axs[1].tick_params(axis='both', which='minor', labelsize=20)\n",
    "\n",
    "# axs[1].plot(ts, color='k', linewidth=1.5, label='Preprocessed time series')\n",
    "# axs[1].set_xlabel('Time', fontsize=20)\n",
    "# axs[1].set_ylabel('Coastline position (m)', fontsize=20)\n",
    "# axs[1].legend()\n",
    "# plot_shoreline_transects(island_info, ax=axs[0], transect_plot=10)\n",
    "\n",
    "axs[3].plot(ts, color='#456990', linewidth=1.5, alpha=0.7, label='Preprocessed time series')\n",
    "axs[3].set_xlabel('Time', fontsize=20)\n",
    "axs[3].set_ylabel('Coastline position (m)', fontsize=20)\n",
    "# ax.set_title('')\n",
    "# ax.legend(fontsize=15)\n",
    "\n",
    "import numpy as np\n",
    "import skimage.exposure as exposure\n",
    "import pyproj\n",
    "\n",
    "def _image_stretch(im):\n",
    "    # Rescale image for visualisation\n",
    "    if np.ndim(im) > 2:\n",
    "        for i in range(np.shape(im)[2]):\n",
    "            im_no_nan = im[:, :, i][~np.isnan(im[:, :, i])]\n",
    "            im[:, :, i] = exposure.rescale_intensity(im[:, :, i], in_range=(im_no_nan.min(), im_no_nan.max()))\n",
    "    \n",
    "    else:\n",
    "        im_no_nan = im[~np.isnan(im)]\n",
    "        im = exposure.rescale_intensity(im, in_range=(im_no_nan.min(), im_no_nan.max()))\n",
    "    \n",
    "    return im\n",
    "\n",
    "kk = 73\n",
    "# georef = all_dict[2][list(all_dict[2].keys())[kk]]\n",
    "# rgb = all_dict[1][list(all_dict[1].keys())[kk]]\n",
    "\n",
    "# axs[0].imshow(_image_stretch(rgb), extent=[georef[0], georef[0] + georef[1] * rgb.shape[1], georef[3] + georef[5] * rgb.shape[0], georef[3]])\n",
    "plot_shoreline_transects(island_info, transect_plot=t, ax=axs[0])\n",
    "axs[0].axis('off')\n",
    "\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import find_peaks, argrelextrema\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "time_series = ts\n",
    "# Fourier transform of time series\n",
    "fft_result = fft(time_series.values)\n",
    "\n",
    "# Get frequencies\n",
    "frequencies = np.fft.fftfreq(len(time_series.values), d=1)#1/12)\n",
    "\n",
    "# Only take the positive half of the spectrum\n",
    "positive_freq = frequencies[:len(frequencies)//2]\n",
    "positive_magnitude = np.abs(fft_result[:len(fft_result)//2])\n",
    "\n",
    "# Convert frequency to cycles per year\n",
    "positive_freq_yearly = positive_freq * 12\n",
    "\n",
    "axs[2].plot(positive_freq_yearly[1:], positive_magnitude[1:], color='#20a39e', linewidth=1.5, label='Fast Fourier Transform')\n",
    "axs[2].set_xlabel('Frequency (cycles per year)', fontsize=20)\n",
    "axs[2].set_ylabel('Amplitude', fontsize=20)\n",
    "axs[2].axvline(x=1, color='k', linestyle='-', linewidth=0.5, zorder=0, alpha=0.5)\n",
    "axs[2].axvline(x=2, color='k', linestyle='-', linewidth=0.5, zorder=0, alpha=0.5)\n",
    "axs[2].axvline(x=3, color='k', linestyle='-', linewidth=0.5, zorder=0, alpha=0.5)\n",
    "axs[2].tick_params(axis='both', which='major', labelsize=12)\n",
    "# axs[2].set_ylim(0, 600)\n",
    "axs[2].set_xlim(0.1, 5)\n",
    "\n",
    "# fft_result without frequency 0\n",
    "fft_result_n = fft_result[1:]\n",
    "\n",
    "# Remove frequencies with amplitude below a threshold\n",
    "#print(all(element is False for element in (stats.zscore(np.abs(fft_result_n)) > self.z_score_seasonality)))\n",
    "score_list = stats.zscore(np.abs(fft_result_n)) > 2.\n",
    "if all(not element for element in score_list):\n",
    "    fft_result = fft_result\n",
    "else:\n",
    "    threshold = np.min(np.abs(fft_result_n[stats.zscore(np.abs(fft_result_n)) > 2.]))\n",
    "    fft_result[np.abs(fft_result) < threshold] = 0\n",
    "\n",
    "# Only take the positive half of the spectrum\n",
    "positive_freq = frequencies[:len(frequencies)//2]\n",
    "positive_magnitude = np.abs(fft_result[:len(fft_result)//2])\n",
    "\n",
    "# Convert frequency to cycles per year\n",
    "positive_freq_yearly = positive_freq * 12\n",
    "\n",
    "axs[2].plot(positive_freq_yearly[1:], positive_magnitude[1:], color='#ffba49', linewidth=2, ls = '--', label='Filtered Fast Fourier Transform')\n",
    "axs[2].legend(fontsize=15)\n",
    "\n",
    "# Inverse Fourier transform (filetered data)\n",
    "filtered_data_fourier = np.fft.ifft(fft_result).real\n",
    "\n",
    "# Find peaks\n",
    "peaks_fourier, _ = find_peaks(filtered_data_fourier, height=0)\n",
    "\n",
    "# Find period\n",
    "period_fourier = stats.mode(np.diff(peaks_fourier)).mode\n",
    "print(period_fourier)\n",
    "\n",
    "axs[3].plot(time_series.index, filtered_data_fourier, color='#540d6e', linewidth=1.5, label='Fourier-filtered time series')\n",
    "ii=0\n",
    "for peak in peaks_fourier:\n",
    "        if ii==0:\n",
    "            axs[3].axvline(time_series.index[peak], color='#EF767A', linestyle='--', linewidth=1.3)\n",
    "        else:\n",
    "            axs[3].axvline(time_series.index[peak], color='#EF767A', linestyle='--', linewidth=1.3)\n",
    "        ii+=1\n",
    "\n",
    "import datetime\n",
    "# axs[3].annotate('', xy=(datetime.datetime(2017, 5, 1), 136), xytext=(datetime.datetime(2018, 4, 1), 136), arrowprops=dict(arrowstyle='<->', color='black'))\n",
    "# plt.text(datetime.datetime(2017, 10, 15), 138, '12 months', horizontalalignment='center', verticalalignment='center', fontsize=20, fontweight='bold')\n",
    "\n",
    "# axs[3].annotate('', xy=(datetime.datetime(2017, 7, 1), 115), xytext=(datetime.datetime(2018, 1, 15), 115), arrowprops=dict(arrowstyle='<->', color='black'))\n",
    "# plt.text(datetime.datetime(2017, 10, 1), 117, '7 months', horizontalalignment='center', verticalalignment='center', fontsize=20, fontweight='bold')\n",
    "\n",
    "# axs[3].annotate('', xy=(datetime.datetime(2017, 2, 1), 95), xytext=(datetime.datetime(2017, 7, 1), 95), arrowprops=dict(arrowstyle='<->', color='black'))\n",
    "# plt.text(datetime.datetime(2017, 4, 1), 97, '5 months', horizontalalignment='center', verticalalignment='center', fontsize=20, fontweight='bold')\n",
    "\n",
    "axs[3].legend(fontsize=15, loc='best')\n",
    "# ax[1, 1].set_title('Fourier reconstruction'\n",
    "\n",
    "# fig.savefig('figures//non_seasonal_signal_new.png', dpi=300)\n",
    "\n",
    "# axs[0].text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153790253156762\n",
      "3.433443601168519\n"
     ]
    }
   ],
   "source": [
    "mstl = MSTL(time_series, periods=[6, 12]).fit()\n",
    "# mstl = STL(time_series, period=12, seasonal=13).fit()\n",
    "# mstl.plot()\n",
    "\n",
    "reconstructed_series = mstl.trend + mstl.seasonal['seasonal_6'] + mstl.seasonal['seasonal_12']\n",
    "\n",
    "plt.plot(time_series.index, time_series.values, color='k', linewidth=1.5, label='Original time series')\n",
    "plt.plot(time_series.index, reconstructed_series, color='r', linewidth=1.5, label='Reconstructed time series')\n",
    "\n",
    "print(r2_score(time_series.values, reconstructed_series))\n",
    "rmse = np.sqrt(np.mean((time_series.values - reconstructed_series)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.935378130989653\n",
      "2.568261810609259\n",
      "[0.8381969]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.seasonal import STL, MSTL\n",
    "import Rbeast as rb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "res = STL(time_series, period=12, seasonal=13).fit()\n",
    "res_B = rb.beast(ts.values, start=[ts.index[0].year, ts.index[0].month, ts.index[0].day], season='harmonic', deltat='1/12 year', period='1 year', quiet=True, print_progress=False)\n",
    "# rb.plot(res_B)\n",
    "# res.plot()\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20,20), sharex=True)\n",
    "\n",
    "# plot time series and trends\n",
    "axs[0].plot(ts.index, ts, color='k', linewidth=2, ls=':', label='Preprocessed time series')\n",
    "axs[0].plot(ts.index, res.trend, color='#003F5C', label='STL (trend component)', linewidth=2)\n",
    "axs[0].plot(ts.index, res_B.trend.Y, color='#BC5090', label='BEAST (trend component)', linewidth=2)\n",
    "for ii, b in enumerate(res_B.trend.cp[:3]):\n",
    "\n",
    "    if np.isnan(b):\n",
    "        continue\n",
    "\n",
    "    fractional_yeard = b\n",
    "    # Separate the year and the fraction\n",
    "    yeard = int(fractional_yeard)\n",
    "    fractiond = fractional_yeard - yeard\n",
    "\n",
    "    # Calculate the number of days in the given year\n",
    "    days_in_year = (datetime(yeard + 1, 1, 1) - datetime(yeard, 1, 1)).days\n",
    "\n",
    "    # Calculate the number of days corresponding to the fractional part\n",
    "    daysd = round(fractiond * days_in_year)\n",
    "\n",
    "    # Get the final date by adding the days to the start of the year\n",
    "    dated = datetime(yeard, 1, 1) + timedelta(days=daysd)\n",
    "\n",
    "    formatted_dated = dated.strftime('%Y-%m-%d')\n",
    "\n",
    "    # datetime format\n",
    "    d = datetime.strptime(formatted_dated, '%Y-%m-%d')\n",
    "    \n",
    "    if ii == 0:\n",
    "        axs[0].axvline(d, color='#BC5090', linestyle='--', linewidth=2, label='BEAST (breakpoints)')\n",
    "    else:\n",
    "        axs[0].axvline(d, color='#BC5090', linestyle='--', linewidth=2)\n",
    "\n",
    "\n",
    "axs[0].fill_between(ts.index, res_B.trend.CI[:, 0], res_B.trend.CI[:, 1], alpha=0.2, color='#BC5090')\n",
    "axs[0].set_xlim(ts.index[0], ts.index[-1])\n",
    "axs[0].text(datetime(2020, 3, 1), 97, 'pIOD', fontsize=25, fontweight='bold')\n",
    "axs[0].text(datetime(2020, 3, 1), 97, 'pIOD', fontsize=25, fontweight='bold')\n",
    "axs[0].legend(fontsize=15, loc='upper left')\n",
    "axs[1].set_xlim(ts.index[0], ts.index[-1])\n",
    "axs[2].set_xlim(ts.index[0], ts.index[-1])\n",
    "\n",
    "\n",
    "axs[1].plot(ts.index, res.seasonal, color='#003F5C', label='STL (seasonal component)', linewidth=2)\n",
    "axs[1].plot(ts.index, res_B.season.Y, color='#BC5090', label='BEAST (seasonal component)', linewidth=2)\n",
    "axs[1].fill_between(ts.index, res_B.season.CI[:, 0], res_B.season.CI[:, 1], alpha=0.2, color='#BC5090')\n",
    "# ax.fill_between(ts.index, res.seasonal - res.seasonal, res.seasonal + res.seasonal, color='seagreen', alpha=0.3)\n",
    "axs[1].set_xlim(ts.index[0], ts.index[-1])\n",
    "axs[1].legend(fontsize=15, loc='upper left')\n",
    "axs[2].set_xlabel('Time', fontsize=20)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[2].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=12)\n",
    "axs[1].set_ylabel('Amplitude (m)', fontsize=20)\n",
    "axs[0].set_ylabel('Amplitude (m)', fontsize=20)\n",
    "axs[2].set_ylabel('Amplitude (m)', fontsize=20)\n",
    "\n",
    "# Plot residuals\n",
    "\n",
    "# custom the stem lines\n",
    "(markers, stemlines, baseline) = axs[2].stem(ts.index, res.resid, label='STL (residuals)')\n",
    "plt.setp(stemlines, linestyle=\"-\", color='#003F5C')\n",
    "plt.setp(markers, color='#003F5C', marker='o', markersize=5)\n",
    "plt.setp(baseline, color=\"black\", linewidth=1)\n",
    "(markers, stemlines, baseline) = axs[2].stem(ts.index, res_B.data - res_B.season.Y - res_B.trend.Y, label='BEAST (residuals)')\n",
    "plt.setp(stemlines, linestyle=\"-\", color='#BC5090')\n",
    "plt.setp(markers, color='#BC5090', marker='v')\n",
    "plt.setp(baseline, color=\"black\", linewidth=1)\n",
    "\n",
    "# axs[2].plot(ts.index, res_B.data - res_B.season.Y - res_B.trend.Y, color='#BC5090', label='BEAST (residuals)', linewidth=2)\n",
    "axs[2].legend(fontsize=15, loc='upper left')\n",
    "\n",
    "plt.savefig('figures//STL_BEAST_new.png', dpi=300)\n",
    "\n",
    "# calculate r2 for STL and BEAST\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_stl = r2_score(res.seasonal, res_B.season.Y)\n",
    "\n",
    "print(r2_stl)\n",
    "\n",
    "rmse = np.sqrt(np.mean((res.seasonal - res_B.season.Y)**2))\n",
    "\n",
    "print(rmse)\n",
    "\n",
    "print(res_B.R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x178f094b0e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find peaks in seasonal component\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "peaks_beast, _ = find_peaks(res_B.season.Y, height=0)\n",
    "# find minima\n",
    "minima_beast = argrelextrema(res_B.season.Y, np.less)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(ts.index, res.seasonal, color='k', label='STL (seasonal component)', linewidth=2)\n",
    "ax.plot(ts.index, res_B.season.Y, color='r', label='BEAST (seasonal component)', linewidth=2)\n",
    "ax.fill_between(ts.index, res_B.season.CI[:, 0], res_B.season.CI[:, 1], alpha=0.2, color='r')\n",
    "ax.scatter(ts.index[peaks_beast], res_B.season.Y[peaks_beast], color='r', marker='o', s=50, label='BEAST peaks')\n",
    "ax.scatter(ts.index[minima_beast], res_B.season.Y[minima_beast], color='r', marker='v', s=50, label='BEAST minima')\n",
    "ax.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.956824626848461"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((res.seasonal - res_B.season.Y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21e4d429460>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(abs(res.seasonal - res_B.season.Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(5, 0.2, '')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falig, ax = plt.subplots()\n",
    "# plt.imshow(im)\n",
    "ax.plot(np.arange(10), np.sin(np.arange(10)))\n",
    "ax.annotate('', xy=(0, 0), xytext=(5, 0.2),\n",
    "             arrowprops=dict(arrowstyle='<->', color='black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file for islands to ignore\n",
    "import shapely.geometry\n",
    "\n",
    "df_islands_ignore = pd.read_excel('islands_to_ignore.xlsx')\n",
    "list_islands_ignore = df_islands_ignore['Island'].values\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "multi_point = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    if island in list_islands_ignore:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "        lat, lon = island_info['spatial_reference']['latitude'], island_info['spatial_reference']['longitude']\n",
    "        all_dict = pd.read_pickle(os.path.join(os.getcwd(), 'data', 'coastsat_data', '{}_{}'.format(island, country), 'all_polygons_{}_{}.data'.format(island, country)))\n",
    "        best_dict = pd.read_pickle(os.path.join(os.getcwd(), 'data', 'coastsat_data', '{}_{}'.format(island, country), 'best_polygons_{}_{}.data'.format(island, country)))\n",
    "\n",
    "        point = shapely.geometry.Point(lon, lat)\n",
    "\n",
    "        key = list(best_dict.keys())[0]\n",
    "        dict_georef = all_dict[2]\n",
    "        dict_rgb_ts = all_dict[1]\n",
    "        dict_poly = all_dict[0]\n",
    "\n",
    "        aff_mat = np.array([[dict_georef[key][1], dict_georef[key][2], dict_georef[key][0]],\n",
    "                            [dict_georef[key][4], dict_georef[key][5], dict_georef[key][3]],\n",
    "                            [0, 0, 1]])\n",
    "\n",
    "        # Create affine transformation\n",
    "        import skimage.transform as transform\n",
    "        tform = transform.AffineTransform(aff_mat)\n",
    "\n",
    "        polygon = dict_poly[key]['polygon_NIR_otsu']\n",
    "        x_poly, y_poly  = polygon.exterior.coords.xy\n",
    "\n",
    "        # Transform polygon\n",
    "        tmp = np.column_stack((x_poly, y_poly))\n",
    "        points_converted = tform(tmp)\n",
    "        poly_image_crs = shapely.geometry.Polygon(points_converted)\n",
    "\n",
    "        # area\n",
    "        area = poly_image_crs.area\n",
    "        compactness = (4 * np.pi * poly_image_crs.area) / (poly_image_crs.length ** 2)\n",
    "        convex_hull = poly_image_crs.convex_hull\n",
    "        solidity = poly_image_crs.area / convex_hull.area\n",
    "        bounding_box = poly_image_crs.bounds\n",
    "        min_rotated_rect = poly_image_crs.minimum_rotated_rectangle\n",
    "        mrr_coords = list(min_rotated_rect.exterior.coords)\n",
    "        major_axis = max([mrr_coords[i][0] - mrr_coords[i-1][0] for i in range(len(mrr_coords))])\n",
    "        minor_axis = max([mrr_coords[i][1] - mrr_coords[i-1][1] for i in range(len(mrr_coords))])\n",
    "        elongation = major_axis / minor_axis\n",
    "\n",
    "        def calculate_curvature(polygon):\n",
    "            coords = np.array(polygon.exterior.coords)\n",
    "            angles = []\n",
    "            for i in range(len(coords) - 2):\n",
    "                v1 = coords[i+1] - coords[i]\n",
    "                v2 = coords[i+2] - coords[i+1]\n",
    "                angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "                if not np.isnan(angle):\n",
    "                    angles.append(angle)\n",
    "            return np.mean(angles)\n",
    "\n",
    "        avg_curvature = calculate_curvature(poly_image_crs)\n",
    "\n",
    "        # save area, compactness, solidity, elongation, avg_curvature into point\n",
    "\n",
    "        \n",
    "    except:\n",
    "        print('Error with island:', island)\n",
    "        continue\n",
    "\n",
    "mp = shapely.geometry.MultiPoint(multi_point)\n",
    "gdf = gpd.GeoDataFrame(geometry=[mp], crs='EPSG:4326')\n",
    "# gdf.to_file('shp//Huvadhoo_included.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps for islands with seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 303/406 [01:28<00:14,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with island: Mathihuttaa - IllegalArgumentException: Points of LinearRing do not form a closed linestring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 406/406 [01:48<00:00,  3.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shapely.geometry\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import skimage.transform as transform\n",
    "\n",
    "# Read file for islands to ignore\n",
    "df_islands_ignore = pd.read_excel('islands_to_ignore.xlsx')\n",
    "list_islands_ignore = df_islands_ignore['Island'].values\n",
    "islands_HA = pd.read_excel('Huvadhoo_islands.xlsx')\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "# List to store the data\n",
    "data_list = []\n",
    "data_list_ns = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    if island in list_islands_ignore:\n",
    "        continue\n",
    "\n",
    "    if island not in islands_HA['island'].values:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "        lat, lon = island_info['spatial_reference']['latitude'], island_info['spatial_reference']['longitude']\n",
    "        point = shapely.geometry.Point(lon, lat)\n",
    "        if 'timeseries_analysis' not in island_info:\n",
    "            continue\n",
    "        ts_analysis_results = island_info['timeseries_analysis']\n",
    "\n",
    "        if 'conditions_seasonality' in ts_analysis_results[list(ts_analysis_results.keys())[0]]['seasonality'].keys():\n",
    "            cond = [sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 for val in ts_analysis_results.keys()]\n",
    "            # print(island, sum(cond))\n",
    "            if sum(cond) > 5:\n",
    "                data_list.append(point)\n",
    "            \n",
    "            else:\n",
    "                data_list_ns.append(point)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error with island: {island} - {str(e)}')\n",
    "        continue\n",
    "\n",
    "\n",
    "mp = shapely.geometry.MultiPoint(data_list)\n",
    "gdf = gpd.GeoDataFrame(geometry=[mp], crs='EPSG:4326')\n",
    "mp_ns = shapely.geometry.MultiPoint(data_list_ns)\n",
    "gdf_ns = gpd.GeoDataFrame(geometry=[mp_ns], crs='EPSG:4326')\n",
    "\n",
    "# Create GeoDataFrame\n",
    "# gdf = gpd.GeoDataFrame(data_list, crs='EPSG:4326')\n",
    "\n",
    "# Save to shapefile\n",
    "gdf.to_file('shp//islands_with_seasonality_cond3.shp')\n",
    "gdf_ns.to_file('shp//islands_without_seasonality_cond3.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of islands inside Huvadhoo Atoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 137/406 [00:30<00:32,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with island: Heenaamaagalaa - Ran out of input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 193/406 [00:39<01:30,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with island: Kalherehaa - Ran out of input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 406/406 [01:20<00:00,  5.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read file for islands to ignore\n",
    "import pyproj\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import shapely\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from IslandTime import retrieve_island_info\n",
    "import geopandas as gpd\n",
    "df_islands_ignore = pd.read_excel('islands_to_ignore.xlsx')\n",
    "list_islands_ignore = df_islands_ignore['Island'].values\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "huvadhu_atoll = ox.geocode_to_gdf('Huvadhu Atoll, Maldives')\n",
    "huvadhu_atoll_box = [huvadhu_atoll.bbox_north.values[0], \\\n",
    "                huvadhu_atoll.bbox_west.values[0], \\\n",
    "                huvadhu_atoll.bbox_south.values[0], \\\n",
    "                huvadhu_atoll.bbox_east.values[0]]\n",
    "\n",
    "# create polygon with the bounding box\n",
    "huvadhu_atoll_polygon = shapely.geometry.Polygon([(huvadhu_atoll_box[1], huvadhu_atoll_box[0]), \\\n",
    "                                                (huvadhu_atoll_box[1], huvadhu_atoll_box[2]), \\\n",
    "                                                (huvadhu_atoll_box[3], huvadhu_atoll_box[2]), \\\n",
    "                                                (huvadhu_atoll_box[3], huvadhu_atoll_box[0])])\n",
    "\n",
    "\n",
    "data_list = []\n",
    "data_not = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    # if island in list_islands_ignore:\n",
    "    #     continue\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "        lat, lon = island_info['spatial_reference']['latitude'], island_info['spatial_reference']['longitude']\n",
    "        point = shapely.geometry.Point(lon, lat)\n",
    "        if huvadhu_atoll_polygon.contains(point):\n",
    "            data_list.append(\n",
    "                {\n",
    "                    'island': island,\n",
    "                    'country': country,\n",
    "                    'geometry': point\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            data_not.append(\n",
    "                {\n",
    "                    'island': island,\n",
    "                    'country': country,\n",
    "                    'geometry': point\n",
    "                }                \n",
    "            )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error with island: {island} - {str(e)}')\n",
    "        continue\n",
    "\n",
    "gdf = gpd.GeoDataFrame(data_list, crs='EPSG:4326')\n",
    "gdf_not = gpd.GeoDataFrame(data_not, crs='EPSG:4326')\n",
    "\n",
    "gdf.to_file('shp//Huvadhoo_islands.shp')\n",
    "gdf_not.to_file('shp//not_Huvadhoo_islands.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('Huvadhoo_islands.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps for seasonality minima, peaks, and amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 303/406 [01:37<00:12,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with island: Mathihuttaa - IllegalArgumentException: Points of LinearRing do not form a closed linestring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 406/406 [01:56<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read file for islands to ignore\n",
    "import pyproj\n",
    "import pandas as pd\n",
    "df_islands_ignore = pd.read_excel('islands_to_ignore.xlsx')\n",
    "list_islands_ignore = df_islands_ignore['Island'].values\n",
    "islands_HA = pd.read_excel('Huvadhoo_islands.xlsx')\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    if island in list_islands_ignore:\n",
    "        continue\n",
    "\n",
    "    if not island in islands_HA['island'].values:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "    \n",
    "        if 'timeseries_analysis' in island_info.keys():\n",
    "            if island_info['timeseries_analysis'] != {}:\n",
    "\n",
    "                lon, lat = island_info['spatial_reference']['longitude'], island_info['spatial_reference']['latitude']\n",
    "                \n",
    "                \n",
    "                # Extract reference shoreline and transects\n",
    "                reference_shoreline = island_info['spatial_reference']['reference_shoreline']\n",
    "                transects = island_info['spatial_reference']['transects']\n",
    "\n",
    "                # Create a polygon from the reference shoreline\n",
    "                polygon_reference_shoreline = shapely.geometry.Polygon(reference_shoreline)\n",
    "\n",
    "                # Short cut for the time series analysis results\n",
    "                ts_analysis_results = island_info['timeseries_analysis']\n",
    "\n",
    "                # Extract the key of the transects\n",
    "                key_transects = [int((key).split('_')[3]) for key in ts_analysis_results.keys()]\n",
    "\n",
    "                # Extract the intersection between the reference shoreline and the transects\n",
    "                x_intersections, y_intersections = [], []\n",
    "                try:\n",
    "                    intersections = [polygon_reference_shoreline.exterior.intersection(shapely.geometry.LineString(transects[key_transect])) for key_transect in key_transects]\n",
    "                except:\n",
    "                    continue\n",
    "                for intersection in intersections:\n",
    "                    if type(intersection) == shapely.geometry.MultiPoint:\n",
    "                        # Take the first point of the MultiPoint\n",
    "                        x_intersections.append(intersection.geoms[0].x)\n",
    "                        y_intersections.append(intersection.geoms[0].y)\n",
    "\n",
    "                    elif type(intersection) == shapely.geometry.LineString:\n",
    "                        x_intersections.append(0.)\n",
    "                        y_intersections.append(0.)\n",
    "\n",
    "                    else:\n",
    "                        x_intersections.append(intersection.x)\n",
    "                        y_intersections.append(intersection.y)\n",
    "\n",
    "                # Reproject the coordinates to the Web Mercator projection\n",
    "                # Source and target coordinate reference systems\n",
    "                tgt_crs = pyproj.CRS('EPSG:4326')\n",
    "                src_crs = pyproj.CRS('EPSG:3857')\n",
    "\n",
    "                # Define transformer\n",
    "                transformer = pyproj.Transformer.from_crs(src_crs, tgt_crs, always_xy=True)\n",
    "\n",
    "                # # Transform latitude and longitude to x and y\n",
    "                x_intersections, y_intersections = transformer.transform(x_intersections, y_intersections)\n",
    "\n",
    "                # Transform reference shoreline to x and y\n",
    "                x_reference_shoreline, y_reference_shoreline = transformer.transform(polygon_reference_shoreline.exterior.coords.xy[0], polygon_reference_shoreline.exterior.coords.xy[1])\n",
    "\n",
    "                # Trend splot and results (colorbar = trend slope and symbol = trend result)\n",
    "                c_trend = [ts_analysis_results[val]['trend']['trend_slope'] for val in ts_analysis_results.keys()]\n",
    "                symbols_trend = [ts_analysis_results[val]['trend']['trend_result'] for val in ts_analysis_results.keys()]\n",
    "\n",
    "                # Seasonality amplitude results (colorbar = seasonality amplitude)\n",
    "                if 'amplitude_seasonal_BEAST_absrange' in ts_analysis_results[list(ts_analysis_results.keys())[0]]['seasonality'].keys():\n",
    "                    c_seasonality_amplitude = [ts_analysis_results[val]['seasonality']['amplitude_seasonal_STL_absrange'] for val in ts_analysis_results.keys()]\n",
    "                    c_seasonality_amplitude_BEAST = [ts_analysis_results[val]['seasonality']['amplitude_seasonal_BEAST_absrange'] for val in ts_analysis_results.keys()]\n",
    "\n",
    "                else:\n",
    "                    c_seasonality_amplitude = [0. for val in ts_analysis_results.keys()]\n",
    "\n",
    "                # Seasonality peaks and minima results\n",
    "                if 'conditions_seasonality' in ts_analysis_results[list(ts_analysis_results.keys())[0]]['seasonality'].keys():\n",
    "                    c_seasonality_peaks = [ts_analysis_results[val]['seasonality']['seasonality_indian_monsoon_peaks'] if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 else 'undetermined' for val in ts_analysis_results.keys()]\n",
    "                    c_seasonality_minima = [ts_analysis_results[val]['seasonality']['seasonality_indian_monsoon_minima'] if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 else 'undetermined' for val in ts_analysis_results.keys()]\n",
    "                    c_seasonality_peaks_BEAST = [ts_analysis_results[val]['seasonality']['seasonality_indian_monsoon_peaks_BEAST'] if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 else 'undetermined' for val in ts_analysis_results.keys()]\n",
    "                    c_seasonality_minima_BEAST = [ts_analysis_results[val]['seasonality']['seasonality_indian_monsoon_minima_BEAST'] if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 else 'undetermined' for val in ts_analysis_results.keys()]\n",
    "                \n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                # Add data to list\n",
    "                for x in range(len(x_intersections)):\n",
    "                    data_list.append({\n",
    "                        'island': island,\n",
    "                        'country': country,\n",
    "                        'geometry': shapely.geometry.Point(x_intersections[x], y_intersections[x]),\n",
    "                        'aSTL': c_seasonality_amplitude[x],\n",
    "                        'aBEAST': c_seasonality_amplitude_BEAST[x],\n",
    "                        'pSTL': c_seasonality_peaks[x],\n",
    "                        'mSTL': c_seasonality_minima[x],\n",
    "                        'pBEAST': c_seasonality_peaks_BEAST[x],\n",
    "                        'mBEAST': c_seasonality_minima_BEAST[x]\n",
    "                    })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error with island: {island} - {str(e)}')\n",
    "        continue\n",
    "\n",
    "gdf = gpd.GeoDataFrame(data_list, crs='EPSG:4326')\n",
    "gdf.to_file('shp//islands_seasonality_cond3_results.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map of aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file for islands to ignore\n",
    "import pyproj\n",
    "df_islands_ignore = pd.read_excel('islands_to_ignore.xlsx')\n",
    "list_islands_ignore = df_islands_ignore['Island'].values\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)[:2]):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    if island in list_islands_ignore:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "    \n",
    "        if 'timeseries_analysis' in island_info.keys():\n",
    "            if island_info['timeseries_analysis'] != {}:\n",
    "\n",
    "                lon, lat = island_info['spatial_reference']['longitude'], island_info['spatial_reference']['latitude']\n",
    "                \n",
    "                \n",
    "                # Extract reference shoreline and transects\n",
    "                reference_shoreline = island_info['spatial_reference']['reference_shoreline']\n",
    "                transects = island_info['spatial_reference']['transects']\n",
    "\n",
    "                # Create a polygon from the reference shoreline\n",
    "                polygon_reference_shoreline = shapely.geometry.Polygon(reference_shoreline)\n",
    "\n",
    "                # Short cut for the time series analysis results\n",
    "                ts_analysis_results = island_info['timeseries_analysis']\n",
    "                ts_analysis_agg = island_info['timeseries_aggregate']\n",
    "\n",
    "                # # Extract the key of the transects\n",
    "                # key_transects = [int((key).split('_')[3]) for key in ts_analysis_results.keys()]\n",
    "\n",
    "                # # Extract the intersection between the reference shoreline and the transects\n",
    "                # x_intersections, y_intersections = [], []\n",
    "                # try:\n",
    "                #     intersections = [polygon_reference_shoreline.exterior.intersection(shapely.geometry.LineString(transects[key_transect])) for key_transect in key_transects]\n",
    "                # except:\n",
    "                #     continue\n",
    "                # for intersection in intersections:\n",
    "                #     if type(intersection) == shapely.geometry.MultiPoint:\n",
    "                #         # Take the first point of the MultiPoint\n",
    "                #         x_intersections.append(intersection.geoms[0].x)\n",
    "                #         y_intersections.append(intersection.geoms[0].y)\n",
    "\n",
    "                #     elif type(intersection) == shapely.geometry.LineString:\n",
    "                #         x_intersections.append(0.)\n",
    "                #         y_intersections.append(0.)\n",
    "\n",
    "                #     else:\n",
    "                #         x_intersections.append(intersection.x)\n",
    "                #         y_intersections.append(intersection.y)\n",
    "\n",
    "                # # Reproject the coordinates to the Web Mercator projection\n",
    "                # # Source and target coordinate reference systems\n",
    "                # tgt_crs = pyproj.CRS('EPSG:4326')\n",
    "                # src_crs = pyproj.CRS('EPSG:3857')\n",
    "\n",
    "                # # Define transformer\n",
    "                # transformer = pyproj.Transformer.from_crs(src_crs, tgt_crs, always_xy=True)\n",
    "\n",
    "                # # # Transform latitude and longitude to x and y\n",
    "                # x_intersections, y_intersections = transformer.transform(x_intersections, y_intersections)\n",
    "\n",
    "                # # Transform reference shoreline to x and y\n",
    "                # x_reference_shoreline, y_reference_shoreline = transformer.transform(polygon_reference_shoreline.exterior.coords.xy[0], polygon_reference_shoreline.exterior.coords.xy[1])\n",
    "\n",
    "                # # Trend splot and results (colorbar = trend slope and symbol = trend result)\n",
    "                # c_trend = [ts_analysis_results[val]['trend']['trend_slope'] for val in ts_analysis_results.keys()]\n",
    "                # symbols_trend = [ts_analysis_results[val]['trend']['trend_result'] for val in ts_analysis_results.keys()]\n",
    "\n",
    "                # # Seasonality amplitude results (colorbar = seasonality amplitude)\n",
    "                # if 'amplitude_seasonal_BEAST_absrange' in ts_analysis_results[list(ts_analysis_results.keys())[0]]['seasonality'].keys():\n",
    "                #     c_seasonality_amplitude = [ts_analysis_results[val]['seasonality']['amplitude_seasonal_STL_absrange'] for val in ts_analysis_results.keys()]\n",
    "                #     c_seasonality_amplitude_BEAST = [ts_analysis_results[val]['seasonality']['amplitude_seasonal_BEAST_absrange'] for val in ts_analysis_results.keys()]\n",
    "\n",
    "                # else:\n",
    "                #     c_seasonality_amplitude = [0. for val in ts_analysis_results.keys()]\n",
    "\n",
    "                # # Seasonality peaks and minima results\n",
    "                # if 'conditions_seasonality' in ts_analysis_results[list(ts_analysis_results.keys())[0]]['seasonality'].keys():\n",
    "                #     c_seasonality_peaks = [ts_analysis_results[val]['seasonality']['seasonality_indian_monsoon_peaks'] if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 else 'undetermined' for val in ts_analysis_results.keys()]\n",
    "                #     c_seasonality_minima = [ts_analysis_results[val]['seasonality']['seasonality_indian_monsoon_minima'] if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 else 'undetermined' for val in ts_analysis_results.keys()]\n",
    "                #     c_seasonality_peaks_BEAST = [ts_analysis_results[val]['seasonality']['seasonality_indian_monsoon_peaks_BEAST'] if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 else 'undetermined' for val in ts_analysis_results.keys()]\n",
    "                #     c_seasonality_minima_BEAST = [ts_analysis_results[val]['seasonality']['seasonality_indian_monsoon_minima_BEAST'] if sum(ts_analysis_results[val]['seasonality']['conditions_seasonality'].values()) >= 3 else 'undetermined' for val in ts_analysis_results.keys()]\n",
    "                \n",
    "                # else:\n",
    "                #     continue\n",
    "                    \n",
    "                # # Add data to list\n",
    "                # for x in range(len(x_intersections)):\n",
    "                #     data_list.append({\n",
    "                #         'island': island,\n",
    "                #         'country': country,\n",
    "                #         'geometry': shapely.geometry.Point(x_intersections[x], y_intersections[x]),\n",
    "                #         'aSTL': c_seasonality_amplitude[x],\n",
    "                #         'aBEAST': c_seasonality_amplitude_BEAST[x],\n",
    "                #         'pSTL': c_seasonality_peaks[x],\n",
    "                #         'mSTL': c_seasonality_minima[x],\n",
    "                #         'pBEAST': c_seasonality_peaks_BEAST[x],\n",
    "                #         'mBEAST': c_seasonality_minima_BEAST[x]\n",
    "                #     })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error with island: {island} - {str(e)}')\n",
    "        continue\n",
    "\n",
    "# gdf = gpd.GeoDataFrame(data_list, crs='EPSG:4326')\n",
    "# gdf.to_file('shp//islands_seasonality_results.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map of reference shorelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 193/406 [00:48<01:33,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with island: Kalherehaa - Ran out of input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 406/406 [01:37<00:00,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read file for islands to ignore\n",
    "import pyproj\n",
    "df_islands_ignore = pd.read_excel('islands_to_ignore.xlsx')\n",
    "list_islands_ignore = df_islands_ignore['Island'].values\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "    \n",
    "        if 'timeseries_analysis' in island_info.keys():\n",
    "            if island_info['timeseries_analysis'] != {}:\n",
    "\n",
    "                lon, lat = island_info['spatial_reference']['longitude'], island_info['spatial_reference']['latitude']\n",
    "                \n",
    "                \n",
    "                # Extract reference shoreline and transects\n",
    "                reference_shoreline = island_info['spatial_reference']['reference_shoreline']\n",
    "                transects = island_info['spatial_reference']['transects']\n",
    "\n",
    "                # Create a polygon from the reference shoreline\n",
    "                polygon_reference_shoreline = shapely.geometry.Polygon(reference_shoreline)\n",
    "\n",
    "                # Reproject the coordinates to the Web Mercator projection\n",
    "                # Source and target coordinate reference systems\n",
    "                tgt_crs = pyproj.CRS('EPSG:4326')\n",
    "                src_crs = pyproj.CRS('EPSG:3857')\n",
    "\n",
    "                # Define transformer\n",
    "                transformer = pyproj.Transformer.from_crs(src_crs, tgt_crs, always_xy=True)\n",
    "\n",
    "                # Transform reference shoreline to x and y\n",
    "                x_reference_shoreline, y_reference_shoreline = transformer.transform(polygon_reference_shoreline.exterior.coords.xy[0], polygon_reference_shoreline.exterior.coords.xy[1])\n",
    "\n",
    "                # Create a LineString from the reference shoreline\n",
    "                line_reference_shoreline = shapely.geometry.LineString(zip(x_reference_shoreline, y_reference_shoreline))\n",
    "\n",
    "                data_list.append({\n",
    "                    'island': island,\n",
    "                    'country': country,\n",
    "                    'geometry': line_reference_shoreline\n",
    "                })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error with island: {island} - {str(e)}')\n",
    "        continue\n",
    "\n",
    "gdf = gpd.GeoDataFrame(data_list, crs='EPSG:4326')\n",
    "\n",
    "gdf.to_file('shp//islands_reference_shoreline.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps for polygon metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------\n",
      "Calculating island metrics (area, compactness, solidity, elongation, average curvature)\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:16<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from IslandTime import Features, retrieve_island_info\n",
    "\n",
    "ii = Features(gdf_all_islands=True, overwrite=True).main()\n",
    "\n",
    "# ii = retrieve_island_info('Aakiraahuttaa', 'Maldives', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>country</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area</th>\n",
       "      <th>compactness</th>\n",
       "      <th>solidity</th>\n",
       "      <th>elongation</th>\n",
       "      <th>avg_curvature</th>\n",
       "      <th>compactnes</th>\n",
       "      <th>avg_curvat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baulhegalla</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.17252 0.49499)</td>\n",
       "      <td>4.129700e+04</td>\n",
       "      <td>0.916788</td>\n",
       "      <td>0.990704</td>\n",
       "      <td>1.070128</td>\n",
       "      <td>1.056035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berasdhoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.54034 1.96825)</td>\n",
       "      <td>6.860008e+05</td>\n",
       "      <td>0.375860</td>\n",
       "      <td>0.694924</td>\n",
       "      <td>0.414228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berinmadhoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (72.97158 7.04707)</td>\n",
       "      <td>1.588193e+05</td>\n",
       "      <td>0.607160</td>\n",
       "      <td>0.922552</td>\n",
       "      <td>0.430827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyrumaddoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.22494 0.79480)</td>\n",
       "      <td>2.437996e+04</td>\n",
       "      <td>0.744893</td>\n",
       "      <td>0.993769</td>\n",
       "      <td>0.598757</td>\n",
       "      <td>0.727421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bileffahi</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (72.97570 6.33794)</td>\n",
       "      <td>6.844993e+05</td>\n",
       "      <td>0.414918</td>\n",
       "      <td>0.775258</td>\n",
       "      <td>0.780705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bileitheyrahaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.53591 2.05687)</td>\n",
       "      <td>1.355695e+05</td>\n",
       "      <td>0.163766</td>\n",
       "      <td>0.562536</td>\n",
       "      <td>0.519623</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boaddoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.33053 0.70559)</td>\n",
       "      <td>2.108613e+04</td>\n",
       "      <td>0.984788</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>1.057241</td>\n",
       "      <td>0.836168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bodehutta (Gaafu Dhaalu)</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.34759 0.25393)</td>\n",
       "      <td>1.967425e+05</td>\n",
       "      <td>0.234502</td>\n",
       "      <td>0.506443</td>\n",
       "      <td>0.873940</td>\n",
       "      <td>0.946299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bodehuttaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.57211 0.41316)</td>\n",
       "      <td>8.125241e+04</td>\n",
       "      <td>0.387323</td>\n",
       "      <td>0.688880</td>\n",
       "      <td>1.260047</td>\n",
       "      <td>0.995556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Boderehaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.01241 0.38621)</td>\n",
       "      <td>5.800243e+04</td>\n",
       "      <td>0.580158</td>\n",
       "      <td>0.847230</td>\n",
       "      <td>0.475620</td>\n",
       "      <td>1.481835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakiraahuttaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.08961 0.26550)</td>\n",
       "      <td>7.271319e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.911357</td>\n",
       "      <td>0.899713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755075</td>\n",
       "      <td>0.818931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aligaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.51679 5.24397)</td>\n",
       "      <td>2.215762e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789404</td>\n",
       "      <td>1.699094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angolhitheemu</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.00639 5.79286)</td>\n",
       "      <td>4.098078e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983549</td>\n",
       "      <td>0.541912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746773</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Araigaththaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.53508 0.45210)</td>\n",
       "      <td>5.083035e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.970780</td>\n",
       "      <td>1.294121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869168</td>\n",
       "      <td>0.774708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athahedha</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.28583 1.81046)</td>\n",
       "      <td>2.673005e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>1.015568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668241</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Athihuttaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.06263 0.28027)</td>\n",
       "      <td>1.079194e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899582</td>\n",
       "      <td>1.079226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640667</td>\n",
       "      <td>1.003918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baarah</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.21320 6.81693)</td>\n",
       "      <td>2.643521e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829469</td>\n",
       "      <td>0.966377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418904</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baavanadhoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.53996 0.52170)</td>\n",
       "      <td>5.763086e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953048</td>\n",
       "      <td>0.431106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.467027</td>\n",
       "      <td>0.734059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Badefodiyaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.06062 0.28153)</td>\n",
       "      <td>2.709738e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994855</td>\n",
       "      <td>1.714911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877092</td>\n",
       "      <td>0.902388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bakeiththaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.49774 0.38097)</td>\n",
       "      <td>2.277736e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.949376</td>\n",
       "      <td>1.421685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.758530</td>\n",
       "      <td>1.510669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     island   country                  geometry          area  \\\n",
       "0               Baulhegalla  Maldives  POINT (73.17252 0.49499)  4.129700e+04   \n",
       "1                 Berasdhoo  Maldives  POINT (73.54034 1.96825)  6.860008e+05   \n",
       "2               Berinmadhoo  Maldives  POINT (72.97158 7.04707)  1.588193e+05   \n",
       "3               Beyrumaddoo  Maldives  POINT (73.22494 0.79480)  2.437996e+04   \n",
       "4                 Bileffahi  Maldives  POINT (72.97570 6.33794)  6.844993e+05   \n",
       "5            Bileitheyrahaa  Maldives  POINT (73.53591 2.05687)  1.355695e+05   \n",
       "6                   Boaddoo  Maldives  POINT (73.33053 0.70559)  2.108613e+04   \n",
       "7  Bodehutta (Gaafu Dhaalu)  Maldives  POINT (73.34759 0.25393)  1.967425e+05   \n",
       "8                Bodehuttaa  Maldives  POINT (73.57211 0.41316)  8.125241e+04   \n",
       "9                 Boderehaa  Maldives  POINT (73.01241 0.38621)  5.800243e+04   \n",
       "0             Aakiraahuttaa  Maldives  POINT (73.08961 0.26550)  7.271319e+04   \n",
       "1                    Aligaa  Maldives  POINT (73.51679 5.24397)  2.215762e+04   \n",
       "2             Angolhitheemu  Maldives  POINT (73.00639 5.79286)  4.098078e+05   \n",
       "3              Araigaththaa  Maldives  POINT (73.53508 0.45210)  5.083035e+04   \n",
       "4                 Athahedha  Maldives  POINT (73.28583 1.81046)  2.673005e+04   \n",
       "5                Athihuttaa  Maldives  POINT (73.06263 0.28027)  1.079194e+05   \n",
       "6                    Baarah  Maldives  POINT (73.21320 6.81693)  2.643521e+06   \n",
       "7               Baavanadhoo  Maldives  POINT (73.53996 0.52170)  5.763086e+04   \n",
       "8               Badefodiyaa  Maldives  POINT (73.06062 0.28153)  2.709738e+04   \n",
       "9               Bakeiththaa  Maldives  POINT (73.49774 0.38097)  2.277736e+04   \n",
       "\n",
       "   compactness  solidity  elongation  avg_curvature  compactnes  avg_curvat  \n",
       "0     0.916788  0.990704    1.070128       1.056035         NaN         NaN  \n",
       "1     0.375860  0.694924    0.414228       0.000000         NaN         NaN  \n",
       "2     0.607160  0.922552    0.430827       0.000000         NaN         NaN  \n",
       "3     0.744893  0.993769    0.598757       0.727421         NaN         NaN  \n",
       "4     0.414918  0.775258    0.780705       0.000000         NaN         NaN  \n",
       "5     0.163766  0.562536    0.519623       0.000158         NaN         NaN  \n",
       "6     0.984788  0.999812    1.057241       0.836168         NaN         NaN  \n",
       "7     0.234502  0.506443    0.873940       0.946299         NaN         NaN  \n",
       "8     0.387323  0.688880    1.260047       0.995556         NaN         NaN  \n",
       "9     0.580158  0.847230    0.475620       1.481835         NaN         NaN  \n",
       "0          NaN  0.911357    0.899713            NaN    0.755075    0.818931  \n",
       "1          NaN  0.789404    1.699094            NaN    0.502575    0.000000  \n",
       "2          NaN  0.983549    0.541912            NaN    0.746773    0.000000  \n",
       "3          NaN  0.970780    1.294121            NaN    0.869168    0.774708  \n",
       "4          NaN  0.872222    1.015568            NaN    0.668241    0.000000  \n",
       "5          NaN  0.899582    1.079226            NaN    0.640667    1.003918  \n",
       "6          NaN  0.829469    0.966377            NaN    0.418904    0.000000  \n",
       "7          NaN  0.953048    0.431106            NaN    0.467027    0.734059  \n",
       "8          NaN  0.994855    1.714911            NaN    0.877092    0.902388  \n",
       "9          NaN  0.949376    1.421685            NaN    0.758530    1.510669  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_metrics = gpd.read_file(os.path.join(os.getcwd(), 'shp', 'islands_metrics.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>country</th>\n",
       "      <th>area</th>\n",
       "      <th>compactnes</th>\n",
       "      <th>solidity</th>\n",
       "      <th>elongation</th>\n",
       "      <th>avg_curvat</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baulhegalla</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>41297.003855</td>\n",
       "      <td>0.916788</td>\n",
       "      <td>0.990704</td>\n",
       "      <td>1.070128</td>\n",
       "      <td>1.056035</td>\n",
       "      <td>POINT (73.17252 0.49499)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berasdhoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>686000.802685</td>\n",
       "      <td>0.375860</td>\n",
       "      <td>0.694924</td>\n",
       "      <td>0.414228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (73.54034 1.96825)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berinmadhoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>158819.290847</td>\n",
       "      <td>0.607160</td>\n",
       "      <td>0.922552</td>\n",
       "      <td>0.430827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (72.97158 7.04707)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyrumaddoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>24379.961774</td>\n",
       "      <td>0.744893</td>\n",
       "      <td>0.993769</td>\n",
       "      <td>0.598757</td>\n",
       "      <td>0.727421</td>\n",
       "      <td>POINT (73.22494 0.79480)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bileffahi</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>684499.344040</td>\n",
       "      <td>0.414918</td>\n",
       "      <td>0.775258</td>\n",
       "      <td>0.780705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POINT (72.97570 6.33794)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bileitheyrahaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>135569.546116</td>\n",
       "      <td>0.163766</td>\n",
       "      <td>0.562536</td>\n",
       "      <td>0.519623</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>POINT (73.53591 2.05687)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boaddoo</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>21086.131076</td>\n",
       "      <td>0.984788</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>1.057241</td>\n",
       "      <td>0.836168</td>\n",
       "      <td>POINT (73.33053 0.70559)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bodehutta (Gaafu Dhaalu)</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>196742.512323</td>\n",
       "      <td>0.234502</td>\n",
       "      <td>0.506443</td>\n",
       "      <td>0.873940</td>\n",
       "      <td>0.946299</td>\n",
       "      <td>POINT (73.34759 0.25393)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bodehuttaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>81252.411687</td>\n",
       "      <td>0.387323</td>\n",
       "      <td>0.688880</td>\n",
       "      <td>1.260047</td>\n",
       "      <td>0.995556</td>\n",
       "      <td>POINT (73.57211 0.41316)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Boderehaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>58002.431387</td>\n",
       "      <td>0.580158</td>\n",
       "      <td>0.847230</td>\n",
       "      <td>0.475620</td>\n",
       "      <td>1.481835</td>\n",
       "      <td>POINT (73.01241 0.38621)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     island   country           area  compactnes  solidity  \\\n",
       "0               Baulhegalla  Maldives   41297.003855    0.916788  0.990704   \n",
       "1                 Berasdhoo  Maldives  686000.802685    0.375860  0.694924   \n",
       "2               Berinmadhoo  Maldives  158819.290847    0.607160  0.922552   \n",
       "3               Beyrumaddoo  Maldives   24379.961774    0.744893  0.993769   \n",
       "4                 Bileffahi  Maldives  684499.344040    0.414918  0.775258   \n",
       "5            Bileitheyrahaa  Maldives  135569.546116    0.163766  0.562536   \n",
       "6                   Boaddoo  Maldives   21086.131076    0.984788  0.999812   \n",
       "7  Bodehutta (Gaafu Dhaalu)  Maldives  196742.512323    0.234502  0.506443   \n",
       "8                Bodehuttaa  Maldives   81252.411687    0.387323  0.688880   \n",
       "9                 Boderehaa  Maldives   58002.431387    0.580158  0.847230   \n",
       "\n",
       "   elongation  avg_curvat                  geometry  \n",
       "0    1.070128    1.056035  POINT (73.17252 0.49499)  \n",
       "1    0.414228    0.000000  POINT (73.54034 1.96825)  \n",
       "2    0.430827    0.000000  POINT (72.97158 7.04707)  \n",
       "3    0.598757    0.727421  POINT (73.22494 0.79480)  \n",
       "4    0.780705    0.000000  POINT (72.97570 6.33794)  \n",
       "5    0.519623    0.000158  POINT (73.53591 2.05687)  \n",
       "6    1.057241    0.836168  POINT (73.33053 0.70559)  \n",
       "7    0.873940    0.946299  POINT (73.34759 0.25393)  \n",
       "8    1.260047    0.995556  POINT (73.57211 0.41316)  \n",
       "9    0.475620    1.481835  POINT (73.01241 0.38621)  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:01<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shapely.geometry\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import skimage.transform as transform\n",
    "import pyproj\n",
    "\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "# List to store the data\n",
    "data_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)[:5]):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "        lat, lon = island_info['spatial_reference']['latitude'], island_info['spatial_reference']['longitude']\n",
    "        reference_shoreline = island_info['spatial_reference']['reference_shoreline']\n",
    "\n",
    "        point = shapely.geometry.Point(lon, lat)\n",
    "        poly_image_crs = shapely.geometry.Polygon(reference_shoreline)\n",
    "\n",
    "        # Calculate metrics\n",
    "        area = poly_image_crs.area\n",
    "        compactness = (4 * np.pi * poly_image_crs.area) / (poly_image_crs.length ** 2)\n",
    "        convex_hull = poly_image_crs.convex_hull\n",
    "        solidity = poly_image_crs.area / convex_hull.area\n",
    "        bounding_box = poly_image_crs.bounds\n",
    "        min_rotated_rect = poly_image_crs.minimum_rotated_rectangle\n",
    "        mrr_coords = list(min_rotated_rect.exterior.coords)\n",
    "        major_axis = max([mrr_coords[i][0] - mrr_coords[i-1][0] for i in range(len(mrr_coords))])\n",
    "        minor_axis = max([mrr_coords[i][1] - mrr_coords[i-1][1] for i in range(len(mrr_coords))])\n",
    "        elongation = major_axis / minor_axis\n",
    "\n",
    "        def calculate_curvature(polygon):\n",
    "            coords = np.array(polygon.exterior.coords)\n",
    "            angles = []\n",
    "            for i in range(len(coords) - 2):\n",
    "                v1 = coords[i+1] - coords[i]\n",
    "                v2 = coords[i+2] - coords[i+1]\n",
    "                angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "                if not np.isnan(angle):\n",
    "                    angles.append(angle)\n",
    "            \n",
    "            # change to degrees\n",
    "            angles = np.degrees(angles)\n",
    "\n",
    "            mean_angle = np.mean(angles)\n",
    "\n",
    "            if mean_angle < 1e-6:\n",
    "                mean_angle = 0.\n",
    "\n",
    "            return mean_angle\n",
    "\n",
    "        avg_curvature = calculate_curvature(poly_image_crs)\n",
    "\n",
    "        # Add data to list\n",
    "        data_list.append({\n",
    "            'island': island,\n",
    "            'country': country,\n",
    "            'geometry': point,\n",
    "            'area': area,\n",
    "            'compactness': compactness,\n",
    "            'solidity': solidity,\n",
    "            'elongation': elongation,\n",
    "            'avg_curvature': avg_curvature\n",
    "        })\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error with island: {island} - {str(e)}')\n",
    "        continue\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data_list, crs='EPSG:4326')\n",
    "\n",
    "# Save to shapefile\n",
    "# gdf.to_file('shp//islands_metrics.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgdf_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\anaconda3\\envs\\IslandTimeEnv\\Lib\\site-packages\\pandas\\core\\indexing.py:1192\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1191\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\anaconda3\\envs\\IslandTimeEnv\\Lib\\site-packages\\pandas\\core\\indexing.py:1753\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1753\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\anaconda3\\envs\\IslandTimeEnv\\Lib\\site-packages\\pandas\\core\\indexing.py:1686\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1684\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1686\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "gdf_s.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>country</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area</th>\n",
       "      <th>compactness</th>\n",
       "      <th>solidity</th>\n",
       "      <th>elongation</th>\n",
       "      <th>avg_curvature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakiraahuttaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.08961 0.26550)</td>\n",
       "      <td>72713.189254</td>\n",
       "      <td>0.755075</td>\n",
       "      <td>0.911357</td>\n",
       "      <td>0.899713</td>\n",
       "      <td>0.818931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aligaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.51679 5.24397)</td>\n",
       "      <td>22157.618766</td>\n",
       "      <td>0.502575</td>\n",
       "      <td>0.789404</td>\n",
       "      <td>1.699094</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angolhitheemu</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.00639 5.79286)</td>\n",
       "      <td>409807.772585</td>\n",
       "      <td>0.746773</td>\n",
       "      <td>0.983549</td>\n",
       "      <td>0.541912</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Araigaththaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.53508 0.45210)</td>\n",
       "      <td>50830.350038</td>\n",
       "      <td>0.869168</td>\n",
       "      <td>0.970780</td>\n",
       "      <td>1.294121</td>\n",
       "      <td>0.774708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athahedha</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.28583 1.81046)</td>\n",
       "      <td>26730.050890</td>\n",
       "      <td>0.668241</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>1.015568</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          island   country                  geometry           area  \\\n",
       "0  Aakiraahuttaa  Maldives  POINT (73.08961 0.26550)   72713.189254   \n",
       "1         Aligaa  Maldives  POINT (73.51679 5.24397)   22157.618766   \n",
       "2  Angolhitheemu  Maldives  POINT (73.00639 5.79286)  409807.772585   \n",
       "3   Araigaththaa  Maldives  POINT (73.53508 0.45210)   50830.350038   \n",
       "4      Athahedha  Maldives  POINT (73.28583 1.81046)   26730.050890   \n",
       "\n",
       "   compactness  solidity  elongation  avg_curvature  \n",
       "0     0.755075  0.911357    0.899713       0.818931  \n",
       "1     0.502575  0.789404    1.699094       0.000000  \n",
       "2     0.746773  0.983549    0.541912       0.000000  \n",
       "3     0.869168  0.970780    1.294121       0.774708  \n",
       "4     0.668241  0.872222    1.015568       0.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.655345306703404e-09"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf['avg_curvature'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shapely.geometry\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import skimage.transform as transform\n",
    "\n",
    "# Read file for islands to ignore\n",
    "df_islands_ignore = pd.read_excel(os.path.join('excel', 'islands_to_ignore.xlsx'))\n",
    "list_islands_ignore = df_islands_ignore['Island'].values\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "# List to store the data\n",
    "data_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)[:1]):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    if island in list_islands_ignore:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "        lat, lon = island_info['spatial_reference']['latitude'], island_info['spatial_reference']['longitude']\n",
    "\n",
    "        if os.path.exists(os.path.join(os.getcwd(), 'data', 'coastsat_data', '{}_{}'.format(island, country), 'best_polygons_{}_{}.data'.format(island, country))):\n",
    "            all_dict = pd.read_pickle(os.path.join(os.getcwd(), 'data', 'coastsat_data', '{}_{}'.format(island, country), 'all_polygons_{}_{}.data'.format(island, country)))\n",
    "            best_dict = pd.read_pickle(os.path.join(os.getcwd(), 'data', 'coastsat_data', '{}_{}'.format(island, country), 'best_polygons_{}_{}.data'.format(island, country)))\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        point = shapely.geometry.Point(lon, lat)\n",
    "\n",
    "        dict_georef = all_dict[2]\n",
    "        dict_rgb_ts = all_dict[1]\n",
    "        dict_poly = all_dict[0]\n",
    "\n",
    "        key = list(best_dict.keys())[0]\n",
    "        polygon = dict_poly[key]['polygon_NIR_otsu']\n",
    "        i = 1\n",
    "        if polygon is None:\n",
    "            while polygon is None:\n",
    "                key = list(best_dict.keys())[i]\n",
    "                polygon = dict_poly[key]['polygon_NIR_otsu']\n",
    "                i += 1\n",
    "                if polygon is not None:\n",
    "                    break\n",
    "\n",
    "        aff_mat = np.array([[dict_georef[key][1], dict_georef[key][2], dict_georef[key][0]],\n",
    "                            [dict_georef[key][4], dict_georef[key][5], dict_georef[key][3]],\n",
    "                            [0, 0, 1]])\n",
    "\n",
    "        # Create affine transformation\n",
    "        \n",
    "        tform = transform.AffineTransform(aff_mat)\n",
    "\n",
    "        # polygon = dict_poly[key]['polygon_NIR_otsu']\n",
    "        x_poly, y_poly  = polygon.exterior.coords.xy\n",
    "\n",
    "        # Transform polygon\n",
    "        tmp = np.column_stack((x_poly, y_poly))\n",
    "        points_converted = tform(tmp)\n",
    "        poly_image_crs = shapely.geometry.Polygon(points_converted)\n",
    "\n",
    "        # Calculate metrics\n",
    "        area = poly_image_crs.area\n",
    "        compactness = (4 * np.pi * poly_image_crs.area) / (poly_image_crs.length ** 2)\n",
    "        convex_hull = poly_image_crs.convex_hull\n",
    "        solidity = poly_image_crs.area / convex_hull.area\n",
    "        bounding_box = poly_image_crs.bounds\n",
    "        min_rotated_rect = poly_image_crs.minimum_rotated_rectangle\n",
    "        mrr_coords = list(min_rotated_rect.exterior.coords)\n",
    "        major_axis = max([mrr_coords[i][0] - mrr_coords[i-1][0] for i in range(len(mrr_coords))])\n",
    "        minor_axis = max([mrr_coords[i][1] - mrr_coords[i-1][1] for i in range(len(mrr_coords))])\n",
    "        elongation = major_axis / minor_axis\n",
    "\n",
    "        def calculate_curvature(polygon):\n",
    "            coords = np.array(polygon.exterior.coords)\n",
    "            angles = []\n",
    "            for i in range(len(coords) - 2):\n",
    "                v1 = coords[i+1] - coords[i]\n",
    "                v2 = coords[i+2] - coords[i+1]\n",
    "                angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "                if not np.isnan(angle):\n",
    "                    angles.append(angle)\n",
    "            return np.mean(angles)\n",
    "\n",
    "        avg_curvature = calculate_curvature(poly_image_crs)\n",
    "\n",
    "        # Add data to list\n",
    "        data_list.append({\n",
    "            'island': island,\n",
    "            'country': country,\n",
    "            'geometry': point,\n",
    "            'area': area,\n",
    "            'compactness': compactness,\n",
    "            'solidity': solidity,\n",
    "            'elongation': elongation,\n",
    "            'avg_curvature': avg_curvature\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error with island: {island} - {str(e)}')\n",
    "        continue\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf_s = gpd.GeoDataFrame(data_list, crs='EPSG:4326')\n",
    "\n",
    "# Save to shapefile\n",
    "# gdf.to_file('shp//islands_metrics.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>country</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area</th>\n",
       "      <th>compactness</th>\n",
       "      <th>solidity</th>\n",
       "      <th>elongation</th>\n",
       "      <th>avg_curvature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakiraahuttaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.08961 0.26550)</td>\n",
       "      <td>142740.474090</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.848453</td>\n",
       "      <td>0.714046</td>\n",
       "      <td>0.245196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Araigaththaa</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>POINT (73.53508 0.45210)</td>\n",
       "      <td>44123.559787</td>\n",
       "      <td>0.895994</td>\n",
       "      <td>0.980368</td>\n",
       "      <td>1.170080</td>\n",
       "      <td>0.141849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          island   country                  geometry           area  \\\n",
       "0  Aakiraahuttaa  Maldives  POINT (73.08961 0.26550)  142740.474090   \n",
       "1   Araigaththaa  Maldives  POINT (73.53508 0.45210)   44123.559787   \n",
       "\n",
       "   compactness  solidity  elongation  avg_curvature  \n",
       "0     0.224896  0.848453    0.714046       0.245196  \n",
       "1     0.895994  0.980368    1.170080       0.141849  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0\tAakiraahuttaa\tMaldives\tPOINT (73.00639 5.79286)\t7.271319e+04\t0.755075\t0.911357\t0.899713\t8.189305e-01\n",
    "3\tAraigaththaa\tMaldives\tPOINT (73.00639 5.79286)\t5.083035e+04\t0.869168\t0.970780\t1.294121\t7.747076e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"294.71072721487144\" height=\"229.01108301593922\" viewBox=\"336830.50200279325 49875.377806987744 294.71072721487144 229.01108301593922\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,99979.76669699143)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"2.0\" opacity=\"0.6\" d=\"M 336990.0,49889.49672474338 L 336990.0,49889.49672474338 L 336980.0,49889.004585597824 L 336970.0,49887.05684403438 L 336960.0,49886.293019106815 L 336950.0,49888.462842661334 L 336944.40423596674,49890.0 L 336940.0,49891.47935579609 L 336930.0,49891.569557510506 L 336920.0,49893.172466120835 L 336910.0,49892.48818651926 L 336900.0,49893.719695667125 L 336890.0,49897.95039464023 L 336886.877446868,49900.0 L 336880.0,49903.94130608974 L 336874.15849042026,49910.0 L 336870.0,49919.90933357879 L 336869.9548992674,49920.0 L 336866.5305232558,49930.0 L 336866.1528997577,49940.0 L 336870.0,49949.697041984735 L 336870.18702874647,49950.0 L 336871.987440032,49960.0 L 336870.0,49966.56415052817 L 336868.978774202,49970.0 L 336865.94388492673,49980.0 L 336862.43713209836,49990.0 L 336860.0,49996.08861375433 L 336857.5479595987,50000.0 L 336853.0759395813,50010.0 L 336850.04339733545,50020.0 L 336850.0,50020.12305555555 L 336845.484940065,50030.0 L 336842.33401940006,50040.0 L 336841.4172149123,50050.0 L 336844.18427178496,50060.0 L 336850.0,50066.70103744939 L 336854.5984410271,50070.0 L 336860.0,50073.88929804957 L 336870.0,50079.841153780944 L 336870.22850609757,50080.0 L 336880.0,50086.51221147594 L 336890.0,50089.06603156009 L 336895.1810970948,50090.0 L 336900.0,50091.45434356253 L 336910.0,50092.77011904762 L 336920.0,50093.47367788461 L 336930.0,50092.693164320284 L 336940.0,50090.99223074987 L 336950.0,50090.12324617347 L 336950.450676306,50090.0 L 336960.0,50087.90656952965 L 336970.0,50085.62206152903 L 336980.0,50084.14778171713 L 336990.0,50083.31472411934 L 337000.0,50082.31495579568 L 337010.0,50080.34597081218 L 337011.57042050693,50080.0 L 337020.0,50078.98207081247 L 337030.0,50078.09042515563 L 337040.0,50076.12703760491 L 337050.0,50073.77143636003 L 337058.7262041284,50070.0 L 337060.0,50069.585788335324 L 337070.0,50065.31989270024 L 337076.6729811361,50060.0 L 337080.0,50056.758183601814 L 337085.6399732851,50050.0 L 337090.0,50043.14076057484 L 337092.51151886384,50040.0 L 337098.2736541903,50030.0 L 337100.0,50024.780489179444 L 337102.3657128514,50020.0 L 337105.8716877081,50010.0 L 337108.7534066737,50000.0 L 337110.0,49996.89095656499 L 337113.8630343866,49990.0 L 337114.29751788906,49980.0 L 337112.8039698874,49970.0 L 337110.0,49962.91176067908 L 337109.28670847864,49960.0 L 337105.5789105088,49950.0 L 337100.0,49940.582023261755 L 337099.6098569225,49940.0 L 337090.51745495497,49930.0 L 337090.0,49929.48777497027 L 337080.0,49921.6925831793 L 337078.3067908654,49920.0 L 337070.0,49910.93926482453 L 337068.80654151714,49910.0 L 337060.0,49903.8746657754 L 337050.0,49901.42650565171 L 337043.7678433642,49900.0 L 337040.0,49898.68237317863 L 337030.0,49896.78310570071 L 337020.0,49894.382273825206 L 337010.0,49893.03632633984 L 337000.0,49891.959583136515 L 336991.8337844488,49890.0 L 336990.0,49889.49672474338 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((336990 49889.497, 336990 49889.497, 336980 49889.005, 336970 4988...>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_image_crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map for included/excluded islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating results maps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 346/401 [01:19<00:10,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with island: Qaruh Island\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 401/401 [01:29<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read file for islands to ignore\n",
    "import shapely.geometry\n",
    "\n",
    "\n",
    "df_islands_ignore = pd.read_excel('islands_to_ignore.xlsx')\n",
    "list_islands_ignore = df_islands_ignore['Island'].values\n",
    "\n",
    "path_to_data = os.path.join(os.getcwd(), 'data', 'info_islands')\n",
    "\n",
    "print('Updating results maps...')\n",
    "\n",
    "multi_point = []\n",
    "multi_point_excluded = []\n",
    "\n",
    "for file in tqdm(os.listdir(path_to_data)):\n",
    "    island = file.split('_')[1] \n",
    "    country = file.split('_')[2].split('.')[0]\n",
    "\n",
    "    try:\n",
    "        island_info = retrieve_island_info(island, country, verbose=False)\n",
    "        lat, lon = island_info['spatial_reference']['latitude'], island_info['spatial_reference']['longitude']\n",
    "        point = shapely.geometry.Point(lon, lat)\n",
    "\n",
    "        if island in list_islands_ignore:\n",
    "            label = 'excluded'\n",
    "            multi_point_excluded.append(point)\n",
    "\n",
    "        else:\n",
    "            label = 'included'\n",
    "            multi_point.append(point)\n",
    "    \n",
    "    except:\n",
    "        print('Error with island:', island)\n",
    "        continue\n",
    "\n",
    "mp = shapely.geometry.MultiPoint(multi_point)\n",
    "mp_excluded = shapely.geometry.MultiPoint(multi_point_excluded)\n",
    "gdf = gpd.GeoDataFrame(geometry=[mp], crs='EPSG:4326')\n",
    "gdf_excluded = gpd.GeoDataFrame(geometry=[mp_excluded], crs='EPSG:4326')\n",
    "gdf.to_file('shp//Huvadhoo_included.shp')\n",
    "gdf_excluded.to_file('shp//Huvadhoo_excluded.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IslandTime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
