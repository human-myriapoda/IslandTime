{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IslandTime import Segmentation, retrieve_island_info, update_data_map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from osgeo import gdal\n",
    "from xml.dom import minidom\n",
    "from PIL import Image\n",
    "# from rembg import remove\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Retrieving all information available for the island\n",
      "Island: Dhakandhoo, Maldives\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "~ The following information is available: ~\n",
      "\n",
      "general_info\n",
      "               island\n",
      "               country\n",
      "               part of\n",
      "               located in the administrative territorial entity\n",
      "               located in or next to body of water\n",
      "               elevation above sea level\n",
      "               atoll\n",
      "spatial_reference\n",
      "               latitude\n",
      "               longitude\n",
      "               polygon\n",
      "               polygon_OSM\n",
      "               reference_shoreline\n",
      "               transects\n",
      "               transects_direction\n",
      "               area_country\n",
      "               reference_shoreline_buffer_L8\n",
      "               reference_shoreline_buffer_L9\n",
      "               reference_shoreline_buffer_S2\n",
      "image_collection_dict\n",
      "               description\n",
      "               S2\n",
      "               L5\n",
      "               L7\n",
      "               L8\n",
      "               L9\n",
      "duvat_magnan_2019\n",
      "               atoll\n",
      "               island number\n",
      "               satellite image date (d/m/y) 2004-2006\n",
      "               satellite image date (d/m/y) 2014-2016\n",
      "               change in island land area (data for inhabited islands only)(in ha) 2014-2016\n",
      "               human footprint on island land area 2004-2006 non-exploited islands\n",
      "               human footprint on island land area 2014-2016 non-exploited islands\n",
      "               coastal modifications 2004-2006 shoreline type entirely natural\n",
      "               coastal modifications 2014-2016 shoreline type entirely natural\n",
      "               human pressure on island reef 2004-2006 boat channel(s) across reef flat\n",
      "               human pressure on island reef 2014-2016 persistence of boat channel(s) across reef flat\n",
      "timeseries_CRW\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries\n",
      "timeseries_nighttime_light\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "timeseries_disasters\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               database\n",
      "               timeseries\n",
      "               confounders\n",
      "timeseries_WorldBank\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries\n",
      "timeseries_WHO\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries\n",
      "timeseries_sea_level_anomaly\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               units\n",
      "               timeseries\n",
      "timeseries_PMLV2\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               units\n",
      "timeseries_PSMSL\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               stations\n",
      "               timeseries\n",
      "timeseries_PSLGM\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "timeseries_coastsat\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               inputs\n",
      "               settings\n",
      "               timeseries\n",
      "timeseries_ERA5\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries_transect_specific\n",
      "               timeseries\n",
      "               units\n",
      "characteristics_ECU\n",
      "               description\n",
      "               source\n",
      "               transects_characteristics_ECU\n",
      "timeseries_vegetation\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               mask_total_vegetation_L8\n",
      "               mask_coastal_vegetation_L8\n",
      "               mask_total_vegetation_L9\n",
      "               mask_coastal_vegetation_L9\n",
      "               mask_total_vegetation_S2\n",
      "               mask_coastal_vegetation_S2\n",
      "               timeseries\n",
      "timeseries_climate_indices\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries\n",
      "timeseries_segmentation\n",
      "               dict_extraction\n",
      "               dict_best_polygons\n",
      "               dict_timeseries\n",
      "               timeseries\n",
      "timeseries_preprocessing\n",
      "               df_coastline_timeseries\n",
      "               raw\n",
      "               optimal time period\n",
      "timeseries_analysis\n",
      "               coastline_position_transect_0_waterline\n",
      "               coastline_position_transect_1_waterline\n",
      "               coastline_position_transect_2_waterline\n",
      "               coastline_position_transect_3_waterline\n",
      "               coastline_position_transect_4_waterline\n",
      "               coastline_position_transect_5_waterline\n",
      "               coastline_position_transect_6_waterline\n",
      "               coastline_position_transect_7_waterline\n",
      "               coastline_position_transect_8_waterline\n",
      "               coastline_position_transect_9_waterline\n",
      "               coastline_position_transect_10_waterline\n",
      "               coastline_position_transect_11_waterline\n",
      "               coastline_position_transect_12_waterline\n",
      "               coastline_position_transect_13_waterline\n",
      "               coastline_position_transect_14_waterline\n",
      "               coastline_position_transect_15_waterline\n",
      "               coastline_position_transect_16_waterline\n",
      "               coastline_position_transect_17_waterline\n",
      "               coastline_position_transect_18_waterline\n",
      "               coastline_position_transect_19_waterline\n",
      "               coastline_position_transect_20_waterline\n",
      "               coastline_position_transect_21_waterline\n",
      "               coastline_position_transect_22_waterline\n",
      "               coastline_position_transect_23_waterline\n",
      "               coastline_position_transect_24_waterline\n",
      "               coastline_position_transect_25_waterline\n",
      "               coastline_position_transect_26_waterline\n",
      "               coastline_position_transect_27_waterline\n",
      "               coastline_position_transect_28_waterline\n",
      "               coastline_position_transect_29_waterline\n",
      "               coastline_position_transect_30_waterline\n",
      "               coastline_position_transect_31_waterline\n",
      "               coastline_position_transect_32_waterline\n",
      "               coastline_position_transect_33_waterline\n",
      "               coastline_position_transect_34_waterline\n",
      "               coastline_position_transect_35_waterline\n",
      "               coastline_position_transect_36_waterline\n",
      "               coastline_position_transect_37_waterline\n",
      "               coastline_position_transect_38_waterline\n",
      "               coastline_position_transect_39_waterline\n",
      "               coastline_position_transect_40_waterline\n",
      "               coastline_position_transect_41_waterline\n",
      "               coastline_position_transect_42_waterline\n",
      "               coastline_position_transect_43_waterline\n",
      "               coastline_position_transect_44_waterline\n",
      "               coastline_position_transect_45_waterline\n",
      "               coastline_position_transect_46_waterline\n",
      "               coastline_position_transect_47_waterline\n",
      "               coastline_position_transect_48_waterline\n",
      "               coastline_position_transect_49_waterline\n",
      "               coastline_position_transect_50_waterline\n",
      "               coastline_position_transect_51_waterline\n",
      "               coastline_position_transect_52_waterline\n",
      "               coastline_position_transect_53_waterline\n",
      "               coastline_position_transect_54_waterline\n",
      "               coastline_position_transect_55_waterline\n",
      "               coastline_position_transect_56_waterline\n",
      "               coastline_position_transect_57_waterline\n",
      "               coastline_position_transect_58_waterline\n",
      "               coastline_position_transect_59_waterline\n",
      "               coastline_position_transect_60_waterline\n",
      "               coastline_position_transect_61_waterline\n",
      "               coastline_position_transect_62_waterline\n",
      "               coastline_position_transect_63_waterline\n",
      "               coastline_position_transect_64_waterline\n",
      "               coastline_position_transect_65_waterline\n",
      "               coastline_position_transect_66_waterline\n",
      "               coastline_position_transect_67_waterline\n",
      "               coastline_position_transect_68_waterline\n",
      "               coastline_position_transect_69_waterline\n",
      "               coastline_position_transect_70_waterline\n",
      "               coastline_position_transect_71_waterline\n",
      "               coastline_position_transect_72_waterline\n",
      "               coastline_position_transect_73_waterline\n",
      "               coastline_position_transect_74_waterline\n",
      "               coastline_position_transect_75_waterline\n",
      "               coastline_position_transect_76_waterline\n",
      "               coastline_position_transect_77_waterline\n",
      "               coastline_position_transect_78_waterline\n",
      "               coastline_position_transect_80_waterline\n",
      "               coastline_position_transect_81_waterline\n",
      "               coastline_position_transect_82_waterline\n",
      "               coastline_position_transect_84_waterline\n",
      "               coastline_position_transect_85_waterline\n",
      "               coastline_position_transect_87_waterline\n",
      "               coastline_position_transect_88_waterline\n",
      "               coastline_position_transect_89_waterline\n",
      "               coastline_position_transect_90_waterline\n",
      "               coastline_position_transect_91_waterline\n",
      "               coastline_position_transect_92_waterline\n",
      "               coastline_position_transect_93_waterline\n",
      "               coastline_position_transect_94_waterline\n",
      "               coastline_position_transect_95_waterline\n",
      "               coastline_position_transect_96_waterline\n",
      "               coastline_position_transect_97_waterline\n",
      "               coastline_position_transect_98_waterline\n",
      "               coastline_position_transect_99_waterline\n",
      "               coastline_position_transect_100_waterline\n",
      "               coastline_position_transect_101_waterline\n",
      "               coastline_position_transect_102_waterline\n",
      "               coastline_position_transect_103_waterline\n",
      "               coastline_position_transect_104_waterline\n",
      "               coastline_position_transect_105_waterline\n",
      "               coastline_position_transect_106_waterline\n",
      "timeseries_aggregation\n",
      "               dict_results_agg_minima\n",
      "               dict_results_agg_peaks\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Retrieving all information available for the island\n",
      "Island: Dhakandhoo, Maldives\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "~ The following information is available: ~\n",
      "\n",
      "general_info\n",
      "               island\n",
      "               country\n",
      "               part of\n",
      "               located in the administrative territorial entity\n",
      "               located in or next to body of water\n",
      "               elevation above sea level\n",
      "               atoll\n",
      "spatial_reference\n",
      "               latitude\n",
      "               longitude\n",
      "               polygon\n",
      "               polygon_OSM\n",
      "               reference_shoreline\n",
      "               transects\n",
      "               transects_direction\n",
      "               area_country\n",
      "               reference_shoreline_buffer_L8\n",
      "               reference_shoreline_buffer_L9\n",
      "               reference_shoreline_buffer_S2\n",
      "image_collection_dict\n",
      "               description\n",
      "               S2\n",
      "               L5\n",
      "               L7\n",
      "               L8\n",
      "               L9\n",
      "duvat_magnan_2019\n",
      "               atoll\n",
      "               island number\n",
      "               satellite image date (d/m/y) 2004-2006\n",
      "               satellite image date (d/m/y) 2014-2016\n",
      "               change in island land area (data for inhabited islands only)(in ha) 2014-2016\n",
      "               human footprint on island land area 2004-2006 non-exploited islands\n",
      "               human footprint on island land area 2014-2016 non-exploited islands\n",
      "               coastal modifications 2004-2006 shoreline type entirely natural\n",
      "               coastal modifications 2014-2016 shoreline type entirely natural\n",
      "               human pressure on island reef 2004-2006 boat channel(s) across reef flat\n",
      "               human pressure on island reef 2014-2016 persistence of boat channel(s) across reef flat\n",
      "timeseries_CRW\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries\n",
      "timeseries_nighttime_light\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "timeseries_disasters\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               database\n",
      "               timeseries\n",
      "               confounders\n",
      "timeseries_WorldBank\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries\n",
      "timeseries_WHO\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries\n",
      "timeseries_sea_level_anomaly\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               units\n",
      "               timeseries\n",
      "timeseries_PMLV2\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               units\n",
      "timeseries_PSMSL\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               stations\n",
      "               timeseries\n",
      "timeseries_PSLGM\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "timeseries_coastsat\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               inputs\n",
      "               settings\n",
      "               timeseries\n",
      "timeseries_ERA5\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries_transect_specific\n",
      "               timeseries\n",
      "               units\n",
      "characteristics_ECU\n",
      "               description\n",
      "               source\n",
      "               transects_characteristics_ECU\n",
      "timeseries_vegetation\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               mask_total_vegetation_L8\n",
      "               mask_coastal_vegetation_L8\n",
      "               mask_total_vegetation_L9\n",
      "               mask_coastal_vegetation_L9\n",
      "               mask_total_vegetation_S2\n",
      "               mask_coastal_vegetation_S2\n",
      "               timeseries\n",
      "timeseries_climate_indices\n",
      "               description\n",
      "               description_timeseries\n",
      "               source\n",
      "               timeseries\n",
      "timeseries_segmentation\n",
      "               dict_extraction\n",
      "               dict_best_polygons\n",
      "               dict_timeseries\n",
      "               timeseries\n",
      "timeseries_preprocessing\n",
      "               df_coastline_timeseries\n",
      "               raw\n",
      "               optimal time period\n",
      "timeseries_analysis\n",
      "               coastline_position_transect_0_waterline\n",
      "               coastline_position_transect_1_waterline\n",
      "               coastline_position_transect_2_waterline\n",
      "               coastline_position_transect_3_waterline\n",
      "               coastline_position_transect_4_waterline\n",
      "               coastline_position_transect_5_waterline\n",
      "               coastline_position_transect_6_waterline\n",
      "               coastline_position_transect_7_waterline\n",
      "               coastline_position_transect_8_waterline\n",
      "               coastline_position_transect_9_waterline\n",
      "               coastline_position_transect_10_waterline\n",
      "               coastline_position_transect_11_waterline\n",
      "               coastline_position_transect_12_waterline\n",
      "               coastline_position_transect_13_waterline\n",
      "               coastline_position_transect_14_waterline\n",
      "               coastline_position_transect_15_waterline\n",
      "               coastline_position_transect_16_waterline\n",
      "               coastline_position_transect_17_waterline\n",
      "               coastline_position_transect_18_waterline\n",
      "               coastline_position_transect_19_waterline\n",
      "               coastline_position_transect_20_waterline\n",
      "               coastline_position_transect_21_waterline\n",
      "               coastline_position_transect_22_waterline\n",
      "               coastline_position_transect_23_waterline\n",
      "               coastline_position_transect_24_waterline\n",
      "               coastline_position_transect_25_waterline\n",
      "               coastline_position_transect_26_waterline\n",
      "               coastline_position_transect_27_waterline\n",
      "               coastline_position_transect_28_waterline\n",
      "               coastline_position_transect_29_waterline\n",
      "               coastline_position_transect_30_waterline\n",
      "               coastline_position_transect_31_waterline\n",
      "               coastline_position_transect_32_waterline\n",
      "               coastline_position_transect_33_waterline\n",
      "               coastline_position_transect_34_waterline\n",
      "               coastline_position_transect_35_waterline\n",
      "               coastline_position_transect_36_waterline\n",
      "               coastline_position_transect_37_waterline\n",
      "               coastline_position_transect_38_waterline\n",
      "               coastline_position_transect_39_waterline\n",
      "               coastline_position_transect_40_waterline\n",
      "               coastline_position_transect_41_waterline\n",
      "               coastline_position_transect_42_waterline\n",
      "               coastline_position_transect_43_waterline\n",
      "               coastline_position_transect_44_waterline\n",
      "               coastline_position_transect_45_waterline\n",
      "               coastline_position_transect_46_waterline\n",
      "               coastline_position_transect_47_waterline\n",
      "               coastline_position_transect_48_waterline\n",
      "               coastline_position_transect_49_waterline\n",
      "               coastline_position_transect_50_waterline\n",
      "               coastline_position_transect_51_waterline\n",
      "               coastline_position_transect_52_waterline\n",
      "               coastline_position_transect_53_waterline\n",
      "               coastline_position_transect_54_waterline\n",
      "               coastline_position_transect_55_waterline\n",
      "               coastline_position_transect_56_waterline\n",
      "               coastline_position_transect_57_waterline\n",
      "               coastline_position_transect_58_waterline\n",
      "               coastline_position_transect_59_waterline\n",
      "               coastline_position_transect_60_waterline\n",
      "               coastline_position_transect_61_waterline\n",
      "               coastline_position_transect_62_waterline\n",
      "               coastline_position_transect_63_waterline\n",
      "               coastline_position_transect_64_waterline\n",
      "               coastline_position_transect_65_waterline\n",
      "               coastline_position_transect_66_waterline\n",
      "               coastline_position_transect_67_waterline\n",
      "               coastline_position_transect_68_waterline\n",
      "               coastline_position_transect_69_waterline\n",
      "               coastline_position_transect_70_waterline\n",
      "               coastline_position_transect_71_waterline\n",
      "               coastline_position_transect_72_waterline\n",
      "               coastline_position_transect_73_waterline\n",
      "               coastline_position_transect_74_waterline\n",
      "               coastline_position_transect_75_waterline\n",
      "               coastline_position_transect_76_waterline\n",
      "               coastline_position_transect_77_waterline\n",
      "               coastline_position_transect_78_waterline\n",
      "               coastline_position_transect_80_waterline\n",
      "               coastline_position_transect_81_waterline\n",
      "               coastline_position_transect_82_waterline\n",
      "               coastline_position_transect_84_waterline\n",
      "               coastline_position_transect_85_waterline\n",
      "               coastline_position_transect_87_waterline\n",
      "               coastline_position_transect_88_waterline\n",
      "               coastline_position_transect_89_waterline\n",
      "               coastline_position_transect_90_waterline\n",
      "               coastline_position_transect_91_waterline\n",
      "               coastline_position_transect_92_waterline\n",
      "               coastline_position_transect_93_waterline\n",
      "               coastline_position_transect_94_waterline\n",
      "               coastline_position_transect_95_waterline\n",
      "               coastline_position_transect_96_waterline\n",
      "               coastline_position_transect_97_waterline\n",
      "               coastline_position_transect_98_waterline\n",
      "               coastline_position_transect_99_waterline\n",
      "               coastline_position_transect_100_waterline\n",
      "               coastline_position_transect_101_waterline\n",
      "               coastline_position_transect_102_waterline\n",
      "               coastline_position_transect_103_waterline\n",
      "               coastline_position_transect_104_waterline\n",
      "               coastline_position_transect_105_waterline\n",
      "               coastline_position_transect_106_waterline\n",
      "timeseries_aggregation\n",
      "               dict_results_agg_minima\n",
      "               dict_results_agg_peaks\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "Time series analysis\n",
      "Island: Dhakandhoo, Maldives\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transect:   0%|          | 0/107 [00:00<?, ?it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:   2%|▏         | 2/107 [00:00<00:06, 15.62it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:   4%|▎         | 4/107 [00:00<00:06, 15.91it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:   6%|▌         | 6/107 [00:00<00:06, 15.12it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:   7%|▋         | 8/107 [00:00<00:06, 15.57it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:   9%|▉         | 10/107 [00:00<00:06, 15.90it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  11%|█         | 12/107 [00:00<00:05, 16.06it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  13%|█▎        | 14/107 [00:00<00:06, 14.65it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  15%|█▍        | 16/107 [00:01<00:06, 14.23it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  17%|█▋        | 18/107 [00:01<00:05, 14.88it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  19%|█▊        | 20/107 [00:01<00:05, 15.31it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  21%|██        | 22/107 [00:01<00:05, 15.66it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  22%|██▏       | 24/107 [00:01<00:05, 15.88it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  24%|██▍       | 26/107 [00:01<00:05, 16.15it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  26%|██▌       | 28/107 [00:01<00:05, 15.18it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  28%|██▊       | 30/107 [00:01<00:05, 14.79it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  30%|██▉       | 32/107 [00:02<00:04, 15.42it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  32%|███▏      | 34/107 [00:02<00:04, 15.77it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  34%|███▎      | 36/107 [00:02<00:04, 15.93it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  36%|███▌      | 38/107 [00:02<00:04, 15.99it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  37%|███▋      | 40/107 [00:02<00:04, 14.58it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  45%|████▍     | 48/107 [00:03<00:03, 15.37it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  47%|████▋     | 50/107 [00:03<00:03, 14.79it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  49%|████▊     | 52/107 [00:03<00:03, 15.78it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  50%|█████     | 54/107 [00:03<00:03, 16.23it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  52%|█████▏    | 56/107 [00:03<00:03, 16.08it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  54%|█████▍    | 58/107 [00:03<00:02, 16.41it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  60%|█████▉    | 64/107 [00:04<00:02, 16.99it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  62%|██████▏   | 66/107 [00:04<00:02, 15.30it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  64%|██████▎   | 68/107 [00:04<00:02, 15.70it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  65%|██████▌   | 70/107 [00:04<00:02, 16.17it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  67%|██████▋   | 72/107 [00:04<00:02, 15.63it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  69%|██████▉   | 74/107 [00:04<00:02, 16.07it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  71%|███████   | 76/107 [00:04<00:01, 16.32it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  73%|███████▎  | 78/107 [00:05<00:01, 15.51it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  76%|███████▌  | 81/107 [00:05<00:01, 18.52it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  78%|███████▊  | 83/107 [00:05<00:01, 16.16it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  80%|████████  | 86/107 [00:05<00:01, 18.84it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  83%|████████▎ | 89/107 [00:05<00:00, 20.53it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  86%|████████▌ | 92/107 [00:05<00:00, 19.32it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  89%|████████▉ | 95/107 [00:05<00:00, 17.95it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  91%|█████████ | 97/107 [00:06<00:00, 17.14it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  93%|█████████▎| 99/107 [00:06<00:00, 17.09it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  94%|█████████▍| 101/107 [00:06<00:00, 16.94it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  96%|█████████▋| 103/107 [00:06<00:00, 16.90it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect:  98%|█████████▊| 105/107 [00:06<00:00, 16.44it/s]c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "c:\\Users\\mp222\\OneDrive - Imperial College London\\IslandTimeGitHub\\IslandTime\\IslandTime\\TimeSeriesAnalysis.py:737: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  results = test(time_series.values)\n",
      "Transect: 100%|██████████| 107/107 [00:06<00:00, 15.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from IslandTime import Workflow, TimeSeriesCoastSat, retrieve_island_info, plot_shoreline_transects, TimeSeriesClimateIndices, PreTimeSeries\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "island = 'Dhakandhoo'\n",
    "country = 'Maldives'\n",
    "\n",
    "# path_coastsat = os.path.join(os.getcwd(), 'data', 'coastsat_data', '{}_{}'.format(island, country))\n",
    "\n",
    "# listdir_coastsat = os.listdir(path_coastsat)\n",
    "\n",
    "# for f in listdir_coastsat:\n",
    "#     if np.char.endswith(f, '_reference_shoreline.pkl') or np.char.endswith(f, '_reference_shoreline.geojson'):\n",
    "#         os.rename(os.path.join(path_coastsat, f), os.path.join(path_coastsat, 'L8', f))\n",
    "\n",
    "# island_info = TimeSeriesCoastSat(island, country, reference_shoreline_transects_only=True, overwrite=True, distance_between_transects=5, retrieve_reference_shoreline_manually=False).main()\n",
    "# island_info = Workflow(island, country, run_all=False, execute_segmentation=True, execute_preprocess=True, execute_analysis=True, update_maps=False, small_island=False).main()\n",
    "\n",
    "#TimeSeriesClimateIndices(island, country, overwrite=True).main()\n",
    "\n",
    "# west, north, east, south = 0.318817, 73.020311, 0.308690, 73.031563\n",
    "\n",
    "\n",
    "# polygon_array = [[north, west],\n",
    "#                   [south, west],\n",
    "#                     [south, east],\n",
    "#                       [north, east],\n",
    "#                         [north, west]]\n",
    "\n",
    "# island_info = PreTimeSeries(island, country, polygon=polygon_array, atoll='Gaafu Dhaalu').main()\n",
    "\n",
    "island_info = retrieve_island_info(island, country)\n",
    "# plot_shoreline_transects(island_info)\n",
    "\n",
    "#TimeSeriesCoastSat(island, country, sat_list=['S2'], re_download=True, date_range=['2021-10-04', '2022-12-31'], overwrite=True).main()\n",
    "\n",
    "# island_info = TimeSeriesCoastSat(island, country, reference_shoreline_transects_only=True, overwrite=True, distance_between_transects=5, retrieve_reference_shoreline_manually=True).main()\n",
    "\n",
    "# island_info = Workflow(isl/and, country, run_all=False, e/xecute_segmentation=True, execute_preprocess=True, execute_analysis=True, update_maps=False, small_island=False).main()\n",
    "island_info = Workflow(island, country, run_all=False, execute_segmentation=False, execute_preprocess=False, execute_analysis=True, update_maps=False, small_island=False).main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shoreline_transects(island_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_47_waterline']['monthly']['coastline_position_transect_47_waterline']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_47_waterline']['monthly']['mean_wave_direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_0_waterline']['monthly']['wave_energy_of_combined_wind_waves_and_swell'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['coastline_position_transect_120_waterline',\n",
       "       'sea_surface_temperature_NOAACRW', 'sea_level_anomaly',\n",
       "       '2_metre_dewpoint_temperature', '2_metre_temperature',\n",
       "       'soil_temperature_level_1', 'evaporation', 'sea_surface_temperature',\n",
       "       'mean_sea_level_pressure', 'wind_speed_10m', 'wind_direction_10m',\n",
       "       'wind_direction_true_10m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_{}_waterline'.format(transect)]['monthly'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect = 2\n",
    "ts1 = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_{}_waterline'.format(transect)]['monthly']['coastline_position_transect_{}_waterline'.format(transect)]\n",
    "ts2 = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_{}_waterline'.format(transect)]['monthly']['mean_wave_direction']\n",
    "ts3 = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_{}_waterline'.format(transect)]['monthly']['wave_energy_of_combined_wind_waves_and_swell']\n",
    "ts4 = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries']['coastline_position_transect_{}_waterline'.format(transect)]['monthly']['sea_level_anomaly']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2555e6ad390>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(ts1.index, ts1.values-np.mean(ts1.values), label='coastline')\n",
    "plt.plot(ts2.index, ts2.values-np.mean(ts2.values), label='wave direction')\n",
    "plt.plot(ts3.index, ts3.values-np.mean(ts3.values), label='wave energy')\n",
    "plt.plot(ts4.index, ts4.values-np.mean(ts4.values), label='sea level anomaly')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: To supress printing the parameers in beast(),      set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast_irreg(),set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast123(),   set extra.printOptions = 0  \n",
      "INFO: To supress warning messages in beast(),            set quiet = 1 \n",
      "INFO: To supress warning messages in beast_irreg(),      set quiet = 1 \n",
      "INFO: To supress warning messages in beast123(),         set extra.quiet = 1  \n",
      "\n",
      "#--------------------------------------------------#\n",
      "#       Brief summary of Input Data                #\n",
      "#--------------------------------------------------#\n",
      "Data Dimension: One signal of length 92\n",
      "IsOrdered     : Yes, ordered in time\n",
      "IsRegular     : Yes, evenly spaced at interval of  0.0833333 year = 1 months = 30.4167 days\n",
      "HasSeasonCmpnt: True  | period = 1 year = 12 months = 365 days. The model 'Y=Trend+Season+Error' is fitted.\n",
      "              : Num_of_DataPoints_per_Period = period/deltaTime = 1/0.0833333 = 12\n",
      "HasOutlierCmpt: False | If true, Y=Trend+Season+Outlier+Error fitted instead of Y=Trend+Season+Error\n",
      "Deseasonalize : False | If true, remove a global seasonal  cmpnt before running BEAST & add it back after BEAST\n",
      "Detrend       : False | If true, remove a global trend component before running BEAST & add it back after BEAST\n",
      "MissingValue  : NaN  flagged as missing values \n",
      "MaxMissingRate: if more than 75% of data is missing, BEAST will skip it.\n",
      "\n",
      "\n",
      "#--------------------------------------------------#\n",
      "#      OPTIONS used in the MCMC inference          #\n",
      "#--------------------------------------------------#\n",
      "\n",
      "#......Start of displaying 'MetaData' ......\n",
      "metadata                =  rb.args() ### or 'lambda: None': just get an empty object### # metadata is used to interpret the input data Y\n",
      "metadata.season         = 'harmonic' # fit a harmonic model to the periodic component\n",
      "metadata.startTime      = 1          # 0001-01-01\n",
      "metadata.deltaTime      = 0.0833333  # 0.0833333 year(s) = 1 month(s) = 30.4167 day(s)\n",
      "metadata.period         = 1          # 1 year(s) = 12 month(s) = 365 day(s) \n",
      "metadata.maxMissingRate = 0.75       # if more than 75% of data is missing, BEAST will skip it.\n",
      "metadata.deseasonalize  = False      # if true,remove a global seasonal cmpnt before running BEAST & add it back later\n",
      "metadata.detrend        = False      # if true,remove a global trend  cmpnt before running BEAST & add it back later\n",
      "#........End of displaying MetaData ........\n",
      "\n",
      "#......Start of displaying 'prior' ......\n",
      "prior                   =  rb.args() ### or 'lambda: None': just get an empty object### # prior is the true model parameters of BEAST\n",
      "prior.seasonMinOrder    = 1          # sorder.minmax[1]: min harmonic order alllowed\n",
      "prior.seasonMaxOrder    = 5          # sorder.minmax[2]: max harmonic order alllowed\n",
      "prior.seasonMinKnotNum  = 0          # scp.minmax[1]   : min num of seasonal chngpts allowed\n",
      "prior.seasonMaxKnotNum  = 10         # scp.minmax[2]   : max num of seasonal chngpts allowed\n",
      "prior.seasonMinSepDist  = 6          # sseg.min        : min seasonal segment length in terms of datapoints\n",
      "prior.seasonLeftMargin  = 6          # sseg.leftmargin : no season chngpts in the first 6 datapoints\n",
      "prior.seasonRightMargin = 6          # sseg.rightmargin: no seoson chngpts in the last 6 datapoints\n",
      "prior.trendMinOrder     = 0          # torder.minmax[1]: min trend polynomial order alllowed\n",
      "prior.trendMaxOrder     = 1          # torder.minmax[2]: max trend polynomial order alllowed\n",
      "prior.trendMinKnotNum   = 0          # tcp.minmax[1]   : min num of chngpts in trend allowed\n",
      "prior.trendMaxKnotNum   = 10         # tcp.minmax[2]   : max num of chngpts in trend allowed\n",
      "prior.trendMinSepDist   = 6          # tseg.min        : min trend segment length in terms of datapoints\n",
      "prior.trendLeftMargin   = 6          # tseg.leftmargin : no trend chngpts in the first 6 datapoints\n",
      "prior.trendRightMargin  = 6          # tseg.rightmargin: no trend chngpts in the last 6 datapoints\n",
      "prior.K_MAX             = 92         # max number of terms in general linear model (relevant only at small values)\n",
      "prior.precValue         = 1.5        # useful mainly when precPriorType='constant'\n",
      "prior.modelPriorType    = 1         \n",
      "prior.precPriorType     = 'componentwise'\n",
      "#......End of displaying prior ......\n",
      "\n",
      "#......Start of displaying 'mcmc' ......\n",
      "mcmc                           =  rb.args() ### or 'lambda: None': just get an empty object### # mcmc is not BEAST parameters but MCMC sampler options\n",
      "mcmc.seed                      = 0          # A nonzero seed to replicate among runs\n",
      "mcmc.samples                   = 8000       # Number of samples saved per chain: the larger, the better\n",
      "mcmc.thinningFactor            = 5          # Thinning the chain: the larger, the better \n",
      "mcmc.burnin                    = 200        # Number of initial samples discarded: the larger, the better\n",
      "mcmc.chainNumber               = 3          # Number of chains: the larger, the better\n",
      "mcmc.maxMoveStepSize           = 6          # Max step of jumping from current changepoint: No need to change\n",
      "mcmc.trendResamplingOrderProb  = 0.1        # Proposal probability of sampling trend polynominal order \n",
      "mcmc.seasonResamplingOrderProb = 0.17       # Proposal probability of sampling seasoanl order \n",
      "mcmc.credIntervalAlphaLevel    = 0.95       # The alphal level for Credible Intervals\n",
      "# Total number of models randomly visited in BEAST is (burnin+sampples*thinFactor)*chainNumber=120600\n",
      "#......End of displaying mcmc ......\n",
      "\n",
      "#......Start of displaying 'extra' ......\n",
      "extra                      =  rb.args() ### or 'lambda: None': just get an empty object### # extra is used to configure output/computing options\n",
      "extra.dumpInputData        = True  # if true, dump a copy of the input data as o.data \n",
      "extra.whichOutputDimIsTime = 1     # 1,2 or 3; which dim of the result is time; used for a 2D/3D input Y\n",
      "extra.computeCredible      = True  # if true, compute  credibiel interval of estimated Y (e.g., o.trend.CI)\n",
      "extra.fastCIComputation    = True  # if true, do not sort but approximiate CI \n",
      "extra.computeSeasonOrder   = True  # if true, dump the estimated time-varying seasonal order: o.season.order \n",
      "extra.computeTrendOrder    = True  # if true, dump the estimated trend polynomial order \n",
      "extra.computeSeasonChngpt  = True  # if true, dump the seasoanl changepoints (scp) in the output \n",
      "extra.computeTrendChngpt   = True  # if true, dump the trend changepoints (tcp) in the output \n",
      "extra.computeSeasonAmp     = False #  compute time-varying seasonal mangitude if season=harmonic  \n",
      "extra.computeTrendSlope    = True  # if true, dump the time-varying slope in trend\n",
      "extra.tallyPosNegSeasonJump= False # differentiate postive/negative jumps at scp\n",
      "extra.tallyPosNegTrendJump = False # differentiate postive/negative jumps at tcp\n",
      "extra.tallyIncDecTrendJump = False # differentiate increased/decreased slopes at tcp\n",
      "extra.printProgressBar     = True  # if true, show an ascii progressbar\n",
      "extra.printOptions         = True  # if true, print the option of the BEAST run\n",
      "extra.consoleWidth         = 85    # an integer specifying the console width for printing\n",
      "extra.numThreadsPerCPU     = 2     # each cpu core spawns 2 concurrent threads (for beast123())\n",
      "extra.numParThreads        = 0     # total number of threads (for beast123() only)\n",
      "#......End of displaying extra ......\n",
      "\n",
      "|Progress: 75.0% done[===============================================>**************]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Progress:100.0% done[==============================================================]\n",
      "\n",
      "INFO: To supress printing the parameers in beast(),      set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast_irreg(),set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast123(),   set extra.printOptions = 0  \n",
      "INFO: To supress warning messages in beast(),            set quiet = 1 \n",
      "INFO: To supress warning messages in beast_irreg(),      set quiet = 1 \n",
      "INFO: To supress warning messages in beast123(),         set extra.quiet = 1  \n",
      "\n",
      "#--------------------------------------------------#\n",
      "#       Brief summary of Input Data                #\n",
      "#--------------------------------------------------#\n",
      "Data Dimension: One signal of length 92\n",
      "IsOrdered     : Yes, ordered in time\n",
      "IsRegular     : Yes, evenly spaced at interval of  0.0833333 year = 1 months = 30.4167 days\n",
      "HasSeasonCmpnt: True  | period = 1 year = 12 months = 365 days. The model 'Y=Trend+Season+Error' is fitted.\n",
      "              : Num_of_DataPoints_per_Period = period/deltaTime = 1/0.0833333 = 12\n",
      "HasOutlierCmpt: False | If true, Y=Trend+Season+Outlier+Error fitted instead of Y=Trend+Season+Error\n",
      "Deseasonalize : False | If true, remove a global seasonal  cmpnt before running BEAST & add it back after BEAST\n",
      "Detrend       : False | If true, remove a global trend component before running BEAST & add it back after BEAST\n",
      "MissingValue  : NaN  flagged as missing values \n",
      "MaxMissingRate: if more than 75% of data is missing, BEAST will skip it.\n",
      "\n",
      "\n",
      "#--------------------------------------------------#\n",
      "#      OPTIONS used in the MCMC inference          #\n",
      "#--------------------------------------------------#\n",
      "\n",
      "#......Start of displaying 'MetaData' ......\n",
      "metadata                =  rb.args() ### or 'lambda: None': just get an empty object### # metadata is used to interpret the input data Y\n",
      "metadata.season         = 'harmonic' # fit a harmonic model to the periodic component\n",
      "metadata.startTime      = 1          # 0001-01-01\n",
      "metadata.deltaTime      = 0.0833333  # 0.0833333 year(s) = 1 month(s) = 30.4167 day(s)\n",
      "metadata.period         = 1          # 1 year(s) = 12 month(s) = 365 day(s) \n",
      "metadata.maxMissingRate = 0.75       # if more than 75% of data is missing, BEAST will skip it.\n",
      "metadata.deseasonalize  = False      # if true,remove a global seasonal cmpnt before running BEAST & add it back later\n",
      "metadata.detrend        = False      # if true,remove a global trend  cmpnt before running BEAST & add it back later\n",
      "#........End of displaying MetaData ........\n",
      "\n",
      "#......Start of displaying 'prior' ......\n",
      "prior                   =  rb.args() ### or 'lambda: None': just get an empty object### # prior is the true model parameters of BEAST\n",
      "prior.seasonMinOrder    = 1          # sorder.minmax[1]: min harmonic order alllowed\n",
      "prior.seasonMaxOrder    = 5          # sorder.minmax[2]: max harmonic order alllowed\n",
      "prior.seasonMinKnotNum  = 0          # scp.minmax[1]   : min num of seasonal chngpts allowed\n",
      "prior.seasonMaxKnotNum  = 10         # scp.minmax[2]   : max num of seasonal chngpts allowed\n",
      "prior.seasonMinSepDist  = 6          # sseg.min        : min seasonal segment length in terms of datapoints\n",
      "prior.seasonLeftMargin  = 6          # sseg.leftmargin : no season chngpts in the first 6 datapoints\n",
      "prior.seasonRightMargin = 6          # sseg.rightmargin: no seoson chngpts in the last 6 datapoints\n",
      "prior.trendMinOrder     = 0          # torder.minmax[1]: min trend polynomial order alllowed\n",
      "prior.trendMaxOrder     = 1          # torder.minmax[2]: max trend polynomial order alllowed\n",
      "prior.trendMinKnotNum   = 0          # tcp.minmax[1]   : min num of chngpts in trend allowed\n",
      "prior.trendMaxKnotNum   = 10         # tcp.minmax[2]   : max num of chngpts in trend allowed\n",
      "prior.trendMinSepDist   = 6          # tseg.min        : min trend segment length in terms of datapoints\n",
      "prior.trendLeftMargin   = 6          # tseg.leftmargin : no trend chngpts in the first 6 datapoints\n",
      "prior.trendRightMargin  = 6          # tseg.rightmargin: no trend chngpts in the last 6 datapoints\n",
      "prior.K_MAX             = 92         # max number of terms in general linear model (relevant only at small values)\n",
      "prior.precValue         = 1.5        # useful mainly when precPriorType='constant'\n",
      "prior.modelPriorType    = 1         \n",
      "prior.precPriorType     = 'componentwise'\n",
      "#......End of displaying prior ......\n",
      "\n",
      "#......Start of displaying 'mcmc' ......\n",
      "mcmc                           =  rb.args() ### or 'lambda: None': just get an empty object### # mcmc is not BEAST parameters but MCMC sampler options\n",
      "mcmc.seed                      = 0          # A nonzero seed to replicate among runs\n",
      "mcmc.samples                   = 8000       # Number of samples saved per chain: the larger, the better\n",
      "mcmc.thinningFactor            = 5          # Thinning the chain: the larger, the better \n",
      "mcmc.burnin                    = 200        # Number of initial samples discarded: the larger, the better\n",
      "mcmc.chainNumber               = 3          # Number of chains: the larger, the better\n",
      "mcmc.maxMoveStepSize           = 6          # Max step of jumping from current changepoint: No need to change\n",
      "mcmc.trendResamplingOrderProb  = 0.1        # Proposal probability of sampling trend polynominal order \n",
      "mcmc.seasonResamplingOrderProb = 0.17       # Proposal probability of sampling seasoanl order \n",
      "mcmc.credIntervalAlphaLevel    = 0.95       # The alphal level for Credible Intervals\n",
      "# Total number of models randomly visited in BEAST is (burnin+sampples*thinFactor)*chainNumber=120600\n",
      "#......End of displaying mcmc ......\n",
      "\n",
      "#......Start of displaying 'extra' ......\n",
      "extra                      =  rb.args() ### or 'lambda: None': just get an empty object### # extra is used to configure output/computing options\n",
      "extra.dumpInputData        = True  # if true, dump a copy of the input data as o.data \n",
      "extra.whichOutputDimIsTime = 1     # 1,2 or 3; which dim of the result is time; used for a 2D/3D input Y\n",
      "extra.computeCredible      = True  # if true, compute  credibiel interval of estimated Y (e.g., o.trend.CI)\n",
      "extra.fastCIComputation    = True  # if true, do not sort but approximiate CI \n",
      "extra.computeSeasonOrder   = True  # if true, dump the estimated time-varying seasonal order: o.season.order \n",
      "extra.computeTrendOrder    = True  # if true, dump the estimated trend polynomial order \n",
      "extra.computeSeasonChngpt  = True  # if true, dump the seasoanl changepoints (scp) in the output \n",
      "extra.computeTrendChngpt   = True  # if true, dump the trend changepoints (tcp) in the output \n",
      "extra.computeSeasonAmp     = False #  compute time-varying seasonal mangitude if season=harmonic  \n",
      "extra.computeTrendSlope    = True  # if true, dump the time-varying slope in trend\n",
      "extra.tallyPosNegSeasonJump= False # differentiate postive/negative jumps at scp\n",
      "extra.tallyPosNegTrendJump = False # differentiate postive/negative jumps at tcp\n",
      "extra.tallyIncDecTrendJump = False # differentiate increased/decreased slopes at tcp\n",
      "extra.printProgressBar     = True  # if true, show an ascii progressbar\n",
      "extra.printOptions         = True  # if true, print the option of the BEAST run\n",
      "extra.consoleWidth         = 85    # an integer specifying the console width for printing\n",
      "extra.numThreadsPerCPU     = 2     # each cpu core spawns 2 concurrent threads (for beast123())\n",
      "extra.numParThreads        = 0     # total number of threads (for beast123() only)\n",
      "#......End of displaying extra ......\n",
      "\n",
      "\\Progress:100.0% done[==============================================================]\n",
      "\n",
      "INFO: To supress printing the parameers in beast(),      set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast_irreg(),set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast123(),   set extra.printOptions = 0  \n",
      "INFO: To supress warning messages in beast(),            set quiet = 1 \n",
      "INFO: To supress warning messages in beast_irreg(),      set quiet = 1 \n",
      "INFO: To supress warning messages in beast123(),         set extra.quiet = 1  \n",
      "\n",
      "#--------------------------------------------------#\n",
      "#       Brief summary of Input Data                #\n",
      "#--------------------------------------------------#\n",
      "Data Dimension: One signal of length 92\n",
      "IsOrdered     : Yes, ordered in time\n",
      "IsRegular     : Yes, evenly spaced at interval of  0.0833333 year = 1 months = 30.4167 days\n",
      "HasSeasonCmpnt: True  | period = 1 year = 12 months = 365 days. The model 'Y=Trend+Season+Error' is fitted.\n",
      "              : Num_of_DataPoints_per_Period = period/deltaTime = 1/0.0833333 = 12\n",
      "HasOutlierCmpt: False | If true, Y=Trend+Season+Outlier+Error fitted instead of Y=Trend+Season+Error\n",
      "Deseasonalize : False | If true, remove a global seasonal  cmpnt before running BEAST & add it back after BEAST\n",
      "Detrend       : False | If true, remove a global trend component before running BEAST & add it back after BEAST\n",
      "MissingValue  : NaN  flagged as missing values \n",
      "MaxMissingRate: if more than 75% of data is missing, BEAST will skip it.\n",
      "\n",
      "\n",
      "#--------------------------------------------------#\n",
      "#      OPTIONS used in the MCMC inference          #\n",
      "#--------------------------------------------------#\n",
      "\n",
      "#......Start of displaying 'MetaData' ......\n",
      "metadata                =  rb.args() ### or 'lambda: None': just get an empty object### # metadata is used to interpret the input data Y\n",
      "metadata.season         = 'harmonic' # fit a harmonic model to the periodic component\n",
      "metadata.startTime      = 1          # 0001-01-01\n",
      "metadata.deltaTime      = 0.0833333  # 0.0833333 year(s) = 1 month(s) = 30.4167 day(s)\n",
      "metadata.period         = 1          # 1 year(s) = 12 month(s) = 365 day(s) \n",
      "metadata.maxMissingRate = 0.75       # if more than 75% of data is missing, BEAST will skip it.\n",
      "metadata.deseasonalize  = False      # if true,remove a global seasonal cmpnt before running BEAST & add it back later\n",
      "metadata.detrend        = False      # if true,remove a global trend  cmpnt before running BEAST & add it back later\n",
      "#........End of displaying MetaData ........\n",
      "\n",
      "#......Start of displaying 'prior' ......\n",
      "prior                   =  rb.args() ### or 'lambda: None': just get an empty object### # prior is the true model parameters of BEAST\n",
      "prior.seasonMinOrder    = 1          # sorder.minmax[1]: min harmonic order alllowed\n",
      "prior.seasonMaxOrder    = 5          # sorder.minmax[2]: max harmonic order alllowed\n",
      "prior.seasonMinKnotNum  = 0          # scp.minmax[1]   : min num of seasonal chngpts allowed\n",
      "prior.seasonMaxKnotNum  = 10         # scp.minmax[2]   : max num of seasonal chngpts allowed\n",
      "prior.seasonMinSepDist  = 6          # sseg.min        : min seasonal segment length in terms of datapoints\n",
      "prior.seasonLeftMargin  = 6          # sseg.leftmargin : no season chngpts in the first 6 datapoints\n",
      "prior.seasonRightMargin = 6          # sseg.rightmargin: no seoson chngpts in the last 6 datapoints\n",
      "prior.trendMinOrder     = 0          # torder.minmax[1]: min trend polynomial order alllowed\n",
      "prior.trendMaxOrder     = 1          # torder.minmax[2]: max trend polynomial order alllowed\n",
      "prior.trendMinKnotNum   = 0          # tcp.minmax[1]   : min num of chngpts in trend allowed\n",
      "prior.trendMaxKnotNum   = 10         # tcp.minmax[2]   : max num of chngpts in trend allowed\n",
      "prior.trendMinSepDist   = 6          # tseg.min        : min trend segment length in terms of datapoints\n",
      "prior.trendLeftMargin   = 6          # tseg.leftmargin : no trend chngpts in the first 6 datapoints\n",
      "prior.trendRightMargin  = 6          # tseg.rightmargin: no trend chngpts in the last 6 datapoints\n",
      "prior.K_MAX             = 92         # max number of terms in general linear model (relevant only at small values)\n",
      "prior.precValue         = 1.5        # useful mainly when precPriorType='constant'\n",
      "prior.modelPriorType    = 1         \n",
      "prior.precPriorType     = 'componentwise'\n",
      "#......End of displaying prior ......\n",
      "\n",
      "#......Start of displaying 'mcmc' ......\n",
      "mcmc                           =  rb.args() ### or 'lambda: None': just get an empty object### # mcmc is not BEAST parameters but MCMC sampler options\n",
      "mcmc.seed                      = 0          # A nonzero seed to replicate among runs\n",
      "mcmc.samples                   = 8000       # Number of samples saved per chain: the larger, the better\n",
      "mcmc.thinningFactor            = 5          # Thinning the chain: the larger, the better \n",
      "mcmc.burnin                    = 200        # Number of initial samples discarded: the larger, the better\n",
      "mcmc.chainNumber               = 3          # Number of chains: the larger, the better\n",
      "mcmc.maxMoveStepSize           = 6          # Max step of jumping from current changepoint: No need to change\n",
      "mcmc.trendResamplingOrderProb  = 0.1        # Proposal probability of sampling trend polynominal order \n",
      "mcmc.seasonResamplingOrderProb = 0.17       # Proposal probability of sampling seasoanl order \n",
      "mcmc.credIntervalAlphaLevel    = 0.95       # The alphal level for Credible Intervals\n",
      "# Total number of models randomly visited in BEAST is (burnin+sampples*thinFactor)*chainNumber=120600\n",
      "#......End of displaying mcmc ......\n",
      "\n",
      "#......Start of displaying 'extra' ......\n",
      "extra                      =  rb.args() ### or 'lambda: None': just get an empty object### # extra is used to configure output/computing options\n",
      "extra.dumpInputData        = True  # if true, dump a copy of the input data as o.data \n",
      "extra.whichOutputDimIsTime = 1     # 1,2 or 3; which dim of the result is time; used for a 2D/3D input Y\n",
      "extra.computeCredible      = True  # if true, compute  credibiel interval of estimated Y (e.g., o.trend.CI)\n",
      "extra.fastCIComputation    = True  # if true, do not sort but approximiate CI \n",
      "extra.computeSeasonOrder   = True  # if true, dump the estimated time-varying seasonal order: o.season.order \n",
      "extra.computeTrendOrder    = True  # if true, dump the estimated trend polynomial order \n",
      "extra.computeSeasonChngpt  = True  # if true, dump the seasoanl changepoints (scp) in the output \n",
      "extra.computeTrendChngpt   = True  # if true, dump the trend changepoints (tcp) in the output \n",
      "extra.computeSeasonAmp     = False #  compute time-varying seasonal mangitude if season=harmonic  \n",
      "extra.computeTrendSlope    = True  # if true, dump the time-varying slope in trend\n",
      "extra.tallyPosNegSeasonJump= False # differentiate postive/negative jumps at scp\n",
      "extra.tallyPosNegTrendJump = False # differentiate postive/negative jumps at tcp\n",
      "extra.tallyIncDecTrendJump = False # differentiate increased/decreased slopes at tcp\n",
      "extra.printProgressBar     = True  # if true, show an ascii progressbar\n",
      "extra.printOptions         = True  # if true, print the option of the BEAST run\n",
      "extra.consoleWidth         = 85    # an integer specifying the console width for printing\n",
      "extra.numThreadsPerCPU     = 2     # each cpu core spawns 2 concurrent threads (for beast123())\n",
      "extra.numParThreads        = 0     # total number of threads (for beast123() only)\n",
      "#......End of displaying extra ......\n",
      "\n",
      "|Progress:100.0% done[==============================================================]\n",
      "\n",
      "INFO: To supress printing the parameers in beast(),      set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast_irreg(),set print.options = 0 \n",
      "INFO: To supress printing the parameers in beast123(),   set extra.printOptions = 0  \n",
      "INFO: To supress warning messages in beast(),            set quiet = 1 \n",
      "INFO: To supress warning messages in beast_irreg(),      set quiet = 1 \n",
      "INFO: To supress warning messages in beast123(),         set extra.quiet = 1  \n",
      "\n",
      "#--------------------------------------------------#\n",
      "#       Brief summary of Input Data                #\n",
      "#--------------------------------------------------#\n",
      "Data Dimension: One signal of length 92\n",
      "IsOrdered     : Yes, ordered in time\n",
      "IsRegular     : Yes, evenly spaced at interval of  0.0833333 year = 1 months = 30.4167 days\n",
      "HasSeasonCmpnt: True  | period = 1 year = 12 months = 365 days. The model 'Y=Trend+Season+Error' is fitted.\n",
      "              : Num_of_DataPoints_per_Period = period/deltaTime = 1/0.0833333 = 12\n",
      "HasOutlierCmpt: False | If true, Y=Trend+Season+Outlier+Error fitted instead of Y=Trend+Season+Error\n",
      "Deseasonalize : False | If true, remove a global seasonal  cmpnt before running BEAST & add it back after BEAST\n",
      "Detrend       : False | If true, remove a global trend component before running BEAST & add it back after BEAST\n",
      "MissingValue  : NaN  flagged as missing values \n",
      "MaxMissingRate: if more than 75% of data is missing, BEAST will skip it.\n",
      "\n",
      "\n",
      "#--------------------------------------------------#\n",
      "#      OPTIONS used in the MCMC inference          #\n",
      "#--------------------------------------------------#\n",
      "\n",
      "#......Start of displaying 'MetaData' ......\n",
      "metadata                =  rb.args() ### or 'lambda: None': just get an empty object### # metadata is used to interpret the input data Y\n",
      "metadata.season         = 'harmonic' # fit a harmonic model to the periodic component\n",
      "metadata.startTime      = 1          # 0001-01-01\n",
      "metadata.deltaTime      = 0.0833333  # 0.0833333 year(s) = 1 month(s) = 30.4167 day(s)\n",
      "metadata.period         = 1          # 1 year(s) = 12 month(s) = 365 day(s) \n",
      "metadata.maxMissingRate = 0.75       # if more than 75% of data is missing, BEAST will skip it.\n",
      "metadata.deseasonalize  = False      # if true,remove a global seasonal cmpnt before running BEAST & add it back later\n",
      "metadata.detrend        = False      # if true,remove a global trend  cmpnt before running BEAST & add it back later\n",
      "#........End of displaying MetaData ........\n",
      "\n",
      "#......Start of displaying 'prior' ......\n",
      "prior                   =  rb.args() ### or 'lambda: None': just get an empty object### # prior is the true model parameters of BEAST\n",
      "prior.seasonMinOrder    = 1          # sorder.minmax[1]: min harmonic order alllowed\n",
      "prior.seasonMaxOrder    = 5          # sorder.minmax[2]: max harmonic order alllowed\n",
      "prior.seasonMinKnotNum  = 0          # scp.minmax[1]   : min num of seasonal chngpts allowed\n",
      "prior.seasonMaxKnotNum  = 10         # scp.minmax[2]   : max num of seasonal chngpts allowed\n",
      "prior.seasonMinSepDist  = 6          # sseg.min        : min seasonal segment length in terms of datapoints\n",
      "prior.seasonLeftMargin  = 6          # sseg.leftmargin : no season chngpts in the first 6 datapoints\n",
      "prior.seasonRightMargin = 6          # sseg.rightmargin: no seoson chngpts in the last 6 datapoints\n",
      "prior.trendMinOrder     = 0          # torder.minmax[1]: min trend polynomial order alllowed\n",
      "prior.trendMaxOrder     = 1          # torder.minmax[2]: max trend polynomial order alllowed\n",
      "prior.trendMinKnotNum   = 0          # tcp.minmax[1]   : min num of chngpts in trend allowed\n",
      "prior.trendMaxKnotNum   = 10         # tcp.minmax[2]   : max num of chngpts in trend allowed\n",
      "prior.trendMinSepDist   = 6          # tseg.min        : min trend segment length in terms of datapoints\n",
      "prior.trendLeftMargin   = 6          # tseg.leftmargin : no trend chngpts in the first 6 datapoints\n",
      "prior.trendRightMargin  = 6          # tseg.rightmargin: no trend chngpts in the last 6 datapoints\n",
      "prior.K_MAX             = 92         # max number of terms in general linear model (relevant only at small values)\n",
      "prior.precValue         = 1.5        # useful mainly when precPriorType='constant'\n",
      "prior.modelPriorType    = 1         \n",
      "prior.precPriorType     = 'componentwise'\n",
      "#......End of displaying prior ......\n",
      "\n",
      "#......Start of displaying 'mcmc' ......\n",
      "mcmc                           =  rb.args() ### or 'lambda: None': just get an empty object### # mcmc is not BEAST parameters but MCMC sampler options\n",
      "mcmc.seed                      = 0          # A nonzero seed to replicate among runs\n",
      "mcmc.samples                   = 8000       # Number of samples saved per chain: the larger, the better\n",
      "mcmc.thinningFactor            = 5          # Thinning the chain: the larger, the better \n",
      "mcmc.burnin                    = 200        # Number of initial samples discarded: the larger, the better\n",
      "mcmc.chainNumber               = 3          # Number of chains: the larger, the better\n",
      "mcmc.maxMoveStepSize           = 6          # Max step of jumping from current changepoint: No need to change\n",
      "mcmc.trendResamplingOrderProb  = 0.1        # Proposal probability of sampling trend polynominal order \n",
      "mcmc.seasonResamplingOrderProb = 0.17       # Proposal probability of sampling seasoanl order \n",
      "mcmc.credIntervalAlphaLevel    = 0.95       # The alphal level for Credible Intervals\n",
      "# Total number of models randomly visited in BEAST is (burnin+sampples*thinFactor)*chainNumber=120600\n",
      "#......End of displaying mcmc ......\n",
      "\n",
      "#......Start of displaying 'extra' ......\n",
      "extra                      =  rb.args() ### or 'lambda: None': just get an empty object### # extra is used to configure output/computing options\n",
      "extra.dumpInputData        = True  # if true, dump a copy of the input data as o.data \n",
      "extra.whichOutputDimIsTime = 1     # 1,2 or 3; which dim of the result is time; used for a 2D/3D input Y\n",
      "extra.computeCredible      = True  # if true, compute  credibiel interval of estimated Y (e.g., o.trend.CI)\n",
      "extra.fastCIComputation    = True  # if true, do not sort but approximiate CI \n",
      "extra.computeSeasonOrder   = True  # if true, dump the estimated time-varying seasonal order: o.season.order \n",
      "extra.computeTrendOrder    = True  # if true, dump the estimated trend polynomial order \n",
      "extra.computeSeasonChngpt  = True  # if true, dump the seasoanl changepoints (scp) in the output \n",
      "extra.computeTrendChngpt   = True  # if true, dump the trend changepoints (tcp) in the output \n",
      "extra.computeSeasonAmp     = False #  compute time-varying seasonal mangitude if season=harmonic  \n",
      "extra.computeTrendSlope    = True  # if true, dump the time-varying slope in trend\n",
      "extra.tallyPosNegSeasonJump= False # differentiate postive/negative jumps at scp\n",
      "extra.tallyPosNegTrendJump = False # differentiate postive/negative jumps at tcp\n",
      "extra.tallyIncDecTrendJump = False # differentiate increased/decreased slopes at tcp\n",
      "extra.printProgressBar     = True  # if true, show an ascii progressbar\n",
      "extra.printOptions         = True  # if true, print the option of the BEAST run\n",
      "extra.consoleWidth         = 85    # an integer specifying the console width for printing\n",
      "extra.numThreadsPerCPU     = 2     # each cpu core spawns 2 concurrent threads (for beast123())\n",
      "extra.numParThreads        = 0     # total number of threads (for beast123() only)\n",
      "#......End of displaying extra ......\n",
      "\n",
      "/Progress:100.0% done[==============================================================]\n"
     ]
    }
   ],
   "source": [
    "import Rbeast as rb\n",
    "\n",
    "o = rb.beast(ts1, deltat='1/12 year', season='harmonic', period='1 year')\n",
    "# rb.plot(o)\n",
    "\n",
    "o2 = rb.beast(ts2, deltat='1/12 year', season='harmonic', period='1 year')\n",
    "# rb.plot(o2)\n",
    "\n",
    "o3 = rb.beast(ts3, deltat='1/12 year', season='harmonic', period='1 year')\n",
    "# rb.plot(o3)\n",
    "\n",
    "o4 = rb.beast(ts4, deltat='1/12 year', season='harmonic', period='1 year')\n",
    "# rb.plot(o4)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ts1.index, (o.season.Y- np.mean(o.season.Y)), label='coastline')\n",
    "# plt.plot(ts1.index, o2.season.Y- np.mean(o2.season.Y)*0.1, label='wave direction')\n",
    "plt.plot(ts1.index, o3.season.Y- np.mean(o3.season.Y), label='wave energy')\n",
    "plt.plot(ts1.index, (o4.season.Y- np.mean(o4.season.Y))*100, label='sea level anomaly')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "stl = STL(ts1, seasonal=13)\n",
    "res = stl.fit()\n",
    "res.plot()\n",
    "s1 = res.seasonal\n",
    "\n",
    "stl = STL(ts2, seasonal=13)\n",
    "res = stl.fit()\n",
    "res.plot()\n",
    "s2 = res.seasonal\n",
    "\n",
    "stl = STL(ts3, seasonal=13)\n",
    "res = stl.fit()\n",
    "res.plot()\n",
    "s3 = res.seasonal\n",
    "\n",
    "stl = STL(ts4, seasonal=13)\n",
    "res = stl.fit()\n",
    "res.plot()\n",
    "s4 = res.seasonal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Normalize Data\n",
    "# Ensure that both series have the same length and index\n",
    "# If not, align the indexes or interpolate the missing values\n",
    "from scipy import signal\n",
    "x = o2.season.Y\n",
    "y = o3.season.Y\n",
    "\n",
    "correlation = signal.correlate(x-np.mean(x), y - np.mean(y), mode=\"full\")\n",
    "lags = signal.correlation_lags(len(x), len(y), mode=\"full\")\n",
    "lag = lags[np.argmax(abs(correlation))]\n",
    "\n",
    "plt.plot(lags, correlation)\n",
    "lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coastline_position_transect_0_waterline\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'coastline_position_transect_coastline_position_transect_0_waterline_waterline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(key)\n\u001b[0;32m     16\u001b[0m transect \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m---> 17\u001b[0m ts1 \u001b[38;5;241m=\u001b[39m \u001b[43misland_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeseries_preprocessing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimal time period\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdict_timeseries\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoastline_position_transect_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_waterline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransect\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonthly\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoastline_position_transect_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_waterline\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(transect)]\n\u001b[0;32m     18\u001b[0m ts2 \u001b[38;5;241m=\u001b[39m island_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeseries_preprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimal time period\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict_timeseries\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoastline_position_transect_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_waterline\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(transect)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonthly\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_wave_direction\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m ts3 \u001b[38;5;241m=\u001b[39m island_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeseries_preprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimal time period\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict_timeseries\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoastline_position_transect_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_waterline\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(transect)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonthly\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwave_energy_of_combined_wind_waves_and_swell\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'coastline_position_transect_coastline_position_transect_0_waterline_waterline'"
     ]
    }
   ],
   "source": [
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import numpy as np\n",
    "\n",
    "lag_res = []\n",
    "lag_res_cc = []\n",
    "cc = []\n",
    "lag_res2 = []\n",
    "lag_res_cc2 = []\n",
    "lag_res3 = []\n",
    "lag_res_cc3 = []\n",
    "\n",
    "for idx, key in enumerate(island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries'].keys()):\n",
    "    print(key)\n",
    "\n",
    "    transect = key\n",
    "    ts1 = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries'][key]['monthly'][key]\n",
    "    ts2 = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries'][key]['monthly']['mean_wave_direction']\n",
    "    ts3 = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries'][key]['monthly']['wave_energy_of_combined_wind_waves_and_swell']\n",
    "    ts4 = island_info['timeseries_preprocessing']['optimal time period']['dict_timeseries'][key]['monthly']['sea_level_anomaly']\n",
    "\n",
    "    if len(ts1) < 12:\n",
    "        continue\n",
    "\n",
    "    # stl1 = STL(a, seasonal=13)\n",
    "    # res1 = stl1.fit()\n",
    "    # s1 = res1.seasonal\n",
    "\n",
    "    # stl2 = STL(b, seasonal=13)\n",
    "    # res2 = stl2.fit()\n",
    "    # s2 = res2.seasonal\n",
    "    # plt.figure()\n",
    "    # plt.plot(s1.index, s1.values-np.mean(s1.values))\n",
    "    # plt.plot(s2.index, s2.values-np.mean(s2.values))\n",
    "\n",
    "    o = rb.beast(ts1, deltat='1/12 year', season='harmonic', period='1 year')\n",
    "    s1 = o.season.Y\n",
    "    # rb.plot(o)\n",
    "\n",
    "    o2 = rb.beast(ts2, deltat='1/12 year', season='harmonic', period='1 year')\n",
    "    s2 = o2.season.Y\n",
    "    # rb.plot(o2)\n",
    "\n",
    "    o3 = rb.beast(ts3, deltat='1/12 year', season='harmonic', period='1 year')\n",
    "    s3 = o3.season.Y\n",
    "    # rb.plot(o3)\n",
    "\n",
    "    o4 = rb.beast(ts4, deltat='1/12 year', season='harmonic', period='1 year')\n",
    "    s4 = o4.season.Y\n",
    "\n",
    "\n",
    "    distance, path = fastdtw(s1, s2, dist=2)\n",
    "    distance2, path2 = fastdtw(s1, s3, dist=2)\n",
    "    distance3, path3 = fastdtw(s1, s4, dist=2)\n",
    "    # print(f\"DTW Distance: {distance}\")\n",
    "\n",
    "    # Plot the time series and the alignment path\n",
    "    # plt.plot(ts1.values, label='x')\n",
    "    # plt.plot(ts2.values, label='y')\n",
    "\n",
    "    # Extract the indices from the alignment path\n",
    "    path_indices_x = [point[0] for point in path]\n",
    "    path_indices_y = [point[1] for point in path]\n",
    "\n",
    "    path_indices_x2 = [point[0] for point in path2]\n",
    "    path_indices_y2 = [point[1] for point in path2]\n",
    "\n",
    "    path_indices_x3 = [point[0] for point in path3]\n",
    "    path_indices_y3 = [point[1] for point in path3]\n",
    "\n",
    "    # Measure the lag from DTW\n",
    "    lag = np.mean(np.abs(np.array(path_indices_x) - np.array(path_indices_y)))\n",
    "    lag2 = np.mean(np.abs(np.array(path_indices_x2) - np.array(path_indices_y2)))\n",
    "    lag3 = np.mean(np.abs(np.array(path_indices_x3) - np.array(path_indices_y3)))\n",
    "\n",
    "    # measure lag from cross-correlation\n",
    "    correlation = signal.correlate(s1-np.mean(s1), s2 - np.mean(s1), mode=\"full\")\n",
    "    lags_cc = signal.correlation_lags(len(s1), len(s2), mode=\"full\")\n",
    "    arg_lags = np.argsort(abs(correlation))[::-1]\n",
    "\n",
    "    correlation2 = signal.correlate(s1-np.mean(s1), s3 - np.mean(s1), mode=\"full\")\n",
    "    lags_cc2 = signal.correlation_lags(len(s1), len(s3), mode=\"full\")\n",
    "    arg_lags2 = np.argsort(abs(correlation2))[::-1]\n",
    "\n",
    "    correlation3 = signal.correlate(s1-np.mean(s1), s4 - np.mean(s1), mode=\"full\")\n",
    "    lags_cc3 = signal.correlation_lags(len(s1), len(s4), mode=\"full\")\n",
    "    arg_lags3 = np.argsort(abs(correlation3))[::-1]\n",
    "\n",
    "    # if abs(lags_cc[arg_lags[0]]) > 12:\n",
    "    #     lag_cc = lags_cc[arg_lags[1]]\n",
    "    # else:\n",
    "    #     lag_cc = lags_cc[arg_lags[0]]\n",
    "    lag_cc = lags[np.argmax(abs(correlation))]\n",
    "    lag_cc2 = lags[np.argmax(abs(correlation2))]\n",
    "    lag_cc3 = lags[np.argmax(abs(correlation3))]\n",
    "\n",
    "    cc.append(idx)\n",
    "    lag_res.append(lag)\n",
    "    lag_res_cc.append(lag_cc)\n",
    "    lag_res2.append(lag2)\n",
    "    lag_res_cc2.append(lag_cc2)\n",
    "    lag_res3.append(lag3)\n",
    "    lag_res_cc3.append(lag_cc3)\n",
    "\n",
    "    print(\"Lag from DTW:\", lag)\n",
    "\n",
    "# for point in path:\n",
    "#     plt.plot([point[0], point[1]], [ts1.values[point[0]], ts2.values[point[1]]], color='red')\n",
    "\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('DTW Alignment Path')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"DTW Distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1c6006ddf50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(cc, lag_res, marker='.')\n",
    "# plt.plot(cc, lag_res_cc, marker='.')\n",
    "plt.axhline(2, color='r', ls='--')\n",
    "plt.axhline(3, color='r', ls='--')\n",
    "plt.axhline(1, color='k', ls='--')\n",
    "# plt.ylim(-12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the time series based on the alignment path\n",
    "aligned_x = np.zeros(len(ts2.values))\n",
    "aligned_y = np.zeros(len(ts2.values))\n",
    "\n",
    "for i, j in path:\n",
    "    aligned_x[j] = ts1.values[i]\n",
    "    aligned_y[j] = ts2.values[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aligned_x, label='x')\n",
    "plt.plot(aligned_y, label='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import *\n",
    "\n",
    "distance, path = dtw(ts1.values, ts2.values)\n",
    "\n",
    "print(\"DTW Distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "# Calculate cross-correlation\n",
    "cross_corr = np.correlate(ts1.values.flatten(), ts2.values.flatten(), mode='full')\n",
    "\n",
    "# Calculate DTW distance\n",
    "dtw_distance, _ = fastdtw(ts1.values.flatten(), ts2.values.flatten(), dist=euclidean)\n",
    "\n",
    "# Calculate Pearson correlation coefficient on rolling windows\n",
    "window_size = 50\n",
    "rolling_corr = ts1.rolling(window_size).corr(ts2)\n",
    "\n",
    "# Plot cross-correlation\n",
    "plt.plot(cross_corr)\n",
    "plt.xlabel('Time Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.title('Cross-Correlation between ts1 and ts2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"DTW Distance:\", dtw_distance)\n",
    "print(\"Max Rolling Pearson Correlation:\", rolling_corr.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-correlation\n",
    "cross_corr = np.correlate(ts1, ts2, mode='full')\n",
    "\n",
    "# Calculate the time lags corresponding to the cross-correlation values\n",
    "time_lags = np.arange(-len(ts1) + 1, len(ts1))\n",
    "\n",
    "# Plot cross-correlation\n",
    "plt.plot(time_lags, cross_corr)\n",
    "plt.xlabel('Time Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.title('Cross-Correlation between ts1 and ts2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find lag with maximum correlation\n",
    "max_corr_index = np.argmax(cross_corr)\n",
    "max_corr_value = cross_corr[max_corr_index]\n",
    "lag_with_max_corr = time_lags[max_corr_index]\n",
    "\n",
    "print(\"Maximum Cross-Correlation:\", max_corr_value)\n",
    "print(\"Lag with Maximum Cross-Correlation:\", lag_with_max_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IslandTime import Workflow, TimeSeriesCoastSat, retrieve_island_info, plot_shoreline_transects, TimeSeriesClimateIndices, PreTimeSeries\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "island = \"Gan (Gaafu Dhaalu)\"\n",
    "country = 'Maldives'\n",
    "\n",
    "#TimeSeriesClimateIndices(island, country, overwrite=True).main()\n",
    "\n",
    "##island_info = PreTimeSeries(island, country, atoll='Haa Alifu').main()\n",
    "\n",
    "# island_info = retrieve_island_info(island, country)\n",
    "# plot_shoreline_transects(island_info)\n",
    "\n",
    "#TimeSeriesCoastSat(island, country, sat_list=['S2'], re_download=True, date_range=['2021-10-04', '2022-12-31'], overwrite=True).main()\n",
    "\n",
    "# island_info = TimeSeriesCoastSat(island, country, reference_shoreline_transects_only=True, overwrite=True, distance_between_transects=50).main()\n",
    "\n",
    "# island_info = Workflow(island, country, run_all=False, execute_segmentation=True, execute_preprocess=True, execute_analysis=True, update_maps=False, small_island=False).main()\n",
    "island_info = Workflow(island, country, run_all=False, execute_segmentation=True, execute_preprocess=True, execute_analysis=True, update_maps=False, small_island=True).main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IslandTime import Workflow, TimeSeriesCoastSat, retrieve_island_info, plot_shoreline_transects, TimeSeriesClimateIndices, PreTimeSeries\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "island = \"Gan (Gaafu Dhaalu)\"\n",
    "country = 'Maldives'\n",
    "\n",
    "#TimeSeriesClimateIndices(island, country, overwrite=True).main()\n",
    "\n",
    "##island_info = PreTimeSeries(island, country, atoll='Haa Alifu').main()\n",
    "\n",
    "# island_info = retrieve_island_info(island, country)\n",
    "# plot_shoreline_transects(island_info)\n",
    "\n",
    "#TimeSeriesCoastSat(island, country, sat_list=['S2'], re_download=True, date_range=['2021-10-04', '2022-12-31'], overwrite=True).main()\n",
    "\n",
    "island_info = TimeSeriesCoastSat(island, country, reference_shoreline_transects_only=True, overwrite=True, distance_between_transects=50).main()\n",
    "\n",
    "# island_info = Workflow(island, country, run_all=False, execute_segmentation=True, execute_preprocess=True, execute_analysis=True, update_maps=False, small_island=False).main()\n",
    "# island_info = Workflow(island, country, run_all=False, execute_segmentation=True, execute_preprocess=True, execute_analysis=True, update_maps=False, small_island=True).main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "island_info['timeseries_preprocessing']['df_coastline_timeseries'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "island_info = retrieve_island_info('Vodamulaa', 'Maldives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_plant = Image.open('cecil_plant.jpg')\n",
    "img_plant_arr = np.array(img_plant)\n",
    "\n",
    "# Removing the background from the given Image \n",
    "output = remove(img_plant_arr) \n",
    "\n",
    "# Create a PIL Image from the output array\n",
    "output_image = Image.fromarray(output)\n",
    "\n",
    "plt.imshow(img_plant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_plant = img_plant_arr[:, :, 0]\n",
    "green_plant = img_plant_arr[:, :, 1]\n",
    "blue_plant = img_plant_arr[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_polygons_segmented, X_peaks, X, histogram_distribution = Segmentation(island_info)._band_segmentation(green_plant, img_plant_arr, label='green', plot_results=True, find_polygons=False, segmented_image=None, cmap=None, animation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Segmentation(island_info)._unsupervised_classification(np.where(result == 0., np.nan, result), n_clusters=2, plot_classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.where(result == 0., np.nan, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_plant)\n",
    "for pol in dict_polygons_segmented['otsu']['polygons']:\n",
    "    gpd.GeoSeries(pol.exterior).plot(ax=ax, color='k')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by area\n",
    "polygons_area = sorted(dict_polygons_segmented['otsu']['polygons'], key=lambda x: x.area, reverse=True)\n",
    "big_polygon = polygons_area[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "shapely.to_geojson(big_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_plant)\n",
    "\n",
    "# Create a mask with zeros (black) and fill the polygon region with white (255)\n",
    "mask = np.zeros_like(img_plant_arr)\n",
    "for pol in dict_polygons_segmented['otsu']['polygons']:\n",
    "    cv2.fillPoly(mask, [np.array(pol.exterior.coords).astype(np.int32)], (255, 255, 255))\n",
    "\n",
    "    for interior in pol.interiors:\n",
    "        gpd.GeoSeries(interior).plot(ax=ax, color='r')\n",
    "        cv2.fillPoly(mask, [np.array(interior.coords).astype(np.int32)], (0, 0, 0))\n",
    "\n",
    "# Invert the mask (to make the polygon region black and the rest white)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the image\n",
    "result = cv2.bitwise_and(img_plant_arr, mask)\n",
    "#plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_drone_imagery = os.path.join(os.getcwd(), 'data', 'drone_imagery', 'Kihaadhoo', 'down_2.tif')\n",
    "path_xml_file = os.path.join(os.getcwd(), 'data', 'drone_imagery', 'Kihaadhoo', 'down_2.tif.aux.xml')\n",
    "\n",
    "xmldoc = minidom.parse(path_xml_file)\n",
    "\n",
    "img = gdal.Open(path_drone_imagery, gdal.GA_ReadOnly)\n",
    "geotransform = img.GetGeoTransform()\n",
    "red = img.GetRasterBand(1).ReadAsArray()\n",
    "green = img.GetRasterBand(2).ReadAsArray()\n",
    "blue = img.GetRasterBand(3).ReadAsArray()\n",
    "mask = img.GetRasterBand(4).ReadAsArray()\n",
    "rgb = np.dstack((red, green, blue))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_dict, X_peaks, X, histogram_distribution = Segmentation.segmentation(blue[5500:6100, 3300:3800], rgb[5500:6100, 3300:3800, :], 'blue', segmented_image=None, cmap=None, classes_to_consider=None, plot_results=True, animation=False, find_polygons=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, img_l in zip(['red', 'green', 'blue'], [red, green, blue]):\n",
    "    \n",
    "    polygons_dict, X_peaks, X, histogram_distribution = Segmentation.segmentation(img_l, rgb, label, segmented_image=None, cmap=None, classes_to_consider=None, plot_results=True, animation=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IslandTime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
